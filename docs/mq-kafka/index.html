<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>消息队列原理之kafka - 大大很二</title><meta name="Description" content="消息队列原理之kafka"><meta property="og:title" content="消息队列原理之kafka" />
<meta property="og:description" content="消息队列原理之kafka" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://russellgao.cn/mq-kafka/" />
<meta property="og:image" content="https://russellgao.cn/images/profile.jpg"/>
<meta property="article:published_time" content="2020-12-17T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-12-22T23:35:13+08:00" /><meta property="og:site_name" content="大大很二" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://russellgao.cn/images/profile.jpg"/>

<meta name="twitter:title" content="消息队列原理之kafka"/>
<meta name="twitter:description" content="消息队列原理之kafka"/>
<meta name="application-name" content="russellgao">
<meta name="apple-mobile-web-app-title" content="russellgao"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="icon" href="https://gitee.com/russellgao/blogs-image/raw/master/images/favicon.ico"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://russellgao.cn/mq-kafka/" /><link rel="prev" href="https://russellgao.cn/mq-rabbitmq/" /><link rel="next" href="https://russellgao.cn/design-principle/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "消息队列原理之kafka",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/russellgao.cn\/mq-kafka\/"
        },"genre": "posts","keywords": "kafka, 消息队列","wordcount":  2651 ,
        "url": "https:\/\/russellgao.cn\/mq-kafka\/","datePublished": "2020-12-17T00:00:00+00:00","dateModified": "2020-12-22T23:35:13+08:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "russellgao"
            },"description": "消息队列原理之kafka"
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : '' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="大大很二"><img
        class="lazyload logo"
        src="/svg/loading.min.svg"
        data-src="https://gitee.com/russellgao/blogs-image/raw/master/images/russellgao.png"
        data-srcset="https://gitee.com/russellgao/blogs-image/raw/master/images/russellgao.png, https://gitee.com/russellgao/blogs-image/raw/master/images/russellgao.png 1.5x, https://gitee.com/russellgao/blogs-image/raw/master/images/russellgao.png 2x"
        data-sizes="auto"
        alt="https://gitee.com/russellgao/blogs-image/raw/master/images/russellgao.png"
        title="https://gitee.com/russellgao/blogs-image/raw/master/images/russellgao.png" />大大很二</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/"> 首页 </a><a class="menu-item" href="/golang/"> Golang </a><a class="menu-item" href="/kubernetes/"> Kubernetes </a><a class="menu-item" href="/servicemesh/"> ServiceMesh </a><a class="menu-item" href="/python/"> Python </a><a class="menu-item" href="/devops/"> Devops </a><a class="menu-item" href="/argorithm/"> 算法 </a><a class="menu-item" href="/opensrouce/"> 开源项目 </a><a class="menu-item" href="/ai/"> 人工智能 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/about/"> 关于 </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="大大很二"><img
        class="lazyload logo"
        src="/svg/loading.min.svg"
        data-src="https://gitee.com/russellgao/blogs-image/raw/master/images/russellgao.png"
        data-srcset="https://gitee.com/russellgao/blogs-image/raw/master/images/russellgao.png, https://gitee.com/russellgao/blogs-image/raw/master/images/russellgao.png 1.5x, https://gitee.com/russellgao/blogs-image/raw/master/images/russellgao.png 2x"
        data-sizes="auto"
        alt="https://gitee.com/russellgao/blogs-image/raw/master/images/russellgao.png"
        title="https://gitee.com/russellgao/blogs-image/raw/master/images/russellgao.png" />大大很二</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/" title="">首页</a><a class="menu-item" href="/golang/" title="">Golang</a><a class="menu-item" href="/kubernetes/" title="">Kubernetes</a><a class="menu-item" href="/servicemesh/" title="">ServiceMesh</a><a class="menu-item" href="/python/" title="">Python</a><a class="menu-item" href="/devops/" title="">Devops</a><a class="menu-item" href="/argorithm/" title="">算法</a><a class="menu-item" href="/opensrouce/" title="">开源项目</a><a class="menu-item" href="/ai/" title="">人工智能</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/about/" title="">关于</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">消息队列原理之kafka</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://github.com/russellgao" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw"></i>russellgao</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2020-12-17">2020-12-17</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;2651 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;13 minutes&nbsp;<span id="/mq-kafka/" class="leancloud_visitors" data-flag-title="消息队列原理之kafka">
                        <i class="far fa-eye fa-fw"></i>&nbsp;<span class=leancloud-visitors-count></span>&nbsp;views
                    </span>&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="true">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#导读">导读</a></li>
    <li><a href="#kafka-主要设计目标如下">Kafka 主要设计目标如下</a></li>
    <li><a href="#kafka-通常用于两大类应用程序">Kafka 通常用于两大类应用程序</a></li>
    <li><a href="#首先几个概念">首先几个概念</a></li>
    <li><a href="#kafka-架构体系如下图">Kafka 架构体系如下图</a></li>
    <li><a href="#kafka-的优点">Kafka 的优点</a></li>
    <li><a href="#kafka-与其他-mq-对比">Kafka 与其他 MQ 对比</a></li>
    <li><a href="#kafka-中的关键术语解释">Kafka 中的关键术语解释</a></li>
    <li><a href="#kafka的工作原理和过程">Kafka的工作原理和过程</a>
      <ul>
        <li><a href="#消息写入算法">消息写入算法</a></li>
        <li><a href="#消息路由策略">消息路由策略</a></li>
        <li><a href="#hw-截断机制">HW 截断机制</a></li>
        <li><a href="#消息发送的可靠性">消息发送的可靠性</a></li>
        <li><a href="#消费者消费过程解析">消费者消费过程解析</a></li>
        <li><a href="#partition-leader-选举范围">Partition Leader 选举范围</a></li>
        <li><a href="#重复消费问题的解决方案">重复消费问题的解决方案</a></li>
        <li><a href="#从架构设计上解决-kafka-重复消费的问题">从架构设计上解决 Kafka 重复消费的问题</a>
          <ul>
            <li><a href="#保存并查询">保存并查询</a></li>
            <li><a href="#利用幂等">利用幂等</a></li>
            <li><a href="#设置前提条件">设置前提条件</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#搭建集群">搭建集群</a></li>
    <li><a href="#kafka-的操作">Kafka 的操作</a>
      <ul>
        <li><a href="#topic">topic</a></li>
        <li><a href="#发送消息">发送消息</a></li>
        <li><a href="#消费消息">消费消息</a></li>
        <li><a href="#kafka-的日志">Kafka 的日志</a></li>
      </ul>
    </li>
    <li><a href="#kafka-api">Kafka API</a>
      <ul>
        <li><a href="#消费者自动提交">消费者自动提交</a></li>
        <li><a href="#消费者同步手动提交">消费者同步手动提交</a></li>
        <li><a href="#消费者异步手工提交">消费者异步手工提交</a></li>
        <li><a href="#spring-boot-使用-kafka">Spring Boot 使用 Kafka</a></li>
      </ul>
    </li>
    <li><a href="#参考">参考</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h2 id="导读">导读</h2>
<blockquote>
<p>本文消息队列系列第二篇，上一篇讲述的是 <a href="https://russellgao.cn/mq-rabbitmq/" target="_blank" rel="noopener noreffer">Rabbitmq</a> ，这篇主要介绍 <code>Kafka</code> 的原理与使用。</p>
<p>Kafka 是一个快速、可扩展的、高吞吐的、可容错的分布式“发布-订阅”消息系统， 使用 Scala 与 Java 语言编写，能够将消息从一个端点传递到另一个端点。
较之传统的消息中间件（例如 ActiveMQ、RabbitMQ），Kafka 具有高吞吐量、内置分区、支持消息副本和高容错的特性，非常适合大规模消息处理应用程序。</p>
<p>Kafka 官网：<code>http://kafka.apache.org/</code></p>
</blockquote>
<h2 id="kafka-主要设计目标如下">Kafka 主要设计目标如下</h2>
<ul>
<li>以时间复杂度为 O(1) 的方式提供消息持久化能力，即使对 TB 级以上数据也能保证常数时间的访问性能。</li>
<li>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条消息的传输。</li>
<li>支持 Kafka Server 间的消息分区，及分布式消费，同时保证每个 Partition 内的消息顺序传输。</li>
<li>同时支持离线数据处理和实时数据处理。</li>
<li>支持在线水平扩展。</li>
</ul>
<h2 id="kafka-通常用于两大类应用程序">Kafka 通常用于两大类应用程序</h2>
<ul>
<li>建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。</li>
<li>构建实时流应用程序，以转换或响应数据流。</li>
</ul>
<p>要了解 Kafka 如何执行这些操作，让我们从头开始深入研究 Kafka 的功能。</p>
<h2 id="首先几个概念">首先几个概念</h2>
<ul>
<li>Kafka 在一个或多个可以跨越多个数据中心的服务器上作为集群运行。</li>
<li>Kafka 集群将记录流存储在称为主题的类别中。</li>
<li>每个记录由一个键，一个值和一个时间戳组成。</li>
</ul>
<h2 id="kafka-架构体系如下图">Kafka 架构体系如下图</h2>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-1.png"
        data-srcset="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-1.png, https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-1.png 1.5x, https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-1.png 2x"
        data-sizes="auto"
        alt="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-1.png"
        title="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-1.png" /></p>
<p>Kafka 的应用场景非常多, 下面我们就来举几个我们最常见的场景：</p>
<ul>
<li>
<p>用户的活动跟踪：用户在网站的不同活动消息发布到不同的主题中心，然后可以对这些消息进行实时监测、实时处理。当然，也可以加载到 Hadoop 或离线处理数据仓库，对用户进行画像。像淘宝、天猫、京东这些大型电商平台，用户的所有活动都要进行追踪的。</p>
</li>
<li>
<p>日志收集如下图：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-2.png"
        data-srcset="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-2.png, https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-2.png 1.5x, https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-2.png 2x"
        data-sizes="auto"
        alt="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-2.png"
        title="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-2.png" /></p>
</li>
<li>
<p>限流削峰如下图：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-3.png"
        data-srcset="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-3.png, https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-3.png 1.5x, https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-3.png 2x"
        data-sizes="auto"
        alt="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-3.png"
        title="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-3.png" /></p>
<p>高吞吐率实现：Kafka 与其他 MQ 相比，最大的特点就是高吞吐率。为了增加存储能力，Kafka 将所有的消息都写入到了低速大容量的硬盘。按理说，这将导致性能损失，但实际上，Kafka 仍然可以保持超高的吞吐率，并且其性能并未受到影响。</p>
</li>
</ul>
<p>其主要采用如下方式实现了高吞吐率：</p>
<ul>
<li>顺序读写：Kafka 将消息写入到了分区 Partition 中，而分区中的消息又是顺序读写的。顺序读写要快于随机读写。</li>
<li>零拷贝：生产者、消费者对于 Kafka 中的消息是采用零拷贝实现的。</li>
<li>批量发送：Kafka 允许批量发送模式。</li>
<li>消息压缩：Kafka 允许对消息集合进行压缩。</li>
</ul>
<h2 id="kafka-的优点">Kafka 的优点</h2>
<ul>
<li>解耦：在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</li>
<li>冗余（副本）：有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的&quot;插入-获取-删除&quot;范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。</li>
<li>扩展性：因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。</li>
<li>灵活性&amp;峰值处理能力：在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</li>
<li>可恢复性：系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</li>
<li>顺序保证：在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。Kafka 保证一个 Partition 内的消息的有序性。</li>
<li>缓冲：在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行，写入队列的处理会尽可能的快速。该缓冲有助于控制和优化数据流经过系统的速度。</li>
<li>异步通信：很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</li>
</ul>
<h2 id="kafka-与其他-mq-对比">Kafka 与其他 MQ 对比</h2>
<ul>
<li>RabbitMQ：RabbitMQ 是使用 Erlang 编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP，SMTP，STOMP，也正因如此，它非常重量级，更适合于企业级的开发。同时实现了 Broker 构架，这意味着消息在发送给客户端时先在中心队列排队。对路由，负载均衡或者数据持久化都有很好的支持。</li>
<li>Redis：Redis 是一个基于 Key-Value 对的 NoSQL 数据库，开发维护很活跃。虽然它是一个 Key-Value 数据库存储系统，但它本身支持 MQ 功能，所以完全可以当做一个轻量级的队列服务来使用。对于 RabbitMQ 和 Redis 的入队和出队操作，各执行 100 万次，每 10 万次记录一次执行时间。测试数据分为 128Bytes、512Bytes、1K 和 10K 四个不同大小的数据。实验表明：入队时，当数据比较小时 Redis 的性能要高于 RabbitMQ，而如果数据大小超过了 10K，Redis 则慢的无法忍受；出队时，无论数据大小，Redis 都表现出非常好的性能，而 RabbitMQ 的出队性能则远低于 Redis。</li>
<li>ZeroMQ：ZeroMQ 号称最快的消息队列系统，尤其针对大吞吐量的需求场景。ZeroMQ 能够实现 RabbitMQ 不擅长的高级/复杂的队列，但是开发人员需要自己组合多种技术框架，技术上的复杂度是对这 MQ 能够应用成功的挑战。ZeroMQ 具有一个独特的非中间件的模式，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序将扮演这个服务器角色。你只需要简单的引用 ZeroMQ 程序库，可以使用 NuGet 安装，然后你就可以愉快的在应用程序之间发送消息了。但是 ZeroMQ 仅提供非持久性的队列，也就是说如果宕机，数据将会丢失。其中，Twitter 的 Storm 0.9.0 以前的版本中默认使用 ZeroMQ 作为数据流的传输（Storm 从 0.9 版本开始同时支持 ZeroMQ 和 Netty 作为传输模块）。</li>
<li>ActiveMQ：ActiveMQ 是 Apache 下的一个子项目。类似于 ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于 RabbitMQ，它少量代码就可以高效地实现高级应用场景。</li>
<li>Kafka/Jafka：Kafka 是 Apache 下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，而 Jafka 是在 Kafka 之上孵化而来的，即 Kafka 的一个升级版。</li>
</ul>
<p>Kafka 具有以下特性:</p>
<ul>
<li>快速持久化，可以在 O(1) 的系统开销下进行消息持久化。</li>
<li>高吞吐，在一台普通的服务器上既可以达到 10W/s 的吞吐速率。</li>
<li>完全的分布式系统，Broker、Producer、Consumer 都原生自动支持分布式，自动实现负载均衡。</li>
<li>支持 Hadoop 数据并行加载，对于像 Hadoop 的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。</li>
</ul>
<p>Kafka 通过 Hadoop 的并行加载机制统一了在线和离线的消息处理。Apache Kafka 相对于 ActiveMQ 是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。</p>
<p>Kafka 的几种重要角色如下：</p>
<ul>
<li>
<p>Kafka 作为存储系统：任何允许发布与使用无关的消息发布的消息队列都有效地充当了运行中消息的存储系统。Kafka 的不同之处在于它是一个非常好的存储系统。写入 Kafka 的数据将写入磁盘并进行复制以实现容错功能。Kafka 允许生产者等待确认，以便直到完全复制并确保即使写入服务器失败的情况下写入也不会完成。</p>
<p>Kafka 的磁盘结构可以很好地扩展使用-无论服务器上有 50KB 还是 50TB 的持久数据，Kafka 都将执行相同的操作。由于认真对待存储并允许客户端控制其读取位置，因此您可以将 Kafka 视为一种专用于高性能，低延迟提交日志存储，复制和传播的专用分布式文件系统。</p>
</li>
<li>
<p>Kafka 作为消息传递系统：Kafka 的流概念与传统的企业消息传递系统相比如何？传统上，消息传递具有两种模型：排队和发布订阅。在队列中，一组使用者可以从服务器中读取内容，并且每条记录都将转到其中一个。在发布-订阅记录中广播给所有消费者。这两个模型中的每一个都有优点和缺点。排队的优势在于，它允许您将数据处理划分到多个使用者实例上，从而扩展处理量。</p>
<p>不幸的是，队列不是多用户的—一次进程读取了丢失的数据。发布-订阅允许您将数据广播到多个进程，但是由于每条消息都传递给每个订阅者，因此无法扩展处理。Kafka 的消费者群体概念概括了这两个概念。与队列一样，使用者组允许您将处理划分为一组进程（使用者组的成员）。与发布订阅一样，Kafka 允许您将消息广播到多个消费者组。</p>
<p>Kafka 模型的优点在于，每个主题都具有这些属性-可以扩展处理范围，并且是多订阅者，无需选择其中一个。与传统的消息传递系统相比，Kafka 还具有更强的订购保证。传统队列将记录按顺序保留在服务器上，如果多个使用者从队列中消费，则服务器将按记录的存储顺序分发记录。但是，尽管服务器按顺序分发记录，但是这些记录是异步传递给使用者的，因此它们可能在不同的使用者上乱序到达。</p>
<p>这实际上意味着在并行使用的情况下会丢失记录的顺序。消息传递系统通常通过“专有使用者”的概念来解决此问题，该概念仅允许一个进程从队列中使用，但是，这当然意味着在处理中没有并行性。Kafka 做得更好，通过在主题内具有并行性（即分区）的概念，Kafka 能够在用户进程池中提供排序保证和负载均衡。</p>
<p>这是通过将主题中的分区分配给消费者组中的消费者来实现的，以便每个分区都由组中的一个消费者完全消费。通过这样做，我们确保使用者是该分区的唯一读取器，并按顺序使用数据。由于存在许多分区，因此仍然可以平衡许多使用者实例上的负载。但是请注意，使用者组中的使用者实例不能超过分区。</p>
</li>
<li>
<p>Kafka 用作流处理：仅读取，写入和存储数据流是不够的，目的是实现对流的实时处理。在 Kafka 中，流处理器是指从输入主题中获取连续数据流，对该输入进行一些处理并生成连续数据流以输出主题的任何东西。例如，零售应用程序可以接受销售和装运的输入流，并输出根据此数据计算出的重新订购和价格调整流。</p>
<p>可以直接使用生产者和消费者 API 进行简单处理。但是，对于更复杂的转换，Kafka 提供了完全集成的 Streams API。这允许构建执行非重要处理的应用程序，这些应用程序计算流的聚合或将流连接在一起。该功能有助于解决此类应用程序所面临的难题：处理无序数据，在代码更改时重新处理输入，执行状态计算等。</p>
<p>流 API 建立在 Kafka 提供的核心原语之上：它使用生产者和使用者 API 进行输入，使用 Kafka 进行状态存储，并使用相同的组机制来实现流处理器实例之间的容错。</p>
</li>
</ul>
<h2 id="kafka-中的关键术语解释">Kafka 中的关键术语解释</h2>
<p><strong>Topic：</strong> 主题。在 Kafka 中，使用一个类别属性来划分消息的所属类，划分消息的这个类称为 Topic。Topic 相当于消息的分类标签，是一个逻辑概念。物理上不同 Topic 的消息分开存储，逻辑上一个 Topic 的消息虽然保存于一个或多个 Broker 上但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数据存于何处。</p>
<p><strong>Partition：</strong> 分区。Topic 中的消息被分割为一个或多个 Partition，其是一个物理概念，对应到系统上 就是一个或若干个目录。Partition 内部的消息是有序的，但 Partition 间的消息是无序的。</p>
<p><strong>Segment 段:</strong> 将  Partition 进一步细分为了若干的 Segment，每个 Segment 文件的大小相等。</p>
<p><strong>Broker：</strong> Kafka 集群包含一个或多个服务器，每个服务器节点称为一个 Broker。Broker 存储 Topic 的数据。如果某 Topic 有 N 个 Partition，集群有 N 个 Broker，那么每个 Broker 存储该 Topic 的一个 Partition。</p>
<p>如果某 Topic 有 N 个 Partition，集群有（N+M）个 Broker，那么其中有 N 个 Broker 存储该 Topic 的一个 Partition，剩下的 M 个 Broker 不存储该 Topic 的 Partition 数据。如果某 Topic 有 N 个 Partition，集群中 Broker 数目少于 N 个，那么一个 Broker 存储该 Topic 的一个或多个 Partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致 Kafka 集群数据不均衡。</p>
<p><strong>Producer：</strong> 生产者。即消息的发布者，生产者将数据发布到他们选择的主题。生产者负责选择将哪个记录分配给主题中的哪个分区。即：生产者生产的一条消息，会被写入到某一个 Partition。</p>
<p><strong>Consumer：</strong> 消费者。可以从 Broker 中读取消息。一个消费者可以消费多个 Topic 的消息；一个消费者可以消费同一个 Topic 中的多个 Partition 中的消息；一个 Partiton 允许多个 Consumer 同时消费。</p>
<p><strong>Consumer Group：</strong> Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。组内可以有多个消费者，它们共享一个公共的 ID，即 Group ID。组内的所有消费者协调在一起来消费订阅主题 的所有分区。Kafka 保证同一个 Consumer Group 中只有一个 Consumer 会消费某条消息。</p>
<p>实际上，Kafka 保证的是稳定状态下每一个 Consumer 实例只会消费某一个或多个特定的 Partition，而某个 Partition 的数据只会被某一个特定的 Consumer 实例所消费。</p>
<p>下面我们用官网的一张图, 来标识 Consumer 数量和 Partition 数量的对应关系。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-4.jpg"
        data-srcset="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-4.jpg, https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-4.jpg 1.5x, https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-4.jpg 2x"
        data-sizes="auto"
        alt="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-4.jpg"
        title="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-4.jpg" /></p>
<p>由两台服务器组成的 Kafka 群集，其中包含四个带有两个使用者组的分区（P0-P3）。消费者组 A 有两个消费者实例，组 B 有四个。</p>
<p>对于这个消费组, 以前一直搞不明白, 我自己的总结是：Topic 中的 Partitoin 到 Group 是发布订阅的通信方式。</p>
<p>即一条 Topic 的 Partition 的消息会被所有的 Group 消费，属于一对多模式；Group 到 Consumer 是点对点通信方式，属于一对一模式。</p>
<p>举个例子：不使用 Group 的话，启动 10 个 Consumer 消费一个 Topic，这 10 个 Consumer 都能得到 Topic 的所有数据，相当于这个 Topic 中的任一条消息被消费 10 次。</p>
<p>使用 Group 的话，连接时带上 groupid，Topic 的消息会分发到 10 个 Consumer 上，每条消息只被消费 1 次。</p>
<p><strong>Replizcas of partition：</strong> 分区副本。副本是一个分区的备份，是为了防止消息丢失而创建的分区的备份。</p>
<p><strong>Partition Leader：</strong> 每个 Partition 有多个副本，其中有且仅有一个作为 Leader，Leader 是当前负责消息读写 的 Partition。即所有读写操作只能发生于 Leader 分区上。</p>
<p><strong>Partition Follower：</strong> 所有 Follower 都需要从 Leader 同步消息，Follower 与 Leader 始终保持消息同步。Leader 与 Follower 的关系是主备关系，而非主从关系。</p>
<p><strong>ISR：</strong></p>
<ul>
<li><strong>ISR，In-Sync Replicas</strong>，是指副本同步列表。ISR 列表是由 Leader 负责维护。</li>
<li><strong>AR，Assigned Replicas</strong>，指某个 Partition 的所有副本, 即已分配的副本列表。</li>
<li><strong>OSR，Outof-Sync Replicas</strong>，即非同步的副本列表。</li>
<li><strong>AR=ISR+OSR</strong></li>
</ul>
<p><strong>Offset：</strong> 偏移量。每条消息都有一个当前 Partition 下唯一的 64 字节的 Offset，它是相当于当前分区第一条消息的偏移量。</p>
<p><strong>Broker Controller：</strong> Kafka集群的多个 Broker 中，有一个会被选举 Controller，负责管理整个集群中 Partition 和 Replicas 的状态。</p>
<p>只有 Broker Controller 会向 Zookeeper 中注册 Watcher，其他 Broker 及分区无需注册。即 Zookeeper 仅需监听 Broker Controller 的状态变化即可。</p>
<p>HW 与 LEO：</p>
<ul>
<li><strong>HW，HighWatermark，高水位</strong>，表示 Consumer 可以消费到的最高 Partition 偏移量。HW 保证了 Kafka 集群中消息的一致性。确切地说，是保证了 Partition 的 Follower 与 Leader 间数 据的一致性。</li>
<li><strong>LEO，Log End Offset</strong>，日志最后消息的偏移量。消息是被写入到 Kafka 的日志文件中的， 这是当前最后一个写入的消息在 Partition 中的偏移量。</li>
<li>对于 Leader 新写入的消息，Consumer 是不能立刻消费的。Leader 会等待该消息被所有 ISR 中的 Partition Follower 同步后才会更新 HW，此时消息才能被 Consumer 消费。</li>
</ul>
<p>我相信你看完上面的概念还是懵逼的，好吧！下面我们就用图来形象话的表示两者的关系吧：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-6.png"
        data-srcset="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-6.png, https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-6.png 1.5x, https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-6.png 2x"
        data-sizes="auto"
        alt="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-6.png"
        title="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-6.png" /></p>
<p><strong>Zookeeper：</strong> Zookeeper 负责维护和协调 Broker，负责 Broker Controller 的选举。在 Kafka 0.9 之前版本，Offset 是由 ZK 负责管理的。</p>
<p>总结：ZK 负责 Controller 的选举，Controller 负责 Leader 的选举。</p>
<p><strong>Coordinator：</strong> 一般指的是运行在每个 Broker 上的 Group Coordinator 进程，用于管理 Consumer Group 中的各个成员，主要用于 Offset 位移管理和 Rebalance。一个 Coordinator 可以同时管理多个消费者组。</p>
<p><strong>Rebalance：</strong> 当消费者组中的数量发生变化，或者 Topic 中的 Partition 数量发生了变化时，Partition 的所有权会在消费者间转移，即 Partition 会重新分配，这个过程称为再均衡 Rebalance。</p>
<p>再均衡能够给消费者组及 Broker 带来高性能、高可用性和伸缩，但在再均衡期间消费者是无法读取消息的，即整个 Broker 集群有小一段时间是不可用的。因此要避免不必要的再均衡。</p>
<p><strong>Offset Commit：</strong> Consumer 从 Broker 中取一批消息写入 Buffer 进行消费，在规定的时间内消费完消息后，会自动将其消费消息的 Offset 提交给 Broker，以记录下哪些消息是消费过的。当然，若在时限内没有消费完毕，其是不会提交 Offset 的。</p>
<h2 id="kafka的工作原理和过程">Kafka的工作原理和过程</h2>
<h3 id="消息写入算法">消息写入算法</h3>
<p>消息发送者将消息发送给 Broker, 并形成最终的可供消费者消费的 log，是比较复杂的过程：</p>
<ul>
<li>Producer 先从 Zookeeper 中找到该 Partition 的 Leader。</li>
<li>Producer将消息发送给该 Leader。</li>
<li>Leader 将消息接入本地的 log，并通知 ISR 的 Followers。</li>
<li>ISR 中的 Followers 从 Leader 中 Pull 消息, 写入本地 log 后向 Leader 发送 Ack。</li>
<li>Leader 收到所有 ISR 中的 Followers 的 Ack 后，增加 HW 并向 Producer 发送 Ack，表示消息写入成功。</li>
</ul>
<h3 id="消息路由策略">消息路由策略</h3>
<p>在通过 API 方式发布消息时，生产者是以 Record 为消息进行发布的。</p>
<p>Record 中包含 Key 与 Value，Value 才是我们真正的消息本身，而 Key 用于路由消息所要存放的 Partition。</p>
<p>消息要写入到哪个 Partition 并不是随机的，而是有路由策略的：</p>
<ul>
<li>若指定了 Partition，则直接写入到指定的 Partition。</li>
<li>若未指定 Partition 但指定了 Key，则通过对 Key 的 Hash 值与 Partition 数量取模，该取模。</li>
<li>结果就是要选出的 Partition 索引。</li>
<li>若 Partition 和 Key 都未指定，则使用轮询算法选出一个 Partition。</li>
</ul>
<h3 id="hw-截断机制">HW 截断机制</h3>
<p>如果 Partition Leader 接收到了新的消息， ISR 中其它 Follower 正在同步过程中，还未同步完毕时 leader 宕机。</p>
<p>此时就需要选举出新的 Leader。若没有 HW 截断机制，将会导致 Partition 中 Leader 与 Follower 数据的不一致。</p>
<p>当原 Leader 宕机后又恢复时，将其 LEO 回退到其宕机时的 HW，然后再与新的 Leader 进行数据同步，这样就可以保证老 Leader 与新 Leader 中数据一致了，这种机制称为 HW 截断机制。</p>
<h3 id="消息发送的可靠性">消息发送的可靠性</h3>
<p>生产者向 Kafka 发送消息时，可以选择需要的可靠性级别。通过 request.required.acks 参数的值进行设置。
<strong>0 值：</strong> 异步发送。生产者向 Kafka 发送消息而不需要 Kafka 反馈成功 Ack。该方式效率最高，但可靠性最低。</p>
<blockquote>
<ul>
<li>其可能会存在消息丢失的情况：</li>
<li>在传输过程中会出现消息丢失。</li>
<li>在 Broker 内部会出现消息丢失。</li>
</ul>
</blockquote>
<p>会出现写入到 Kafka 中的消息的顺序与生产顺序不一致的情况。</p>
<p><strong>1 值：</strong> 同步发送。生产者发送消息给 Kafka，Broker 的 Partition Leader 在收到消息后马上发送成功 Ack（无需等等 ISR 中的 Follower 同步）。</p>
<p>生产者收到后知道消息发送成功，然后会再发送消息。如果一直未收到 Kafka 的 Ack，则生产者会认为消息发送失败，会重发消息。</p>
<p>该方式对于 Producer 来说，若没有收到 Ack，一定可以确认消息发送失败了，然后可以重发。</p>
<p>但是，即使收到了 ACK，也不能保证消息一定就发送成功了。故，这种情况，也可能会发生消息丢失的情况。</p>
<p><strong>-1 值：</strong> 同步发送。生产者发送消息给 Kafka，Kafka 收到消息后要等到 ISR 列表中的所有副本都 同步消息完成后，才向生产者发送成功 Ack。</p>
<p>如果一直未收到 Kafka 的 Ack，则认为消息发送 失败，会自动重发消息。该方式会出现消息重复接收的情况。</p>
<h3 id="消费者消费过程解析">消费者消费过程解析</h3>
<p>生产者将消息发送到 Topitc 中，消费者即可对其进行消费，其消费过程如下：</p>
<ul>
<li>Consumer 向 Broker 提交连接请求，其所连接上的 Broker 都会向其发送Broker Controller 的通信 URL，即配置文件中的 Listeners 地址。</li>
<li>当 Consumer 指定了要消费的 Topic 后，会向 Broker Controller 发送消费请求。</li>
<li>Broker Controller 会为 Consumer 分配一个或几个 Partition Leader，并将该 Partition 的当前 Offset 发送给 Consumer。</li>
<li>Consumer 会按照 Broker Controller 分配的 Partition 对其中的消息进行消费。</li>
<li>当 Consumer 消费完该条消息后，Consumer 会向 Broker 发送一个消息已经被消费反馈，即该消息的 Offset。</li>
<li>在 Broker 接收到 Consumer 的 Offset 后，会更新相应的 __consumer_offset 中。</li>
<li>以上过程会一直重复，知道消费者停止请求消费。</li>
<li>Consumer 可以重置 Offset，从而可以灵活消费存储在 Broker 上的消息。</li>
</ul>
<h3 id="partition-leader-选举范围">Partition Leader 选举范围</h3>
<p>当 Leader 宕机后，Broker Controller 会从 ISR 中挑选一个 Follower 成为新的 Leader。</p>
<p>如果 ISR 中没有其他副本怎么办？可以通过 unclean.leader.election.enable 的值来设置 Leader 选举范围。</p>
<p>False：必须等到 ISR 列表中所有的副本都活过来才进行新的选举。该策略可靠性有保证，但可用性低。</p>
<p>True：在 ISR 列表中没有副本的情况下，可以选择任意一个没有宕机的主机作为新的 Leader，该策略可用性高，但可靠性没有保证。</p>
<h3 id="重复消费问题的解决方案">重复消费问题的解决方案</h3>
<p>同一个 Consumer 重复消费：当 Consumer 由于消费能力低而引发了消费超时，则可能会形成重复消费。</p>
<p>在某数据刚好消费完毕，但是正准备提交 Offset 时候，消费时间超时，则 Broker 认为这条消息未消费成功。这时就会产生重复消费问题。其解决方案：延长 Offset 提交时间。</p>
<p>不同的 Consumer 重复消费：当 Consumer 消费了消息，但还没有提交 Offset 时宕机，则这些已经被消费过的消息会被重复消费。其解决方案：将自动提交改为手动提交。</p>
<h3 id="从架构设计上解决-kafka-重复消费的问题">从架构设计上解决 Kafka 重复消费的问题</h3>
<p>我们在设计程序的时候，比如考虑到网络故障等一些异常的情况，我们都会设置消息的重试次数，可能还有其他可能出现消息重复，那我们应该如何解决呢？下面提供三个方案：</p>
<h4 id="保存并查询">保存并查询</h4>
<p>给每个消息都设置一个独一无二的 uuid，所有的消息，我们都要存一个 uuid。</p>
<p>我们在消费消息的时候，首先去持久化系统中查询一下看这个看是否以前消费过，如没有消费过，在进行消费，如果已经消费过，丢弃就好了。</p>
<p>下图表明了这种方案：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-7.png"
        data-srcset="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-7.png, https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-7.png 1.5x, https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-7.png 2x"
        data-sizes="auto"
        alt="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-7.png"
        title="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-7.png" /></p>
<h4 id="利用幂等">利用幂等</h4>
<p>幂等（Idempotence）在数学上是这样定义的，如果一个函数 f(x) 满足：f(f(x)) = f(x)，则函数 f(x) 满足幂等性。</p>
<p>这个概念被拓展到计算机领域，被用来描述一个操作、方法或者服务。一个幂等操作的特点是，其任意多次执行所产生的影响均与一次执行的影响相同。</p>
<p>一个幂等的方法，使用同样的参数，对它进行多次调用和一次调用，对系统产生的影响是一样的。所以，对于幂等的方法，不用担心重复执行会对系统造成任何改变。</p>
<p>我们举个例子来说明一下。在不考虑并发的情况下，“将 X 老师的账户余额设置为 100 万元”，执行一次后对系统的影响是，X 老师的账户余额变成了 100 万元。只要提供的参数 100 万元不变，那即使再执行多少次，X 老师的账户余额始终都是 100 万元，不会变化，这个操作就是一个幂等的操作。</p>
<p>再举一个例子，“将 X 老师的余额加 100 万元”，这个操作它就不是幂等的，每执行一次，账户余额就会增加 100 万元，执行多次和执行一次对系统的影响（也就是账户的余额）是不一样的。</p>
<p>所以，通过这两个例子，我们可以想到如果系统消费消息的业务逻辑具备幂等性，那就不用担心消息重复的问题了，因为同一条消息，消费一次和消费多次对系统的影响是完全一样的。也就可以认为，消费多次等于消费一次。</p>
<p>那么，如何实现幂等操作呢？最好的方式就是，从业务逻辑设计上入手，将消费的业务逻辑设计成具备幂等性的操作。</p>
<p>但是，不是所有的业务都能设计成天然幂等的，这里就需要一些方法和技巧来实现幂等。</p>
<p>下面我们介绍一种常用的方法：利用数据库的唯一约束实现幂等。</p>
<p>例如，我们刚刚提到的那个不具备幂等特性的转账的例子：将 X 老师的账户余额加 100 万元。在这个例子中，我们可以通过改造业务逻辑，让它具备幂等性。</p>
<p>首先，我们可以限定，对于每个转账单每个账户只可以执行一次变更操作，在分布式系统中，这个限制实现的方法非常多，最简单的是我们在数据库中建一张转账流水表。</p>
<p>这个表有三个字段：转账单 ID、账户 ID 和变更金额，然后给转账单 ID 和账户 ID 这两个字段联合起来创建一个唯一约束，这样对于相同的转账单 ID 和账户 ID，表里至多只能存在一条记录。</p>
<p>这样，我们消费消息的逻辑可以变为：“在转账流水表中增加一条转账记录，然后再根据转账记录，异步操作更新用户余额即可。”</p>
<p>在转账流水表增加一条转账记录这个操作中，由于我们在这个表中预先定义了“账户 ID 转账单 ID”的唯一约束，对于同一个转账单同一个账户只能插入一条记录，后续重复的插入操作都会失败，这样就实现了一个幂等的操作。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-8.png"
        data-srcset="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-8.png, https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-8.png 1.5x, https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-8.png 2x"
        data-sizes="auto"
        alt="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-8.png"
        title="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-8.png" /></p>
<h4 id="设置前提条件">设置前提条件</h4>
<p>为更新的数据设置前置条件另外一种实现幂等的思路是，给数据变更设置一个前置条件，如果满足条件就更新数据，否则拒绝更新数据，在更新数据的时候，同时变更前置条件中需要判断的数据。</p>
<p>这样，重复执行这个操作时，由于第一次更新数据的时候已经变更了前置条件中需要判断的数据，不满足前置条件，则不会重复执行更新数据操作。</p>
<p>比如，刚刚我们说过，“将 X 老师的账户的余额增加 100 万元”这个操作并不满足幂等性，我们可以把这个操作加上一个前置条件，变为：“如果 X 老师的账户当前的余额为 500 万元，将余额加 100 万元”，这个操作就具备了幂等性。</p>
<p>对应到消息队列中的使用时，可以在发消息时在消息体中带上当前的余额，在消费的时候进行判断数据库中，当前余额是否与消息中的余额相等，只有相等才执行变更操作。</p>
<p>但是，如果我们要更新的数据不是数值，或者我们要做一个比较复杂的更新操作怎么办？用什么作为前置判断条件呢？</p>
<p>更加通用的方法是，给你的数据增加一个版本号属性，每次更数据前，比较当前数据的版本号是否和消息中的版本号一致，如果不一致就拒绝更新数据，更新数据的同时将版本号 +1，一样可以实现幂等。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-9.png"
        data-srcset="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-9.png, https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-9.png 1.5x, https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-9.png 2x"
        data-sizes="auto"
        alt="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-9.png"
        title="https://gitee.com/russellgao/blogs-image/raw/master/images/mq/kafka-9.png" /></p>
<p>我们在工作中，为了保证环境的高可用，防止单点，Kafka 都是以集群的方式出现的，下面就带领大家一起搭建一套 Kafka 集群环境。</p>
<p>我们在官网下载 Kafka，下载地址为：http://kafka.apache.org/downloads，下载我们需要的版本，推荐使用稳定的版本。</p>
<h2 id="搭建集群">搭建集群</h2>
<p>下载并解压：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">cd</span> /usr/local/src
wget http://mirrors.tuna.tsinghua.edu.cn/apache/kafka/2.4.0/kafka_2.11-2.4.0.tgz
mkdir /data/servers
tar xzvf kafka_2.11-2.4.0.tgz -C /data/servers/
<span class="nb">cd</span> /data/servers/kafka_2.11-2.4.0
</code></pre></td></tr></table>
</div>
</div><p>修改配置文件：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">确保每个机器上的 id 不一样
 broker.id<span class="o">=</span><span class="m">0</span>
  配置服务端的监控地址
 <span class="nv">listeners</span><span class="o">=</span>PLAINTEXT://192.168.51.128:9092
  Kafka 日志目录
 log.dirs<span class="o">=</span>/data/servers/kafka_2.11-2.4.0/logs
 <span class="c1">#Kafka 设置的 partitons 的个数</span>
 num.partitions<span class="o">=</span><span class="m">1</span>

  ZooKeeper 的连接地址，如果有自己的 ZooKeeper 集群，请直接使用自己搭建的 ZooKeeper 集群
 zookeeper.connect<span class="o">=</span>192.168.51.128:2181
</code></pre></td></tr></table>
</div>
</div><p>因为我自己是本机做实验，所有使用的是一个主机的不同端口，在线上，就是不同的机器，大家参考即可。</p>
<p>我们这里使用 Kafka 的 ZooKeeper，只启动一个节点，但是正真的生产过程中，是需要 ZooKeeper 集群，自己搭建就好，后期我们也会出 ZooKeeper 的教程，大家请关注就好了。</p>
<p>拷贝 3 份配置文件：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1">#创建对应的日志目录</span>
mkdir -p /data/servers/kafka_2.11-2.4.0/logs/9092
mkdir -p /data/servers/kafka_2.11-2.4.0/logs/9093
mkdir -p /data/servers/kafka_2.11-2.4.0/logs/9094

<span class="c1">#拷贝三份配置文件</span>
cp server.properties server_9092.properties 
cp server.properties server_9093.properties 
cp server.properties server_9094.properties
</code></pre></td></tr></table>
</div>
</div><p>修改不同端口对应的文件：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1">#9092 的 id 为 0，9093 的 id 为 1，9094 的 id 为 2</span>
 broker.id<span class="o">=</span><span class="m">0</span>
<span class="c1"># 配置服务端的监控地址，在不通的配置文件中写入不同的端口</span>
 <span class="nv">listeners</span><span class="o">=</span>PLAINTEXT://192.168.51.128:9092
<span class="c1"># Kafka 日志目录，目录也是对应不同的端口</span>
 log.dirs<span class="o">=</span>/data/servers/kafka_2.11-2.4.0/logs/9092
<span class="c1"># Kafka 设置的 partitons 的个数</span>
 num.partitions<span class="o">=</span><span class="m">1</span>
<span class="c1"># ZooKeeper 的连接地址，如果有自己的 ZooKeeper 集群，请直接使用自己搭建的 ZooKeeper 集群</span>
 zookeeper.connect<span class="o">=</span>192.168.51.128:2181
</code></pre></td></tr></table>
</div>
</div><p>修改 ZooKeeper 的配置文件：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="nv">dataDir</span><span class="o">=</span>/data/servers/zookeeper
server.1<span class="o">=</span>192.168.51.128:2888:3888
</code></pre></td></tr></table>
</div>
</div><p>然后创建 ZooKeeper 的 myid 文件：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">echo</span> <span class="s2">&#34;1&#34;</span>&gt; /data/servers/zookeeper/myid
</code></pre></td></tr></table>
</div>
</div><p>启动 ZooKeeper：</p>
<p>使用 Kafka 内置的 ZooKeeper：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">cd</span> /data/servers/kafka_2.11-2.4.0/bin
zookeeper-server-start.sh -daemon ../config/zookeeper.properties 
netstat -anp <span class="p">|</span>grep <span class="m">2181</span>
</code></pre></td></tr></table>
</div>
</div><p>启动 Kafka：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">./kafka-server-start.sh -daemon ../config/server_9092.properties   
./kafka-server-start.sh -daemon ../config/server_9093.properties   
./kafka-server-start.sh -daemon ../config/server_9094.properties
</code></pre></td></tr></table>
</div>
</div><h2 id="kafka-的操作">Kafka 的操作</h2>
<h3 id="topic">topic</h3>
<p>我们先来看一下创建 Topic 常用的参数吧：</p>
<ul>
<li>&ndash;create：创建 topic</li>
<li>&ndash;delete：删除 topic</li>
<li>&ndash;alter：修改 topic 的名字或者 partition 个数</li>
<li>&ndash;list：查看 topic</li>
<li>&ndash;describe：查看 topic 的详细信息</li>
<li>&ndash;topic &lt;String: topic&gt;：指定 topic 的名字</li>
<li>&ndash;zookeeper &lt;String: hosts&gt;：指定 Zookeeper 的连接地址参数提示并不赞成这样使用（DEPRECATED, The connection string for the zookeeper connection in the form host:port. Multiple hosts can be given to allow fail-over.）</li>
<li>&ndash;bootstrap-server &lt;String: server to connect to&gt;：指定 Kafka 的连接地址，推荐使用这个，参数的提示信息显示（REQUIRED: The Kafka server to connect to. In case of providing this, a direct Zookeeper connection won&rsquo;t be required.）。</li>
<li>&ndash;replication-factor &lt;Integer: replication factor&gt;：对于每个 Partiton 的备份个数。（The replication factor for each partition in the topic being created. If not supplied, defaults to the cluster default.）</li>
<li>&ndash;partitions &lt;Integer: # of partitions&gt;：指定该 topic 的分区的个数。</li>
</ul>
<p>示例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">cd</span> /data/servers/kafka_2.11-2.4.0/bin
<span class="c1"># 创建 topic  test1</span>
kafka-topics.sh --create --bootstrap-server<span class="o">=</span>192.168.51.128:9092,10.231.128.96:9093,192.168.51.128:9094 --replication-factor <span class="m">1</span> --partitions <span class="m">1</span> --topic test1
<span class="c1"># 创建 topic test2</span>
kafka-topics.sh --create --bootstrap-server<span class="o">=</span>192.168.51.128:9092,10.231.128.96:9093,192.168.51.128:9094 --replication-factor <span class="m">1</span> --partitions <span class="m">1</span> --topic test2
<span class="c1"># 查看 topic</span>
kafka-topics.sh --list --bootstrap-server<span class="o">=</span>192.168.51.128:9092,10.231.128.96:9093,192.168.51.128:9094
</code></pre></td></tr></table>
</div>
</div><p>自动创建 Topic</p>
<p>我们在工作中，如果我们不想去管理 Topic，可以通过 Kafka 的配置文件来管理。</p>
<p>我们可以让 Kafka 自动创建 Topic，需要在我们的 Kafka 配置文件中加入如下配置文件：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">auto.create.topics.enable<span class="o">=</span><span class="nb">true</span>

</code></pre></td></tr></table>
</div>
</div><p>如果删除 Topic 想达到物理删除的目的，也是需要配置的：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">delete.topic.enable<span class="o">=</span><span class="nb">true</span>

</code></pre></td></tr></table>
</div>
</div><h3 id="发送消息">发送消息</h3>
<p>他们可以通过客户端的命令生产消息，先来看看 kafka-console-producer.sh 常用的几个参数吧：</p>
<ul>
<li>&ndash;topic &lt;String: topic&gt;：指定 topic</li>
<li>&ndash;timeout &lt;Integer: timeout_ms&gt;：超时时间</li>
<li>&ndash;sync：异步发送消息</li>
<li>&ndash;broker-list &lt;String: broker-list&gt;：官网提示：REQUIRED: The broker list string in the form HOST1:PORT1,HOST2:PORT2.</li>
</ul>
<p>这个参数是必须的：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">kafka-console-producer.sh --broker-list 192.168.51.128:9092,192.168.51.128:9093,192.168.51.128:9094 --topic test1
</code></pre></td></tr></table>
</div>
</div><h3 id="消费消息">消费消息</h3>
<p>我们也还是先来看看 kafka-console-consumer.sh 的参数吧：</p>
<ul>
<li>&ndash;topic &lt;String: topic&gt;：指定 topic</li>
<li>&ndash;group &lt;String: consumer group id&gt;：指定消费者组</li>
<li>&ndash;from-beginning：指定从开始进行消费, 如果不指定, 就从当前进行消费</li>
<li>&ndash;bootstrap-server：Kafka 的连接地址‍‍</li>
</ul>
<h3 id="kafka-的日志">Kafka 的日志</h3>
<p>Kafka 的日志分两种：</p>
<ul>
<li>第一种日志是我们的 Kafka 的启动日志，就是我们排查问题，查看报错信息的日志。</li>
<li>第二种日志就是我们的数据日志，Kafka 是我们的数据是以日志的形式存在存盘中的，我们第二种所说的日志就是我们的 Partiton 与 Segment。</li>
</ul>
<p>那我们就来说说备份和分区吧：我们创建一个分区，一个备份，那么 test 就应该在三台机器上或者三个数据目录只有一个 test-0。（分区的下标是从 0 开始的）</p>
<p>如果我们创建 N 个分区，我们就会在三个服务器上发现，test_0-n，如果我们创建 M 个备份，我们就会在发现，test_0 到 test_n 每一个都是 M 个。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">kafka-console-consumer.sh --bootstrap-server 192.168.51.128:9092,192.168.51.128:9093,192.168.51.128:9094 --topic test1 ---beginning
</code></pre></td></tr></table>
</div>
</div><h2 id="kafka-api">Kafka API</h2>
<p>使用 Kafka 原生的 API</p>
<h3 id="消费者自动提交">消费者自动提交</h3>
<p>定义自己的生产者：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.kafka.clients.producer.Callback</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.producer.KafkaProducer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.producer.ProducerRecord</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.producer.RecordMetadata</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">java.util.Properties</span><span class="o">;</span>

<span class="cm">/**
</span><span class="cm"> * @ClassName MyKafkaProducer
</span><span class="cm"> * @Description TODO
</span><span class="cm"> * @Author lingxiangxiang
</span><span class="cm"> * @Date 3:37 PM
</span><span class="cm"> * @Version 1.0
</span><span class="cm"> **/</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyKafkaProducer</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">kafka</span><span class="o">.</span><span class="na">clients</span><span class="o">.</span><span class="na">producer</span><span class="o">.</span><span class="na">KafkaProducer</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">producer</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">MyKafkaProducer</span><span class="o">()</span> <span class="o">{</span>
        <span class="n">Properties</span> <span class="n">properties</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Properties</span><span class="o">();</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;bootstrap.servers&#34;</span><span class="o">,</span> <span class="s">&#34;192.168.51.128:9092,192.168.51.128:9093,192.168.51.128:9094&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;key.serializer&#34;</span><span class="o">,</span> <span class="s">&#34;org.apache.kafka.common.serialization.IntegerSerializer&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;value.serializer&#34;</span><span class="o">,</span> <span class="s">&#34;org.apache.kafka.common.serialization.StringSerializer&#34;</span><span class="o">);</span>
        <span class="c1">// 设置批量发送
</span><span class="c1"></span>        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;batch.size&#34;</span><span class="o">,</span> <span class="n">16384</span><span class="o">);</span>
        <span class="c1">// 批量发送的等待时间 50ms, 超过 50ms, 不足批量大小也发送
</span><span class="c1"></span>        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;linger.ms&#34;</span><span class="o">,</span> <span class="n">50</span><span class="o">);</span>
        <span class="k">this</span><span class="o">.</span><span class="na">producer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">kafka</span><span class="o">.</span><span class="na">clients</span><span class="o">.</span><span class="na">producer</span><span class="o">.</span><span class="na">KafkaProducer</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;(</span><span class="n">properties</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">sendMsg</span><span class="o">()</span> <span class="o">{</span>
        <span class="kt">boolean</span> <span class="n">result</span> <span class="o">=</span> <span class="kc">true</span><span class="o">;</span>
        <span class="k">try</span> <span class="o">{</span>
            <span class="c1">// 正常发送, test2 是 topic, 0 代表的是分区, 1 代表的是 key, hello world 是发送的消息内容
</span><span class="c1"></span>            <span class="kd">final</span> <span class="n">ProducerRecord</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">record</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ProducerRecord</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;(</span><span class="s">&#34;test2&#34;</span><span class="o">,</span> <span class="n">0</span><span class="o">,</span> <span class="n">1</span><span class="o">,</span> <span class="s">&#34;hello world&#34;</span><span class="o">);</span>
            <span class="n">producer</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="n">record</span><span class="o">);</span>
            <span class="c1">// 有回调函数的调用
</span><span class="c1"></span>            <span class="n">producer</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="n">record</span><span class="o">,</span> <span class="k">new</span> <span class="n">Callback</span><span class="o">()</span> <span class="o">{</span>
                <span class="nd">@Override</span>
                <span class="kd">public</span> <span class="kt">void</span> <span class="nf">onCompletion</span><span class="o">(</span><span class="n">RecordMetadata</span> <span class="n">recordMetadata</span><span class="o">,</span> <span class="n">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
                    <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">recordMetadata</span><span class="o">.</span><span class="na">topic</span><span class="o">());</span>
                    <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">recordMetadata</span><span class="o">.</span><span class="na">partition</span><span class="o">());</span>
                    <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">recordMetadata</span><span class="o">.</span><span class="na">offset</span><span class="o">());</span>
                <span class="o">}</span>
            <span class="o">});</span>
          <span class="c1">// 自己定义一个类
</span><span class="c1"></span>            <span class="n">producer</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="n">record</span><span class="o">,</span> <span class="k">new</span> <span class="n">MyCallback</span><span class="o">(</span><span class="n">record</span><span class="o">));</span>
        <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="n">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">result</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
        <span class="o">}</span>
        <span class="k">return</span> <span class="n">result</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></td></tr></table>
</div>
</div><p>定义生产者发送成功的回调函数：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.kafka.clients.producer.Callback</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.producer.RecordMetadata</span><span class="o">;</span>

<span class="cm">/**
</span><span class="cm"> * @ClassName MyCallback
</span><span class="cm"> * @Description TODO
</span><span class="cm"> * @Author lingxiangxiang
</span><span class="cm"> * @Date 3:51 PM
</span><span class="cm"> * @Version 1.0
</span><span class="cm"> **/</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyCallback</span> <span class="kd">implements</span> <span class="n">Callback</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="n">Object</span> <span class="n">msg</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">MyCallback</span><span class="o">(</span><span class="n">Object</span> <span class="n">msg</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">msg</span> <span class="o">=</span> <span class="n">msg</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">onCompletion</span><span class="o">(</span><span class="n">RecordMetadata</span> <span class="n">metadata</span><span class="o">,</span> <span class="n">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;topic = &#34;</span> <span class="o">+</span> <span class="n">metadata</span><span class="o">.</span><span class="na">topic</span><span class="o">());</span>
        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;partiton = &#34;</span> <span class="o">+</span> <span class="n">metadata</span><span class="o">.</span><span class="na">partition</span><span class="o">());</span>
        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;offset = &#34;</span> <span class="o">+</span> <span class="n">metadata</span><span class="o">.</span><span class="na">offset</span><span class="o">());</span>
        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">msg</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></td></tr></table>
</div>
</div><p>生产者测试类：在生产者测试类中，自己遇到一个坑，就是最后自己没有加 sleep，就是怎么检查自己的代码都没有问题，但是最后就是没法发送成功消息，最后加了一个 sleep 就可以了。</p>
<p>因为主函数 main 已经执行完退出，但是消息并没有发送完成，需要进行等待一下。当然，你在生产环境中可能不会遇到这样问题，呵呵！</p>
<p>代码如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import static</span> <span class="nn">java.lang.Thread.sleep</span><span class="o">;</span>

<span class="cm">/**
</span><span class="cm"> * @ClassName MyKafkaProducerTest
</span><span class="cm"> * @Description TODO
</span><span class="cm"> * @Author lingxiangxiang
</span><span class="cm"> * @Date 3:46 PM
</span><span class="cm"> * @Version 1.0
</span><span class="cm"> **/</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyKafkaProducerTest</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">InterruptedException</span> <span class="o">{</span>
        <span class="n">MyKafkaProducer</span> <span class="n">producer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MyKafkaProducer</span><span class="o">();</span>
        <span class="kt">boolean</span> <span class="n">result</span> <span class="o">=</span> <span class="n">producer</span><span class="o">.</span><span class="na">sendMsg</span><span class="o">();</span>
        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;send msg &#34;</span> <span class="o">+</span> <span class="n">result</span><span class="o">);</span>
        <span class="n">sleep</span><span class="o">(</span><span class="n">1000</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></td></tr></table>
</div>
</div><p>消费者类：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">kafka.utils.ShutdownableThread</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.consumer.ConsumerRecord</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.consumer.ConsumerRecords</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.consumer.KafkaConsumer</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.Collections</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.Properties</span><span class="o">;</span>

<span class="cm">/**
</span><span class="cm"> * @ClassName MyKafkaConsumer
</span><span class="cm"> * @Description TODO
</span><span class="cm"> * @Author lingxiangxiang
</span><span class="cm"> * @Date 4:12 PM
</span><span class="cm"> * @Version 1.0
</span><span class="cm"> **/</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyKafkaConsumer</span> <span class="kd">extends</span> <span class="n">ShutdownableThread</span> <span class="o">{</span>

    <span class="kd">private</span> <span class="n">KafkaConsumer</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">consumer</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">MyKafkaConsumer</span><span class="o">()</span> <span class="o">{</span>
        <span class="kd">super</span><span class="o">(</span><span class="s">&#34;KafkaConsumerTest&#34;</span><span class="o">,</span> <span class="kc">false</span><span class="o">);</span>
        <span class="n">Properties</span> <span class="n">properties</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Properties</span><span class="o">();</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;bootstrap.servers&#34;</span><span class="o">,</span> <span class="s">&#34;192.168.51.128:9092,192.168.51.128:9093,192.168.51.128:9094&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;group.id&#34;</span><span class="o">,</span> <span class="s">&#34;mygroup&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;enable.auto.commit&#34;</span><span class="o">,</span> <span class="s">&#34;true&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;auto.commit.interval.ms&#34;</span><span class="o">,</span> <span class="s">&#34;1000&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;session.timeout.ms&#34;</span><span class="o">,</span> <span class="s">&#34;30000&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;heartbeat.interval.ms&#34;</span><span class="o">,</span> <span class="s">&#34;10000&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;auto.offset.reset&#34;</span><span class="o">,</span> <span class="s">&#34;earliest&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;key.deserializer&#34;</span><span class="o">,</span> <span class="s">&#34;org.apache.kafka.common.serialization.IntegerDeserializer&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;value.deserializer&#34;</span><span class="o">,</span> <span class="s">&#34;org.apache.kafka.common.serialization.StringDeserializer&#34;</span><span class="o">);</span>
        <span class="k">this</span><span class="o">.</span><span class="na">consumer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">KafkaConsumer</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;(</span><span class="n">properties</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">doWork</span><span class="o">()</span> <span class="o">{</span>
        <span class="n">consumer</span><span class="o">.</span><span class="na">subscribe</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&#34;test2&#34;</span><span class="o">));</span>
        <span class="n">ConsumerRecords</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span><span class="n">records</span> <span class="o">=</span> <span class="n">consumer</span><span class="o">.</span><span class="na">poll</span><span class="o">(</span><span class="n">1000</span><span class="o">);</span>
        <span class="k">for</span> <span class="o">(</span><span class="n">ConsumerRecord</span> <span class="n">record</span> <span class="o">:</span> <span class="n">records</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;topic = &#34;</span> <span class="o">+</span> <span class="n">record</span><span class="o">.</span><span class="na">topic</span><span class="o">());</span>
            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;partition = &#34;</span> <span class="o">+</span> <span class="n">record</span><span class="o">.</span><span class="na">partition</span><span class="o">());</span>
            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;key = &#34;</span> <span class="o">+</span> <span class="n">record</span><span class="o">.</span><span class="na">key</span><span class="o">());</span>
            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;value = &#34;</span> <span class="o">+</span> <span class="n">record</span><span class="o">.</span><span class="na">value</span><span class="o">());</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></td></tr></table>
</div>
</div><p>消费者的测试类：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="cm">/**
</span><span class="cm"> * @ClassName MyConsumerTest
</span><span class="cm"> * @Description TODO
</span><span class="cm"> * @Author lingxiangxiang
</span><span class="cm"> * @Date 4:23 PM
</span><span class="cm"> * @Version 1.0
</span><span class="cm"> **/</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyConsumerTest</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">MyKafkaConsumer</span> <span class="n">consumer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MyKafkaConsumer</span><span class="o">();</span>
        <span class="n">consumer</span><span class="o">.</span><span class="na">start</span><span class="o">();</span>
        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;==================&#34;</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="消费者同步手动提交">消费者同步手动提交</h3>
<p>前面的消费者都是以自动提交 Offset 的方式对 Broker 中的消息进行消费的，但自动提交 可能会出现消息重复消费的情况。</p>
<p>所以在生产环境下，很多时候需要对 Offset 进行手动提交， 以解决重复消费的问题。</p>
<p>手动提交又可以划分为同步提交、异步提交，同异步联合提交。这些提交方式仅仅是 doWork() 方法不相同，其构造器是相同的。</p>
<p>所以下面首先在前面消费者类的基础上进行构造器的修改，然后再分别实现三种不同的提交方式。</p>
<p>同步提交方式是，消费者向 Broker 提交 Offset 后等待 Broker 成功响应。若没有收到响应，则会重新提交，直到获取到响应。</p>
<p>而在这个等待过程中，消费者是阻塞的。其严重影响了消费者的吞吐量。</p>
<p>修改前面的 MyKafkaConsumer.java, 主要修改下面的配置：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">kafka.utils.ShutdownableThread</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.consumer.ConsumerRecord</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.consumer.ConsumerRecords</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.consumer.KafkaConsumer</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.Collections</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.Properties</span><span class="o">;</span>

<span class="cm">/**
</span><span class="cm"> * @ClassName MyKafkaConsumer
</span><span class="cm"> * @Description TODO
</span><span class="cm"> * @Author lingxiangxiang
</span><span class="cm"> * @Date 4:12 PM
</span><span class="cm"> * @Version 1.0
</span><span class="cm"> **/</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyKafkaConsumer</span> <span class="kd">extends</span> <span class="n">ShutdownableThread</span> <span class="o">{</span>

    <span class="kd">private</span> <span class="n">KafkaConsumer</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">consumer</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">MyKafkaConsumer</span><span class="o">()</span> <span class="o">{</span>
        <span class="kd">super</span><span class="o">(</span><span class="s">&#34;KafkaConsumerTest&#34;</span><span class="o">,</span> <span class="kc">false</span><span class="o">);</span>
        <span class="n">Properties</span> <span class="n">properties</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Properties</span><span class="o">();</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;bootstrap.servers&#34;</span><span class="o">,</span> <span class="s">&#34;192.168.51.128:9092,192.168.51.128:9093,192.168.51.128:9094&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;group.id&#34;</span><span class="o">,</span> <span class="s">&#34;mygroup&#34;</span><span class="o">);</span>
      <span class="c1">// 这里要修改成手动提交
</span><span class="c1"></span>        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;enable.auto.commit&#34;</span><span class="o">,</span> <span class="s">&#34;false&#34;</span><span class="o">);</span>
        <span class="c1">// properties.put(&#34;auto.commit.interval.ms&#34;, &#34;1000&#34;);
</span><span class="c1"></span>        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;session.timeout.ms&#34;</span><span class="o">,</span> <span class="s">&#34;30000&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;heartbeat.interval.ms&#34;</span><span class="o">,</span> <span class="s">&#34;10000&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;auto.offset.reset&#34;</span><span class="o">,</span> <span class="s">&#34;earliest&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;key.deserializer&#34;</span><span class="o">,</span> <span class="s">&#34;org.apache.kafka.common.serialization.IntegerDeserializer&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;value.deserializer&#34;</span><span class="o">,</span> <span class="s">&#34;org.apache.kafka.common.serialization.StringDeserializer&#34;</span><span class="o">);</span>
        <span class="k">this</span><span class="o">.</span><span class="na">consumer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">KafkaConsumer</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;(</span><span class="n">properties</span><span class="o">);</span>
    <span class="o">}</span>
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">doWork</span><span class="o">()</span> <span class="o">{</span>
        <span class="n">consumer</span><span class="o">.</span><span class="na">subscribe</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&#34;test2&#34;</span><span class="o">));</span>
        <span class="n">ConsumerRecords</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span><span class="n">records</span> <span class="o">=</span> <span class="n">consumer</span><span class="o">.</span><span class="na">poll</span><span class="o">(</span><span class="n">1000</span><span class="o">);</span>
        <span class="k">for</span> <span class="o">(</span><span class="n">ConsumerRecord</span> <span class="n">record</span> <span class="o">:</span> <span class="n">records</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;topic = &#34;</span> <span class="o">+</span> <span class="n">record</span><span class="o">.</span><span class="na">topic</span><span class="o">());</span>
            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;partition = &#34;</span> <span class="o">+</span> <span class="n">record</span><span class="o">.</span><span class="na">partition</span><span class="o">());</span>
            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;key = &#34;</span> <span class="o">+</span> <span class="n">record</span><span class="o">.</span><span class="na">key</span><span class="o">());</span>
            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;value = &#34;</span> <span class="o">+</span> <span class="n">record</span><span class="o">.</span><span class="na">value</span><span class="o">());</span>

          <span class="c1">//手动同步提交
</span><span class="c1"></span>          <span class="n">consumer</span><span class="o">.</span><span class="na">commitSync</span><span class="o">();</span>
        <span class="o">}</span>

    <span class="o">}</span>
<span class="o">}</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="消费者异步手工提交">消费者异步手工提交</h3>
<p>手动同步提交方式需要等待 Broker 的成功响应，效率太低，影响消费者的吞吐量。</p>
<p>异步提交方式是，消费者向 Broker 提交 Offset 后不用等待成功响应，所以其增加了消费者的吞吐量。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">kafka.utils.ShutdownableThread</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.consumer.ConsumerRecord</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.consumer.ConsumerRecords</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.consumer.KafkaConsumer</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.Collections</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.Properties</span><span class="o">;</span>

<span class="cm">/**
</span><span class="cm"> * @ClassName MyKafkaConsumer
</span><span class="cm"> * @Description TODO
</span><span class="cm"> * @Author lingxiangxiang
</span><span class="cm"> * @Date 4:12 PM
</span><span class="cm"> * @Version 1.0
</span><span class="cm"> **/</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyKafkaConsumer</span> <span class="kd">extends</span> <span class="n">ShutdownableThread</span> <span class="o">{</span>

    <span class="kd">private</span> <span class="n">KafkaConsumer</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">consumer</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">MyKafkaConsumer</span><span class="o">()</span> <span class="o">{</span>
        <span class="kd">super</span><span class="o">(</span><span class="s">&#34;KafkaConsumerTest&#34;</span><span class="o">,</span> <span class="kc">false</span><span class="o">);</span>
        <span class="n">Properties</span> <span class="n">properties</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Properties</span><span class="o">();</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;bootstrap.servers&#34;</span><span class="o">,</span> <span class="s">&#34;192.168.51.128:9092,192.168.51.128:9093,192.168.51.128:9094&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;group.id&#34;</span><span class="o">,</span> <span class="s">&#34;mygroup&#34;</span><span class="o">);</span>
      <span class="c1">// 这里要修改成手动提交
</span><span class="c1"></span>        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;enable.auto.commit&#34;</span><span class="o">,</span> <span class="s">&#34;false&#34;</span><span class="o">);</span>
        <span class="c1">// properties.put(&#34;auto.commit.interval.ms&#34;, &#34;1000&#34;);
</span><span class="c1"></span>        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;session.timeout.ms&#34;</span><span class="o">,</span> <span class="s">&#34;30000&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;heartbeat.interval.ms&#34;</span><span class="o">,</span> <span class="s">&#34;10000&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;auto.offset.reset&#34;</span><span class="o">,</span> <span class="s">&#34;earliest&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;key.deserializer&#34;</span><span class="o">,</span> <span class="s">&#34;org.apache.kafka.common.serialization.IntegerDeserializer&#34;</span><span class="o">);</span>
        <span class="n">properties</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&#34;value.deserializer&#34;</span><span class="o">,</span> <span class="s">&#34;org.apache.kafka.common.serialization.StringDeserializer&#34;</span><span class="o">);</span>
        <span class="k">this</span><span class="o">.</span><span class="na">consumer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">KafkaConsumer</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;(</span><span class="n">properties</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">doWork</span><span class="o">()</span> <span class="o">{</span>
        <span class="n">consumer</span><span class="o">.</span><span class="na">subscribe</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&#34;test2&#34;</span><span class="o">));</span>
        <span class="n">ConsumerRecords</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span><span class="n">records</span> <span class="o">=</span> <span class="n">consumer</span><span class="o">.</span><span class="na">poll</span><span class="o">(</span><span class="n">1000</span><span class="o">);</span>
        <span class="k">for</span> <span class="o">(</span><span class="n">ConsumerRecord</span> <span class="n">record</span> <span class="o">:</span> <span class="n">records</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;topic = &#34;</span> <span class="o">+</span> <span class="n">record</span><span class="o">.</span><span class="na">topic</span><span class="o">());</span>
            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;partition = &#34;</span> <span class="o">+</span> <span class="n">record</span><span class="o">.</span><span class="na">partition</span><span class="o">());</span>
            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;key = &#34;</span> <span class="o">+</span> <span class="n">record</span><span class="o">.</span><span class="na">key</span><span class="o">());</span>
            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;value = &#34;</span> <span class="o">+</span> <span class="n">record</span><span class="o">.</span><span class="na">value</span><span class="o">());</span>

          <span class="c1">//手动同步提交
</span><span class="c1"></span>          <span class="c1">// consumer.commitSync();
</span><span class="c1"></span>          <span class="c1">//手动异步提交
</span><span class="c1"></span>          <span class="c1">// consumer.commitAsync();
</span><span class="c1"></span>          <span class="c1">// 带回调公共的手动异步提交
</span><span class="c1"></span>          <span class="n">consumer</span><span class="o">.</span><span class="na">commitAsync</span><span class="o">((</span><span class="n">offsets</span><span class="o">,</span> <span class="n">e</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="o">{</span>
            <span class="k">if</span><span class="o">(</span><span class="n">e</span> <span class="o">!=</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
              <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;提交次数, offsets = &#34;</span> <span class="o">+</span> <span class="n">offsets</span><span class="o">);</span>
              <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;exception = &#34;</span> <span class="o">+</span> <span class="n">e</span><span class="o">);</span>
            <span class="o">}</span>
          <span class="o">});</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="spring-boot-使用-kafka">Spring Boot 使用 Kafka</h3>
<p>现在大家的开发过程中，很多都用的是 Spring Boot 的项目，直接启动了，如果还是用原生的 API，就是有点 Low 了啊，那 Kafka 是如何和 Spring Boot 进行联合的呢？</p>
<p>Maven 配置：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">&lt;!-- https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients --&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
      &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
      &lt;version&gt;2.1.1&lt;/version&gt;
    &lt;/dependency&gt;
</code></pre></td></tr></table>
</div>
</div><p>添加配置文件，在 application.properties 中加入如下配置信息：</p>
<p>Kafka 连接地址：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">spring.kafka.bootstrap-servers = 192.168.51.128:9092,10.231.128.96:9093,192.168.51.128:9094
</code></pre></td></tr></table>
</div>
</div><p>生产者：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">spring.kafka.producer.acks = 0
spring.kafka.producer.key-serializer = org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer = org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.retries = 3
spring.kafka.producer.batch-size = 4096
spring.kafka.producer.buffer-memory = 33554432
spring.kafka.producer.compression-type = gzip
</code></pre></td></tr></table>
</div>
</div><p>消费者：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">spring.kafka.consumer.group-id = mygroup
spring.kafka.consumer.auto-commit-interval = 5000
spring.kafka.consumer.heartbeat-interval = 3000
spring.kafka.consumer.key-deserializer = org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer = org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.auto-offset-reset = earliest
spring.kafka.consumer.enable-auto-commit = true
# listenner, 标识消费者监听的个数
spring.kafka.listener.concurrency = 8
# topic的名字
kafka.topic1 = topic1
</code></pre></td></tr></table>
</div>
</div><p>生产者：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">lombok.extern.slf4j.Slf4j</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.springframework.beans.factory.annotation.Value</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.springframework.kafka.core.KafkaTemplate</span><span class="o">;</span>

<span class="nd">@Service</span>
<span class="nd">@Slf4j</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyKafkaProducerServiceImpl</span> <span class="kd">implements</span> <span class="n">MyKafkaProducerService</span> <span class="o">{</span>
        <span class="nd">@Resource</span>
    <span class="kd">private</span> <span class="n">KafkaTemplate</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">kafkaTemplate</span><span class="o">;</span>
        <span class="c1">// 读取配置文件
</span><span class="c1"></span>    <span class="nd">@Value</span><span class="o">(</span><span class="s">&#34;${kafka.topic1}&#34;</span><span class="o">)</span>
    <span class="kd">private</span> <span class="n">String</span> <span class="n">topic</span><span class="o">;</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">sendKafka</span><span class="o">()</span> <span class="o">{</span>
      <span class="n">kafkaTemplate</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="n">topic</span><span class="o">,</span> <span class="s">&#34;hell world&#34;</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></td></tr></table>
</div>
</div><p>消费者：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="nd">@Component</span>
<span class="nd">@Slf4j</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyKafkaConsumer</span> <span class="o">{</span>
  <span class="nd">@KafkaListener</span><span class="o">(</span><span class="n">topics</span> <span class="o">=</span> <span class="s">&#34;${kafka.topic1}&#34;</span><span class="o">)</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">listen</span><span class="o">(</span><span class="n">ConsumerRecord</span><span class="o">&lt;?,</span> <span class="o">?&gt;</span> <span class="n">record</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">Optional</span><span class="o">&lt;?&gt;</span> <span class="n">kafkaMessage</span> <span class="o">=</span> <span class="n">Optional</span><span class="o">.</span><span class="na">ofNullable</span><span class="o">(</span><span class="n">record</span><span class="o">.</span><span class="na">value</span><span class="o">());</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">kafkaMessage</span><span class="o">.</span><span class="na">isPresent</span><span class="o">())</span> <span class="o">{</span>
            <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">&#34;----------------- record =&#34;</span> <span class="o">+</span> <span class="n">record</span><span class="o">);</span>
            <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">&#34;------------------ message =&#34;</span> <span class="o">+</span> <span class="n">kafkaMessage</span><span class="o">.</span><span class="na">get</span><span class="o">());</span>
<span class="o">}</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="参考">参考</h2>
<p>本文系转载 <a href="https://mp.weixin.qq.com/s/R1en4V0Tlwlpt102BjotoA" target="_blank" rel="noopener noreffer">https://mp.weixin.qq.com/s/R1en4V0Tlwlpt102BjotoA</a></p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2020-12-22</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/mq-kafka/index.md" target="_blank">Read Markdown</a>
                        </span></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://russellgao.cn/mq-kafka/" data-title="消息队列原理之kafka" data-hashtags="kafka,消息队列"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://russellgao.cn/mq-kafka/" data-hashtag="kafka"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="Share on WhatsApp" data-sharer="whatsapp" data-url="https://russellgao.cn/mq-kafka/" data-title="消息队列原理之kafka" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://russellgao.cn/mq-kafka/" data-title="消息队列原理之kafka"><i data-svg-src="/lib/simple-icons/icons/line.min.svg"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://russellgao.cn/mq-kafka/" data-title="消息队列原理之kafka"><i class="fab fa-weibo fa-fw"></i></a><a href="javascript:void(0);" title="Share on Myspace" data-sharer="myspace" data-url="https://russellgao.cn/mq-kafka/" data-title="消息队列原理之kafka" data-description="消息队列原理之kafka"><i data-svg-src="/lib/simple-icons/icons/myspace.min.svg"></i></a><a href="javascript:void(0);" title="Share on Blogger" data-sharer="blogger" data-url="https://russellgao.cn/mq-kafka/" data-title="消息队列原理之kafka" data-description="消息队列原理之kafka"><i class="fab fa-blogger fa-fw"></i></a><a href="javascript:void(0);" title="Share on Evernote" data-sharer="evernote" data-url="https://russellgao.cn/mq-kafka/" data-title="消息队列原理之kafka"><i class="fab fa-evernote fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/kafka/">kafka</a>,&nbsp;<a href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/">消息队列</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/mq-rabbitmq/" class="prev" rel="prev" title="消息队列原理之rabbitmq"><i class="fas fa-angle-left fa-fw"></i>消息队列原理之rabbitmq</a>
            <a href="/design-principle/" class="next" rel="next" title="设计模式六大原则">设计模式六大原则<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"><div id="valine" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://valine.js.org/">Valine</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.73.0">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2020 - 2021</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://github.com/russellgao" target="_blank">高维宗(russellgao)</a></span><span class="icp-splitter">&nbsp;|&nbsp;</span><br class="icp-br"/>
                    <span class="icp"><a href="http://beian.miit.gov.cn/" target="_blank">沪ICP备2020034038号</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/valine/valine.min.css"><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=Array.prototype.fill%2CArray.prototype.find%2CArray.from%2CIntersectionObserver%2CMath.sign%2CObject.assign%2CPromise%2CObject.entries%2CElement.prototype.closest%2CrequestAnimationFrame%2CCustomEvent%2Chtml5shiv%2CObject.values%2Cfetch%2CElement.prototype.after"></script><script type="text/javascript" src="/lib/object-fit-images/ofi.min.js"></script><script type="text/javascript" src="/lib/valine/Valine.min.js"></script><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/twemoji/twemoji.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{"valine":{"appId":"UPHfC2syBI9Pu5vyncYfvYX5-9Nh9j0Va","appKey":"MBiG6UopXrWQR41mzt7jtq8o","avatar":"mp","el":"#valine","emojiCDN":"https://cdn.jsdelivr.net/npm/emoji-datasource-google@5.0.1/img/google/64/","emojiMaps":{"100":"1f4af.png","alien":"1f47d.png","anger":"1f4a2.png","angry":"1f620.png","anguished":"1f627.png","astonished":"1f632.png","black_heart":"1f5a4.png","blue_heart":"1f499.png","blush":"1f60a.png","bomb":"1f4a3.png","boom":"1f4a5.png","broken_heart":"1f494.png","brown_heart":"1f90e.png","clown_face":"1f921.png","cold_face":"1f976.png","cold_sweat":"1f630.png","confounded":"1f616.png","confused":"1f615.png","cry":"1f622.png","crying_cat_face":"1f63f.png","cupid":"1f498.png","dash":"1f4a8.png","disappointed":"1f61e.png","disappointed_relieved":"1f625.png","dizzy":"1f4ab.png","dizzy_face":"1f635.png","drooling_face":"1f924.png","exploding_head":"1f92f.png","expressionless":"1f611.png","face_vomiting":"1f92e.png","face_with_cowboy_hat":"1f920.png","face_with_hand_over_mouth":"1f92d.png","face_with_head_bandage":"1f915.png","face_with_monocle":"1f9d0.png","face_with_raised_eyebrow":"1f928.png","face_with_rolling_eyes":"1f644.png","face_with_symbols_on_mouth":"1f92c.png","face_with_thermometer":"1f912.png","fearful":"1f628.png","flushed":"1f633.png","frowning":"1f626.png","ghost":"1f47b.png","gift_heart":"1f49d.png","green_heart":"1f49a.png","grimacing":"1f62c.png","grin":"1f601.png","grinning":"1f600.png","hankey":"1f4a9.png","hear_no_evil":"1f649.png","heart":"2764-fe0f.png","heart_decoration":"1f49f.png","heart_eyes":"1f60d.png","heart_eyes_cat":"1f63b.png","heartbeat":"1f493.png","heartpulse":"1f497.png","heavy_heart_exclamation_mark_ornament":"2763-fe0f.png","hole":"1f573-fe0f.png","hot_face":"1f975.png","hugging_face":"1f917.png","hushed":"1f62f.png","imp":"1f47f.png","innocent":"1f607.png","japanese_goblin":"1f47a.png","japanese_ogre":"1f479.png","joy":"1f602.png","joy_cat":"1f639.png","kiss":"1f48b.png","kissing":"1f617.png","kissing_cat":"1f63d.png","kissing_closed_eyes":"1f61a.png","kissing_heart":"1f618.png","kissing_smiling_eyes":"1f619.png","laughing":"1f606.png","left_speech_bubble":"1f5e8-fe0f.png","love_letter":"1f48c.png","lying_face":"1f925.png","mask":"1f637.png","money_mouth_face":"1f911.png","nauseated_face":"1f922.png","nerd_face":"1f913.png","neutral_face":"1f610.png","no_mouth":"1f636.png","open_mouth":"1f62e.png","orange_heart":"1f9e1.png","partying_face":"1f973.png","pensive":"1f614.png","persevere":"1f623.png","pleading_face":"1f97a.png","pouting_cat":"1f63e.png","purple_heart":"1f49c.png","rage":"1f621.png","relaxed":"263a-fe0f.png","relieved":"1f60c.png","revolving_hearts":"1f49e.png","right_anger_bubble":"1f5ef-fe0f.png","robot_face":"1f916.png","rolling_on_the_floor_laughing":"1f923.png","scream":"1f631.png","scream_cat":"1f640.png","see_no_evil":"1f648.png","shushing_face":"1f92b.png","skull":"1f480.png","skull_and_crossbones":"2620-fe0f.png","sleeping":"1f634.png","sleepy":"1f62a.png","slightly_frowning_face":"1f641.png","slightly_smiling_face":"1f642.png","smile":"1f604.png","smile_cat":"1f638.png","smiley":"1f603.png","smiley_cat":"1f63a.png","smiling_face_with_3_hearts":"1f970.png","smiling_imp":"1f608.png","smirk":"1f60f.png","smirk_cat":"1f63c.png","sneezing_face":"1f927.png","sob":"1f62d.png","space_invader":"1f47e.png","sparkling_heart":"1f496.png","speak_no_evil":"1f64a.png","speech_balloon":"1f4ac.png","star-struck":"1f929.png","stuck_out_tongue":"1f61b.png","stuck_out_tongue_closed_eyes":"1f61d.png","stuck_out_tongue_winking_eye":"1f61c.png","sunglasses":"1f60e.png","sweat":"1f613.png","sweat_drops":"1f4a6.png","sweat_smile":"1f605.png","thinking_face":"1f914.png","thought_balloon":"1f4ad.png","tired_face":"1f62b.png","triumph":"1f624.png","two_hearts":"1f495.png","unamused":"1f612.png","upside_down_face":"1f643.png","weary":"1f629.png","white_frowning_face":"2639-fe0f.png","white_heart":"1f90d.png","wink":"1f609.png","woozy_face":"1f974.png","worried":"1f61f.png","yawning_face":"1f971.png","yellow_heart":"1f49b.png","yum":"1f60b.png","zany_face":"1f92a.png","zipper_mouth_face":"1f910.png","zzz":"1f4a4.png"},"enableQQ":false,"highlight":true,"lang":"en","pageSize":10,"placeholder":"Your comment ...","recordIP":true,"serverURLs":"https://uphfc2sy.lc-cn-e1-shared.com","visitor":true}},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":50,"type":"lunr"},"twemoji":true};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
