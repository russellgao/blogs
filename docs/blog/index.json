[{"categories":null,"content":"投稿到 servicemesh 社区的文章","date":"2020-11-10","objectID":"/opensrouce/elk/","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/opensrouce/elk/"},{"categories":null,"content":"ELK 这篇文档是由我投稿的云原生社区的文章，节选自 istio-handbook，如果有兴趣可以参考这本书。 ELK 指的是由 Elasticsearch + Logstash + Kibana 组成的日志采集、存储、展示为一体的日志解决方案，简称 “ELK Stack”。ELK Stack 还包含 Beats（如Filebeat、Metricbeat、Heartbeat等）、Kafka等成员，是目前主流的一种日志解决方案。 Elasticsearch 是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。 Logstash 是免费且开放的服务器端数据处理管道，能够从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的“存储库”中。Logstash 比较耗资源，在实践中我们一般用作实时解析和转换数据。Logstash 采用可插拔框架，拥有 200 多个插件。您可以将不同的输入选择、过滤器和输出选择混合搭配、精心安排，让它们在管道中和谐地运行。 Kibana 是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。 Kafka 是由 Apache 软件基金会开发的一个开源流处理平台，由 Scala 和 Java 编写。用来做缓冲，当日志量比较大的时候可以缓解后端 Elasticsearch 的压力。 Beats 是数据采集的得力工具。Beats家族成员包括如下： Filebeat：用于日志文件采集，内置了多种模块（Apache、Cisco ASA、Microsoft Azure、NGINX、MySQL 等等）。 Metricbeat： 用于指标采集。 Packetbeat：用于网络数据采集。 Winlogbeat：用于Windows 事件采集。 Auditbeat：用于审计日志采集。 Heartbeat：用于运行时间采集。 其中 Filebeat 被经常用来收集 Node 或者 Pod 中的日志。 Beats 用于收集客户端的日志，发送给缓存队列如Kafka，目的是为了解耦数据收集与解析入库的过程，同时提高了可扩展性，使日志系统有峰值处理能力，不会因为突发的访问压力造成日志系统奔溃。缓存队列可选的还有 Redis，由于 Redis 是内存型，很容易写满，生产环境建议用 kafka。Logstash 从 缓存队列中消费日志解析处理之后写到 Elasticsearch，通过 Kibana 展示给最终用户。 ","date":"2020-11-10","objectID":"/opensrouce/elk/:0:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/opensrouce/elk/"},{"categories":null,"content":"采集方案 Filebeat 有两种部署模式，一是通过 DaemonSet 方式部署，二是通过 Sidecar 方式部署，Filebeat 采集后发送到 Kafka ，再由 Logstash 从 Kafka 中消费写到 Elasticsearch。 ","date":"2020-11-10","objectID":"/opensrouce/elk/:1:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/opensrouce/elk/"},{"categories":null,"content":"DaemonSet 方式部署 开启 Envoy 的访问日志输出到 stdout ，以 DaemonSet 的方式在每一台集群节点部署 Filebeat ，并将日志目录挂载至 Filebeat Pod，实现对 Envoy 访问日志的采集。 ","date":"2020-11-10","objectID":"/opensrouce/elk/:1:1","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/opensrouce/elk/"},{"categories":null,"content":"Sidecar 方式部署 Filebeat 和 Envoy 部署在同一个 Pod 内，共享日志数据卷， Envoy 写，Filebeat 读，实现对 Envoy 访问日志的采集。 ","date":"2020-11-10","objectID":"/opensrouce/elk/:1:2","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/opensrouce/elk/"},{"categories":null,"content":"部署 ELK 有了以上的基础，我们开始部署 ELK Stack ","date":"2020-11-10","objectID":"/opensrouce/elk/:2:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/opensrouce/elk/"},{"categories":null,"content":"部署 Kafka 首先，创建一个新的 namespace 用于部署 ELK Stack： # Logging Namespace. All below are a part of this namespace. apiVersion: v1 kind: Namespace metadata: name: logging 接下来，部署 Kafka 服务。 Kafka 通过 Zookeeper 管理集群配置，所以在部署 Kafka 需要先部署 Zookeeper。 Zookeeper 是一个分布式的，开放源码的分布式应用程序协调服务。 Kafka 与 Zookeeper 都是有状态服务，部署时需要选择 StatefulSet 。 部署 Zookeeper Service apiVersion:v1kind:Servicemetadata:name:zookeeper-clusternamespace:loggingspec:selector:app:zookeeper-clusterports:- name:httpport:2181targetPort:2181type:ClusterIP Zookeeper 在集群内使用，供 Kafka 使用，创建类型为 ClusterIP 的 Service 。 Zookeeper 的默认端口是2181。 部署 Zookeeper ConfigMap apiVersion:v1kind:ConfigMapmetadata:name:zookeeper-confignamespace:loggingdata:ZOO_CONF_DIR:/confZOO_PORT:\"2181\" Zookeeper 配置文件中的 key 都可以 以 ZOO_ 加大写的方式设置到环境变量中，使之生效。 这里仅列举部分配置。 部署 Zookeeper StatefulSet apiVersion:apps/v1kind:StatefulSetmetadata:name:zookeepernamespace:loggingspec:serviceName:zookeeper-clusterreplicas:1updateStrategy:type:RollingUpdateselector:matchLabels:app:zookeeper-clustertemplate:metadata:labels:app:zookeeper-clusterannotations:sidecar.istio.io/inject:\"false\"spec:containers:- name:zookeeperresources:requests:cpu:10mmemory:100Milimits:memory:200Miimage:zookeeperimagePullPolicy:IfNotPresentenvFrom:- configMapRef:name:zookeeper-configreadinessProbe:tcpSocket:port:2181initialDelaySeconds:5periodSeconds:10livenessProbe:tcpSocket:port:2181initialDelaySeconds:15periodSeconds:20ports:- containerPort:2181name:zk-client sidecar.istio.io/inject=false 标识此服务无需 sidecar 注入。 部署 Kafka Service apiVersion:v1kind:Servicemetadata:name:bootstrap-kafkanamespace:loggingspec:clusterIP:Noneports:- port:9092selector:app:kafka---apiVersion:v1kind:Servicemetadata:name:kafka-clusternamespace:loggingspec:ports:- name:httptargetPort:9092port:9092selector:app:kafkatype:ClusterIP 部署两个 Service 。 bootstrap-kafka 为后续部署 Kafka Statefulset 使用。 kafka-cluster 为 Kafka 的访问入口，在生产中使用可以用其他的 Service 类型。 kafka 的默认端口是9092 部署 Kafka ConfigMap apiVersion:v1kind:ConfigMapmetadata:name:kafka-confignamespace:loggingdata:KAFKA_ADVERTISED_LISTENERS:\"PLAINTEXT://kafka-cluster:9092\"KAFKA_LISTENERS:\"PLAINTEXT://0.0.0.0:9092\"KAFKA_ZOOKEEPER_CONNECT:\"zookeeper-cluster:2181\"KAFKA_LOG_RETENTION_HOURS:\"48\"KAFKA_NUM_PARTITIONS:\"30\" Kafka 配置文件（server.properties）中的 key 都可以 以 KAFKA_ 加大写的方式设置到环境变量中，使之生效。 KAFKA_ADVERTISED_LISTENERS 为 Kafka 监听的服务地址。 KAFKA_ZOOKEEPER_CONNECT 为前面部署的 Zookeeper 的服务地址。 KAFKA_LOG_RETENTION_HOURS 为 Kafka 数据保留的时间，超过这个时间将会被清理，可以根据实际情况进行调整。 KAFKA_NUM_PARTITIONS 为创建 Kafka topic 时的默认分片数，设置大一些可以增加 Kafka 的吞吐量。 这里仅列举部分配置。 部署 Kafka StatefulSet apiVersion:apps/v1kind:StatefulSetmetadata:name:kafkanamespace:loggingspec:selector:matchLabels:app:kafkaserviceName:bootstrap-kafkareplicas:1template:metadata:labels:app:kafkaannotations:sidecar.istio.io/inject:\"false\"spec:containers:- name:kafka-brokerimage:russellgao/kafka:2.12-2.0.1ports:- name:insidecontainerPort:9092resources:requests:cpu:0.1memory:1024Milimits:memory:3069MireadinessProbe:tcpSocket:port:9092timeoutSeconds:1initialDelaySeconds:5periodSeconds:10livenessProbe:tcpSocket:port:9092timeoutSeconds:1initialDelaySeconds:15periodSeconds:20envFrom:- configMapRef:name:kafka-config kafka 对磁盘的 IO 要求较高，可以选择固态硬盘或者经过IO优化的磁盘，否则可能会成为日志系统的瓶颈。 请注意，本次实践没有把数据卷映射出来，在生产实践中使用 volumeClaimTemplates 来为 Pod 提供持久化存储。resources 可以根据实际情况调整。 ","date":"2020-11-10","objectID":"/opensrouce/elk/:2:1","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/opensrouce/elk/"},{"categories":null,"content":"部署 Logstash Logstash 是一个无状态服务，通过 Deployment 进行部署。 部署 Logstash ConfigMap apiVersion:v1kind:ConfigMapmetadata:name:logstash-confnamespace:loggingdata:logstash.conf:| input {http{host=\u003e\"0.0.0.0\"# default: 0.0.0.0port =\u003e 8080 # default:8080user=\u003e\"logstash\"password=\u003e\"aoDJ0JVgkfNPjarn\"response_headers=\u003e{\"Content-Type\"=\u003e\"text/plain\"\"Access-Control-Allow-Origin\"=\u003e\"*\"\"Access-Control-Allow-Methods\"=\u003e\"GET, POST, DELETE, PUT\"\"Access-Control-Allow-Headers\"=\u003e\"authorization, content-type\"\"Access-Control-Allow-Credentials\"=\u003etrue}}kafka{topics=\u003e\"istio\"bootstrap_servers=\u003e\"kafka-cluster:9092\"auto_offset_reset=\u003e\"earliest\"group_id=\u003e\"istio_kafka_gr\"consumer_threads=\u003e3codec=\u003e\"json\"}}filter{grok{match=\u003e{\"message\"=\u003e\"(?m)\\[%{TIMESTAMP_ISO8601:timestamp}\\] \"%{NOTSPACE:method}%{NOTSPACE:path}%{NOTSPACE:protocol}\" %{NUMBER:response_code:int} %{NOTSPACE:response_flags} \"%{NOTSPACE:istio_policy_status}\" \"%{NOTSPACE:upstream_transport_failure_reason}\" %{NUMBER:bytes_received:int} %{NUMBER:bytes_sent:int} %{NUMBER:duration:int} %{NUMBER:upstream_service_time:int} \"%{NOTSPACE:x_forwarded_for}\" \"%{NOTSPACE:user_agent}\" \"%{NOTSPACE:request_id}\" \"%{NOTSPACE:authority}\" \"%{NOTSPACE:upstream_host}\" %{NOTSPACE:upstream_cluster} %{NOTSPACE:upstream_local_address} %{NOTSPACE:downstream_local_address} %{NOTSPACE:downstream_remote_address} %{NOTSPACE:requested_server_name} %{NOTSPACE:route_name}\"}remove_field=\u003e[\"message\"]}date{match=\u003e[\"timestamp\",\"yyyy-MM-ddTHH:mm:ss.SSSZ\"]timezone=\u003e\"Asia/Shanghai\"}ruby{code=\u003e\"event.set('[@metadata][index_day]',(event.get('@timestamp').time.localtime + 8*60*60 ).strftime('%Y.%m.%d'))\"}}output{if\"_grokparsefailure\"notin[tags]{elasticsearch{user=\u003e\"elastic\"password=\u003e\"elastic\"hosts=\u003e[\"elasticsearch.com:9200\"]index=\u003e\"istio-%{[@metadata][index_day]}\"}}} Logstash 配置由3部分组成： input Logstash input 支持非常多的数据源，如 File、Elasticsearch、Beats、Redis、Kafka、Http等。 Http input 用于Logstash 的健康检查，也可通过 http 接口将日志直接发送到 Logstash，主要用于移动端的场景。 Kafka input 用于收集日志，一个input只能从一个 Topic 中读取数据，需要和后续的 Filebeat output 对应。 filter Logstash filter 支持非常多的插件，可以对数据进行解析、加工、转换，如 grok、date、ruby、json、drop等。 grok 用于对日志进行解析。 date 用于把 timestamp 转化成 elasticsearch 中的 @timestamp 字段，可以指定时区。 ruby 插件支持执行 ruby 代码，可以进行复杂逻辑的处理，此处的用法是 @timestamp 字段的时间加8小时，解决自动生成的索引时差问题。 output Logstash output 支持非常多的数据源，如 elasticsearch、cvs、jdbc 等。 此处是把 grok 解析成功的日志写到 elasticsearch 。 部署 Logstash Deployment apiVersion:apps/v1beta2kind:Deploymentmetadata:name:logstashnamespace:loggingspec:replicas:2selector:matchLabels:app:logstashtemplate:metadata:labels:app:logstashannotations:sidecar.istio.io/inject:\"false\"spec:volumes:- name:configconfigMap:name:logstash-confhostname:logstashcontainers:- name:logstashimage:logstash:7.2.0args:[\"-f\",\"/usr/share/logstash/pipeline/logstash.conf\",]imagePullPolicy:IfNotPresentvolumeMounts:- name:configmountPath:\"/usr/share/logstash/pipeline/logstash.conf\"readOnly:truesubPath:logstash.confresources:requests:cpu:0.5memory:1024Milimits:cpu:1.5memory:3072MireadinessProbe:tcpSocket:port:8080initialDelaySeconds:5periodSeconds:10livenessProbe:tcpSocket:port:8080initialDelaySeconds:15periodSeconds:20 Logstash 不需要对外发布服务，即不需要创建 Service，从 Kafka 中消费日志，处理完成之后写到 Elasticsearch 。 Logstash 只需要把配置文件挂载进去，无需挂载其他目录，排查错误时可通过 Logstash Console Log 进行查看。 部署 Logstash HorizontalPodAutoscaler apiVersion:autoscaling/v2beta1kind:HorizontalPodAutoscalermetadata:name:logstashnamespace:loggingspec:scaleTargetRef:apiVersion:apps/v1beta2kind:Deploymentname:logstashminReplicas:2maxReplicas:10metrics:- type:Resourceresource:name:cputargetAverageUtilization:80 Logstash 比较消费 CPU ，可以部署 HPA，可以根据日志量动态的扩所容。 Logstash 的压力对 CPU 比较敏感，可以只根据 CPU 这一个指标进行 HPA。 Logstash 的配置文件支持if/else条件判断，通过这种方式，一个 Logstash 集群可以支持比较多的日志格式。另外 Logstash 的 grok 语法相对复杂，可以使用 Kibana Dev Tools 工具进行调试，如下图： ","date":"2020-11-10","objectID":"/opensrouce/elk/:2:2","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/opensrouce/elk/"},{"categories":null,"content":"部署 Filebeat 这里仅给出 Filebeat DaemonSet 的部署过程。 部署 Filebeat ConfigMap apiVersion:v1kind:ConfigMapmetadata:name:filebeat-confnamespace:loggingdata:filebeat.yml:| filebeat:inputs:- paths:- /var/log- /var/lib/docker/containersignore_older:1hforce_close_files:true#强制filebeat在文件名改变时，关闭文件，会有丢失日志的风险close_older:1mfields_under_root:trueoutput:kafka:enabled:truehosts:[\"kafka-cluster:9092\"]topic:\"istio\"version:\"2.0.0\"partition.round_robin:reachable_only:falseworker:2max_retries:3bulk_max_size:2048timeout:30sbroker_timeout:10schannel_buffer_size:256keep_alive:60compression:gzipmax_message_bytes:1000000required_acks:1 input.paths 代表 Filebeat 监听的日志路径。 input.ignore_older 代表日志文件的修改时间超过这个之间，将会忽略，这个在 Filebeat 重启时很有效果，解决重复读取日志的问题。 out.kafka.hosts 和之前部署的 Kafka Service 对应。 out.kafka.topic 和之前部署的 Logstash ConfigMap 中的 input 对应。 部署 Filebeat DaemonSet apiVersion:apps/v1kind:DaemonSetmetadata:name:filebeatnamespace:logginglabels:app:filebeatspec:selector:matchLabels:app:filebeattemplate:metadata:labels:app:filebeatannotations:sidecar.istio.io/inject:\"false\"spec:containers:- name:filebeatimage:elastic/filebeat:7.2.0imagePullPolicy:IfNotPresentvolumeMounts:- name:configmountPath:\"/usr/share/filebeat/filebeat.yml\"readOnly:truesubPath:filebeat.yml- name:varlogmountPath:/var/log- name:varlibdockercontainersmountPath:/var/lib/docker/containersresources:requests:cpu:0.1memory:200Milimits:cpu:0.3memory:600Mivolumes:- name:varloghostPath:path:/var/log- name:varlibdockercontainershostPath:path:/var/lib/docker/containers- name:configconfigMap:name:filebeat-conf 这里声明了两个 hostPath 类型的数据卷，路径为日志存储的路径。 将宿主机的 /var/log 和 /var/lib/docker/containers 挂载到了 Filebeat Pod 内便于 Filebeat 收集日志。 Filebeat 不需要部署 Service 。 Filebeat 对资源消耗比较少，可忽略对 Node 的资源消耗。 ","date":"2020-11-10","objectID":"/opensrouce/elk/:2:3","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/opensrouce/elk/"},{"categories":null,"content":"小结 本节为大家介绍了 ELK 的原理和安装部署，以及如何收集日志。 ","date":"2020-11-10","objectID":"/opensrouce/elk/:3:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/opensrouce/elk/"},{"categories":null,"content":"参考 Beats Logstash Zookeeper ","date":"2020-11-10","objectID":"/opensrouce/elk/:4:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/opensrouce/elk/"},{"categories":null,"content":"投稿到 servicemesh 社区的文章","date":"2020-11-10","objectID":"/elk/","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"ELK 这篇文档是由我投稿的云原生社区的文章，节选自 istio-handbook，如果有兴趣可以参考这本书。 ELK 指的是由 Elasticsearch + Logstash + Kibana 组成的日志采集、存储、展示为一体的日志解决方案，简称 “ELK Stack”。ELK Stack 还包含 Beats（如Filebeat、Metricbeat、Heartbeat等）、Kafka等成员，是目前主流的一种日志解决方案。 Elasticsearch 是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。 Logstash 是免费且开放的服务器端数据处理管道，能够从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的“存储库”中。Logstash 比较耗资源，在实践中我们一般用作实时解析和转换数据。Logstash 采用可插拔框架，拥有 200 多个插件。您可以将不同的输入选择、过滤器和输出选择混合搭配、精心安排，让它们在管道中和谐地运行。 Kibana 是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。 Kafka 是由 Apache 软件基金会开发的一个开源流处理平台，由 Scala 和 Java 编写。用来做缓冲，当日志量比较大的时候可以缓解后端 Elasticsearch 的压力。 Beats 是数据采集的得力工具。Beats家族成员包括如下： Filebeat：用于日志文件采集，内置了多种模块（Apache、Cisco ASA、Microsoft Azure、NGINX、MySQL 等等）。 Metricbeat： 用于指标采集。 Packetbeat：用于网络数据采集。 Winlogbeat：用于Windows 事件采集。 Auditbeat：用于审计日志采集。 Heartbeat：用于运行时间采集。 其中 Filebeat 被经常用来收集 Node 或者 Pod 中的日志。 Beats 用于收集客户端的日志，发送给缓存队列如Kafka，目的是为了解耦数据收集与解析入库的过程，同时提高了可扩展性，使日志系统有峰值处理能力，不会因为突发的访问压力造成日志系统奔溃。缓存队列可选的还有 Redis，由于 Redis 是内存型，很容易写满，生产环境建议用 kafka。Logstash 从 缓存队列中消费日志解析处理之后写到 Elasticsearch，通过 Kibana 展示给最终用户。 ","date":"2020-11-10","objectID":"/elk/:0:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"采集方案 Filebeat 有两种部署模式，一是通过 DaemonSet 方式部署，二是通过 Sidecar 方式部署，Filebeat 采集后发送到 Kafka ，再由 Logstash 从 Kafka 中消费写到 Elasticsearch。 ","date":"2020-11-10","objectID":"/elk/:1:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"DaemonSet 方式部署 开启 Envoy 的访问日志输出到 stdout ，以 DaemonSet 的方式在每一台集群节点部署 Filebeat ，并将日志目录挂载至 Filebeat Pod，实现对 Envoy 访问日志的采集。 ","date":"2020-11-10","objectID":"/elk/:1:1","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"Sidecar 方式部署 Filebeat 和 Envoy 部署在同一个 Pod 内，共享日志数据卷， Envoy 写，Filebeat 读，实现对 Envoy 访问日志的采集。 ","date":"2020-11-10","objectID":"/elk/:1:2","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"部署 ELK 有了以上的基础，我们开始部署 ELK Stack ","date":"2020-11-10","objectID":"/elk/:2:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"部署 Kafka 首先，创建一个新的 namespace 用于部署 ELK Stack： # Logging Namespace. All below are a part of this namespace. apiVersion: v1 kind: Namespace metadata: name: logging 接下来，部署 Kafka 服务。 Kafka 通过 Zookeeper 管理集群配置，所以在部署 Kafka 需要先部署 Zookeeper。 Zookeeper 是一个分布式的，开放源码的分布式应用程序协调服务。 Kafka 与 Zookeeper 都是有状态服务，部署时需要选择 StatefulSet 。 部署 Zookeeper Service apiVersion:v1kind:Servicemetadata:name:zookeeper-clusternamespace:loggingspec:selector:app:zookeeper-clusterports:- name:httpport:2181targetPort:2181type:ClusterIP Zookeeper 在集群内使用，供 Kafka 使用，创建类型为 ClusterIP 的 Service 。 Zookeeper 的默认端口是2181。 部署 Zookeeper ConfigMap apiVersion:v1kind:ConfigMapmetadata:name:zookeeper-confignamespace:loggingdata:ZOO_CONF_DIR:/confZOO_PORT:\"2181\" Zookeeper 配置文件中的 key 都可以 以 ZOO_ 加大写的方式设置到环境变量中，使之生效。 这里仅列举部分配置。 部署 Zookeeper StatefulSet apiVersion:apps/v1kind:StatefulSetmetadata:name:zookeepernamespace:loggingspec:serviceName:zookeeper-clusterreplicas:1updateStrategy:type:RollingUpdateselector:matchLabels:app:zookeeper-clustertemplate:metadata:labels:app:zookeeper-clusterannotations:sidecar.istio.io/inject:\"false\"spec:containers:- name:zookeeperresources:requests:cpu:10mmemory:100Milimits:memory:200Miimage:zookeeperimagePullPolicy:IfNotPresentenvFrom:- configMapRef:name:zookeeper-configreadinessProbe:tcpSocket:port:2181initialDelaySeconds:5periodSeconds:10livenessProbe:tcpSocket:port:2181initialDelaySeconds:15periodSeconds:20ports:- containerPort:2181name:zk-client sidecar.istio.io/inject=false 标识此服务无需 sidecar 注入。 部署 Kafka Service apiVersion:v1kind:Servicemetadata:name:bootstrap-kafkanamespace:loggingspec:clusterIP:Noneports:- port:9092selector:app:kafka---apiVersion:v1kind:Servicemetadata:name:kafka-clusternamespace:loggingspec:ports:- name:httptargetPort:9092port:9092selector:app:kafkatype:ClusterIP 部署两个 Service 。 bootstrap-kafka 为后续部署 Kafka Statefulset 使用。 kafka-cluster 为 Kafka 的访问入口，在生产中使用可以用其他的 Service 类型。 kafka 的默认端口是9092 部署 Kafka ConfigMap apiVersion:v1kind:ConfigMapmetadata:name:kafka-confignamespace:loggingdata:KAFKA_ADVERTISED_LISTENERS:\"PLAINTEXT://kafka-cluster:9092\"KAFKA_LISTENERS:\"PLAINTEXT://0.0.0.0:9092\"KAFKA_ZOOKEEPER_CONNECT:\"zookeeper-cluster:2181\"KAFKA_LOG_RETENTION_HOURS:\"48\"KAFKA_NUM_PARTITIONS:\"30\" Kafka 配置文件（server.properties）中的 key 都可以 以 KAFKA_ 加大写的方式设置到环境变量中，使之生效。 KAFKA_ADVERTISED_LISTENERS 为 Kafka 监听的服务地址。 KAFKA_ZOOKEEPER_CONNECT 为前面部署的 Zookeeper 的服务地址。 KAFKA_LOG_RETENTION_HOURS 为 Kafka 数据保留的时间，超过这个时间将会被清理，可以根据实际情况进行调整。 KAFKA_NUM_PARTITIONS 为创建 Kafka topic 时的默认分片数，设置大一些可以增加 Kafka 的吞吐量。 这里仅列举部分配置。 部署 Kafka StatefulSet apiVersion:apps/v1kind:StatefulSetmetadata:name:kafkanamespace:loggingspec:selector:matchLabels:app:kafkaserviceName:bootstrap-kafkareplicas:1template:metadata:labels:app:kafkaannotations:sidecar.istio.io/inject:\"false\"spec:containers:- name:kafka-brokerimage:russellgao/kafka:2.12-2.0.1ports:- name:insidecontainerPort:9092resources:requests:cpu:0.1memory:1024Milimits:memory:3069MireadinessProbe:tcpSocket:port:9092timeoutSeconds:1initialDelaySeconds:5periodSeconds:10livenessProbe:tcpSocket:port:9092timeoutSeconds:1initialDelaySeconds:15periodSeconds:20envFrom:- configMapRef:name:kafka-config kafka 对磁盘的 IO 要求较高，可以选择固态硬盘或者经过IO优化的磁盘，否则可能会成为日志系统的瓶颈。 请注意，本次实践没有把数据卷映射出来，在生产实践中使用 volumeClaimTemplates 来为 Pod 提供持久化存储。resources 可以根据实际情况调整。 ","date":"2020-11-10","objectID":"/elk/:2:1","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"部署 Logstash Logstash 是一个无状态服务，通过 Deployment 进行部署。 部署 Logstash ConfigMap apiVersion:v1kind:ConfigMapmetadata:name:logstash-confnamespace:loggingdata:logstash.conf:| input {http{host=\u003e\"0.0.0.0\"# default: 0.0.0.0port =\u003e 8080 # default:8080user=\u003e\"logstash\"password=\u003e\"aoDJ0JVgkfNPjarn\"response_headers=\u003e{\"Content-Type\"=\u003e\"text/plain\"\"Access-Control-Allow-Origin\"=\u003e\"*\"\"Access-Control-Allow-Methods\"=\u003e\"GET, POST, DELETE, PUT\"\"Access-Control-Allow-Headers\"=\u003e\"authorization, content-type\"\"Access-Control-Allow-Credentials\"=\u003etrue}}kafka{topics=\u003e\"istio\"bootstrap_servers=\u003e\"kafka-cluster:9092\"auto_offset_reset=\u003e\"earliest\"group_id=\u003e\"istio_kafka_gr\"consumer_threads=\u003e3codec=\u003e\"json\"}}filter{grok{match=\u003e{\"message\"=\u003e\"(?m)\\[%{TIMESTAMP_ISO8601:timestamp}\\] \"%{NOTSPACE:method}%{NOTSPACE:path}%{NOTSPACE:protocol}\" %{NUMBER:response_code:int} %{NOTSPACE:response_flags} \"%{NOTSPACE:istio_policy_status}\" \"%{NOTSPACE:upstream_transport_failure_reason}\" %{NUMBER:bytes_received:int} %{NUMBER:bytes_sent:int} %{NUMBER:duration:int} %{NUMBER:upstream_service_time:int} \"%{NOTSPACE:x_forwarded_for}\" \"%{NOTSPACE:user_agent}\" \"%{NOTSPACE:request_id}\" \"%{NOTSPACE:authority}\" \"%{NOTSPACE:upstream_host}\" %{NOTSPACE:upstream_cluster} %{NOTSPACE:upstream_local_address} %{NOTSPACE:downstream_local_address} %{NOTSPACE:downstream_remote_address} %{NOTSPACE:requested_server_name} %{NOTSPACE:route_name}\"}remove_field=\u003e[\"message\"]}date{match=\u003e[\"timestamp\",\"yyyy-MM-ddTHH:mm:ss.SSSZ\"]timezone=\u003e\"Asia/Shanghai\"}ruby{code=\u003e\"event.set('[@metadata][index_day]',(event.get('@timestamp').time.localtime + 8*60*60 ).strftime('%Y.%m.%d'))\"}}output{if\"_grokparsefailure\"notin[tags]{elasticsearch{user=\u003e\"elastic\"password=\u003e\"elastic\"hosts=\u003e[\"elasticsearch.com:9200\"]index=\u003e\"istio-%{[@metadata][index_day]}\"}}} Logstash 配置由3部分组成： input Logstash input 支持非常多的数据源，如 File、Elasticsearch、Beats、Redis、Kafka、Http等。 Http input 用于Logstash 的健康检查，也可通过 http 接口将日志直接发送到 Logstash，主要用于移动端的场景。 Kafka input 用于收集日志，一个input只能从一个 Topic 中读取数据，需要和后续的 Filebeat output 对应。 filter Logstash filter 支持非常多的插件，可以对数据进行解析、加工、转换，如 grok、date、ruby、json、drop等。 grok 用于对日志进行解析。 date 用于把 timestamp 转化成 elasticsearch 中的 @timestamp 字段，可以指定时区。 ruby 插件支持执行 ruby 代码，可以进行复杂逻辑的处理，此处的用法是 @timestamp 字段的时间加8小时，解决自动生成的索引时差问题。 output Logstash output 支持非常多的数据源，如 elasticsearch、cvs、jdbc 等。 此处是把 grok 解析成功的日志写到 elasticsearch 。 部署 Logstash Deployment apiVersion:apps/v1beta2kind:Deploymentmetadata:name:logstashnamespace:loggingspec:replicas:2selector:matchLabels:app:logstashtemplate:metadata:labels:app:logstashannotations:sidecar.istio.io/inject:\"false\"spec:volumes:- name:configconfigMap:name:logstash-confhostname:logstashcontainers:- name:logstashimage:logstash:7.2.0args:[\"-f\",\"/usr/share/logstash/pipeline/logstash.conf\",]imagePullPolicy:IfNotPresentvolumeMounts:- name:configmountPath:\"/usr/share/logstash/pipeline/logstash.conf\"readOnly:truesubPath:logstash.confresources:requests:cpu:0.5memory:1024Milimits:cpu:1.5memory:3072MireadinessProbe:tcpSocket:port:8080initialDelaySeconds:5periodSeconds:10livenessProbe:tcpSocket:port:8080initialDelaySeconds:15periodSeconds:20 Logstash 不需要对外发布服务，即不需要创建 Service，从 Kafka 中消费日志，处理完成之后写到 Elasticsearch 。 Logstash 只需要把配置文件挂载进去，无需挂载其他目录，排查错误时可通过 Logstash Console Log 进行查看。 部署 Logstash HorizontalPodAutoscaler apiVersion:autoscaling/v2beta1kind:HorizontalPodAutoscalermetadata:name:logstashnamespace:loggingspec:scaleTargetRef:apiVersion:apps/v1beta2kind:Deploymentname:logstashminReplicas:2maxReplicas:10metrics:- type:Resourceresource:name:cputargetAverageUtilization:80 Logstash 比较消费 CPU ，可以部署 HPA，可以根据日志量动态的扩所容。 Logstash 的压力对 CPU 比较敏感，可以只根据 CPU 这一个指标进行 HPA。 Logstash 的配置文件支持if/else条件判断，通过这种方式，一个 Logstash 集群可以支持比较多的日志格式。另外 Logstash 的 grok 语法相对复杂，可以使用 Kibana Dev Tools 工具进行调试，如下图： ","date":"2020-11-10","objectID":"/elk/:2:2","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"部署 Filebeat 这里仅给出 Filebeat DaemonSet 的部署过程。 部署 Filebeat ConfigMap apiVersion:v1kind:ConfigMapmetadata:name:filebeat-confnamespace:loggingdata:filebeat.yml:| filebeat:inputs:- paths:- /var/log- /var/lib/docker/containersignore_older:1hforce_close_files:true#强制filebeat在文件名改变时，关闭文件，会有丢失日志的风险close_older:1mfields_under_root:trueoutput:kafka:enabled:truehosts:[\"kafka-cluster:9092\"]topic:\"istio\"version:\"2.0.0\"partition.round_robin:reachable_only:falseworker:2max_retries:3bulk_max_size:2048timeout:30sbroker_timeout:10schannel_buffer_size:256keep_alive:60compression:gzipmax_message_bytes:1000000required_acks:1 input.paths 代表 Filebeat 监听的日志路径。 input.ignore_older 代表日志文件的修改时间超过这个之间，将会忽略，这个在 Filebeat 重启时很有效果，解决重复读取日志的问题。 out.kafka.hosts 和之前部署的 Kafka Service 对应。 out.kafka.topic 和之前部署的 Logstash ConfigMap 中的 input 对应。 部署 Filebeat DaemonSet apiVersion:apps/v1kind:DaemonSetmetadata:name:filebeatnamespace:logginglabels:app:filebeatspec:selector:matchLabels:app:filebeattemplate:metadata:labels:app:filebeatannotations:sidecar.istio.io/inject:\"false\"spec:containers:- name:filebeatimage:elastic/filebeat:7.2.0imagePullPolicy:IfNotPresentvolumeMounts:- name:configmountPath:\"/usr/share/filebeat/filebeat.yml\"readOnly:truesubPath:filebeat.yml- name:varlogmountPath:/var/log- name:varlibdockercontainersmountPath:/var/lib/docker/containersresources:requests:cpu:0.1memory:200Milimits:cpu:0.3memory:600Mivolumes:- name:varloghostPath:path:/var/log- name:varlibdockercontainershostPath:path:/var/lib/docker/containers- name:configconfigMap:name:filebeat-conf 这里声明了两个 hostPath 类型的数据卷，路径为日志存储的路径。 将宿主机的 /var/log 和 /var/lib/docker/containers 挂载到了 Filebeat Pod 内便于 Filebeat 收集日志。 Filebeat 不需要部署 Service 。 Filebeat 对资源消耗比较少，可忽略对 Node 的资源消耗。 ","date":"2020-11-10","objectID":"/elk/:2:3","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"小结 本节为大家介绍了 ELK 的原理和安装部署，以及如何收集日志。 ","date":"2020-11-10","objectID":"/elk/:3:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"参考 Beats Logstash Zookeeper ","date":"2020-11-10","objectID":"/elk/:4:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"Hugo, the world's fastest framework for building websites","date":"2020-11-08","objectID":"/about/","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"作者简介 云原生爱好者，专注于devops，ops，kubernetes，云原生，算法等领域，可以关注作者个人公众号，不定期有干货分享哦！ ","date":"2020-11-08","objectID":"/about/:1:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"Hugo, the world's fastest framework for building websites","date":"2020-11-08","objectID":"/golang/defer/","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"背景 在学习和使用 Go 的过程中发现，Go 在语言层面的设计有很多有趣的地方，所以准备用一个系列来细数这些有趣的地方。写这个系列一是为了加深自己的理解，二是愿意分享，分享 Go 中有趣的设计细节。每篇都会通过一个例子讲述一个细节，感兴趣的话可以关注一下哟！ ","date":"2020-11-08","objectID":"/golang/defer/:1:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"Go 介绍 Go（又称 Golang）是 Google 的 Robert Griesemer，Rob Pike 及 Ken Thompson 开发的一种静态强类型、编译型语言。Go 语言语法与 C 相近，但功能上有：内存安全，GC（垃圾回收），结构形态及 CSP-style 并发计算。 Go 是由这3位大佬从2007年9月开始设计Go，2009年正式推出，到目前为止已经发了15个大版本，最新版为1.15.4。Go 现在广泛应用于云原生、中间件、还有各个业务平台，如 docker、kubernetes、etcd等都是Go语言编写。所以还是很有必要了解一下哟！ 下面简单说说Go的优缺点，俗话说：一万个人眼中有一万个哈姆雷特，所以优缺点都是相对而言，就谈谈自己使用过程中的感受，具体的优缺点会在后面的系列文章中一一提到，这里是抛砖引玉。 ","date":"2020-11-08","objectID":"/golang/defer/:2:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"Go 优点 语言层面支持并发：一个 go 关键字即可实现并发，其他编程语言依赖于库实现并发，这是有本质的区别 高性能 编译完之后生成二进制文件，可免去环境依赖 defer 机制 内置runtime 内嵌C支持，Go里面也可以直接包含C代码，利用现有的丰富的C库 跨平台编译 。。。 ","date":"2020-11-08","objectID":"/golang/defer/:3:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"Go 缺点 包管理 。。。 ","date":"2020-11-08","objectID":"/golang/defer/:4:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"defer 说起 Go 语言的最强大的地方，不得不说 Go 的并发机制和调度原理，但是今天不讲这些高深的理论，先从简单的开始。先思考这么几个问题（可以用自己熟悉的语言思考如何解决）: 对于文件的打开关闭，网络连接的建立断开场景，当打开时候应该何时关闭? 当调用一个函数，希望在函数返回时修改它的值，该如何解决? 先看看defer 的官方定义 ： A “defer” statement invokes a function whose execution is deferred to the moment the surrounding function returns, either because the surrounding function executed a return statement, reached the end of its function body, or because the corresponding goroutine is panicking. 意思是说，当包裹defer 的函数返回时或者包裹defer的函数执行到末尾时或者所在的goroutine发生panic时才会执行。 换句话说就是当函数执行完之后或者发生异常时再执行defer语句，就是说在被调函数返回之后，赋值给调用函数之前，还有机会执行其他指令，是不是很神奇。先看一段python 代码 : def f(x,y) : z = x / y z += 1 return z ​ if __name__ == \"__main__\" : result = f(4 /2) 当调用函数f，f返回给z并且赋值给result，在这时间，是没有任何机会执行其他的函数代码的。再看一段go代码: package main func main() { result := f(4, 2) fmt.Println(result) } ​ func f(x, y int) (r int) { r = x / y r += 1 defer func() { r += 2 }() return } 当调用函数f，f返回之后，在赋值之前执行了r +=2 。现在回想一下之前的两个问题，如果有defer 机制，是不是可以很好的解决。如对于第一个问题，在defer 语句中处理文件的关闭，连接的释放等，而不用考虑一些异常情况。 那defer的实现原理是怎样的呢? defer 其实是调用runtime.deferproc 进行实现，在defer 出现的地方，插入了call runtime.deferproc，然后在函数返回之前的地方，插入指令call runtime.deferreturn。 普通函数返回时，汇编代码类似于: add xx SP return 如果包含了defer 语句，汇编代码类似于: call runtime.deferreturn， add xx SP return goroutine的控制结构中，有一张表记录defer，调用runtime.deferproc时会将需要defer的表达式记录在表中，而在调用runtime.deferreturn的时候，则会依次从defer表中出栈并执行。 defer 在使用过程中也存在一些坑，看几个例子: 例1: func f() (result int) { defer func() { result++ }() return 10 } 例2: func f() (result int) { t := 10 defer func() { t = t + 1 }() return t } 例3: func f() (result int) { defer func(result int) { result = result + 1 }(result) return 10 } 大家可以先心里默默算一下他们的结果 第一个是11，第二个是10，第三个是10。 defer表达式可能会在设置函数返回值之后，在返回到调用函数之前，修改返回值，使最终的函数返回值与你想象的不一致。其实使用defer时，用一个简单的转换规则改写一下，就不会迷糊了。改写规则是将return语句拆成两句写，return xxx会被改写成: 返回值 = xxx 调用defer函数 空的return 例1 会被改写成: func f() (result int) { result = 10 // return语句不是一条原子调用，return xxx其实是赋值＋ret指令 defer func() { result++ }() return // 空的return指令 } 所以返回值是11 例2 会被改写成: func f() (result int) { t := 10 result = t // 赋值指令 defer func() { t = t + 1 //defer被插入到赋值与返回之间执行，这个例子中返回值 result没被修改过 }() return // 空的return指令 } 所以返回值是10 例3 就留给大家自己改写一下啦，有兴趣可以私我沟通哟！ ","date":"2020-11-08","objectID":"/golang/defer/:5:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"总结 这篇主要做了对Go语言的介绍和优缺点，分析了defer 的用法以及实现原理，最后用例子展示了使用过程中可能会存在的坑。下篇预告: Go 的调度模型，欢迎关注!!! 如果有理解不正确的地方，欢迎指出。 ","date":"2020-11-08","objectID":"/golang/defer/:6:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"Golang 细节欣赏","date":"2020-11-08","objectID":"/defer/","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"背景 在学习和使用 Go 的过程中发现，Go 在语言层面的设计有很多有趣的地方，所以准备用一个系列来细数这些有趣的地方。写这个系列一是为了加深自己的理解，二是愿意分享，分享 Go 中有趣的设计细节。每篇都会通过一个例子讲述一个细节，感兴趣的话可以关注一下哟！ ","date":"2020-11-08","objectID":"/defer/:1:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"Go 介绍 Go（又称 Golang）是 Google 的 Robert Griesemer，Rob Pike 及 Ken Thompson 开发的一种静态强类型、编译型语言。Go 语言语法与 C 相近，但功能上有：内存安全，GC（垃圾回收），结构形态及 CSP-style 并发计算。 Go 是由这3位大佬从2007年9月开始设计Go，2009年正式推出，到目前为止已经发了15个大版本，最新版为1.15.4。Go 现在广泛应用于云原生、中间件、还有各个业务平台，如 docker、kubernetes、etcd等都是Go语言编写。所以还是很有必要了解一下哟！ 下面简单说说Go的优缺点，俗话说：一万个人眼中有一万个哈姆雷特，所以优缺点都是相对而言，就谈谈自己使用过程中的感受，具体的优缺点会在后面的系列文章中一一提到，这里是抛砖引玉。 ","date":"2020-11-08","objectID":"/defer/:2:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"Go 优点 语言层面支持并发：一个 go 关键字即可实现并发，其他编程语言依赖于库实现并发，这是有本质的区别 高性能 编译完之后生成二进制文件，可免去环境依赖 defer 机制 内置runtime 内嵌C支持，Go里面也可以直接包含C代码，利用现有的丰富的C库 跨平台编译 。。。 ","date":"2020-11-08","objectID":"/defer/:3:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"Go 缺点 包管理 。。。 ","date":"2020-11-08","objectID":"/defer/:4:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"defer 说起 Go 语言的最强大的地方，不得不说 Go 的并发机制和调度原理，但是今天不讲这些高深的理论，先从简单的开始。先思考这么几个问题（可以用自己熟悉的语言思考如何解决）: 对于文件的打开关闭，网络连接的建立断开场景，当打开时候应该何时关闭? 当调用一个函数，希望在函数返回时修改它的值，该如何解决? 先看看defer 的官方定义 ： A “defer” statement invokes a function whose execution is deferred to the moment the surrounding function returns, either because the surrounding function executed a return statement, reached the end of its function body, or because the corresponding goroutine is panicking. 意思是说，当包裹defer 的函数返回时或者包裹defer的函数执行到末尾时或者所在的goroutine发生panic时才会执行。 换句话说就是当函数执行完之后或者发生异常时再执行defer语句，就是说在被调函数返回之后，赋值给调用函数之前，还有机会执行其他指令，是不是很神奇。先看一段python 代码 : def f(x,y) : z = x / y z += 1 return z ​ if __name__ == \"__main__\" : result = f(4 /2) 当调用函数f，f返回给z并且赋值给result，在这时间，是没有任何机会执行其他的函数代码的。再看一段go代码: package main func main() { result := f(4, 2) fmt.Println(result) } ​ func f(x, y int) (r int) { r = x / y r += 1 defer func() { r += 2 }() return } 当调用函数f，f返回之后，在赋值之前执行了r +=2 。现在回想一下之前的两个问题，如果有defer 机制，是不是可以很好的解决。如对于第一个问题，在defer 语句中处理文件的关闭，连接的释放等，而不用考虑一些异常情况。 那defer的实现原理是怎样的呢? defer 其实是调用runtime.deferproc 进行实现，在defer 出现的地方，插入了call runtime.deferproc，然后在函数返回之前的地方，插入指令call runtime.deferreturn。 普通函数返回时，汇编代码类似于: add xx SP return 如果包含了defer 语句，汇编代码类似于: call runtime.deferreturn， add xx SP return goroutine的控制结构中，有一张表记录defer，调用runtime.deferproc时会将需要defer的表达式记录在表中，而在调用runtime.deferreturn的时候，则会依次从defer表中出栈并执行。 defer 在使用过程中也存在一些坑，看几个例子: 例1: func f() (result int) { defer func() { result++ }() return 10 } 例2: func f() (result int) { t := 10 defer func() { t = t + 1 }() return t } 例3: func f() (result int) { defer func(result int) { result = result + 1 }(result) return 10 } 大家可以先心里默默算一下他们的结果 第一个是11，第二个是10，第三个是10。 defer表达式可能会在设置函数返回值之后，在返回到调用函数之前，修改返回值，使最终的函数返回值与你想象的不一致。其实使用defer时，用一个简单的转换规则改写一下，就不会迷糊了。改写规则是将return语句拆成两句写，return xxx会被改写成: 返回值 = xxx 调用defer函数 空的return 例1 会被改写成: func f() (result int) { result = 10 // return语句不是一条原子调用，return xxx其实是赋值＋ret指令 defer func() { result++ }() return // 空的return指令 } 所以返回值是11 例2 会被改写成: func f() (result int) { t := 10 result = t // 赋值指令 defer func() { t = t + 1 //defer被插入到赋值与返回之间执行，这个例子中返回值 result没被修改过 }() return // 空的return指令 } 所以返回值是10 例3 就留给大家自己改写一下啦，有兴趣可以私我沟通哟！ ","date":"2020-11-08","objectID":"/defer/:5:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"总结 这篇主要做了对Go语言的介绍和优缺点，分析了defer 的用法以及实现原理，最后用例子展示了使用过程中可能会存在的坑。下篇预告: Go 的调度模型，欢迎关注!!! 如果有理解不正确的地方，欢迎指出。 ","date":"2020-11-08","objectID":"/defer/:6:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"自己开源的项目","date":"2020-11-08","objectID":"/opensrouce/myself/","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/myself/"},{"categories":null,"content":"toolkit ","date":"2020-11-08","objectID":"/opensrouce/myself/:0:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/myself/"},{"categories":null,"content":"作用 用于提供工作效率的工具箱，里面有各种工具，就比如真实工具箱中里面有扳手，各种大小的起子，钳子等 某些场景下确实可以达到事半功倍的效果 ","date":"2020-11-08","objectID":"/opensrouce/myself/:1:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/myself/"},{"categories":null,"content":"安装 ","date":"2020-11-08","objectID":"/opensrouce/myself/:2:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/myself/"},{"categories":null,"content":"源码安装 有 go 语言环境的可以直接用源码进行编译运行 git clone https://github.com/russellgao/toolkit.git cd toolkit make ","date":"2020-11-08","objectID":"/opensrouce/myself/:2:1","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/myself/"},{"categories":null,"content":"二进制 可以直接在release 页面进行下载对应的操作系统的二进制文件 https://github.com/russellgao/toolkit/releases/ ","date":"2020-11-08","objectID":"/opensrouce/myself/:2:2","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/myself/"},{"categories":null,"content":"用法 ","date":"2020-11-08","objectID":"/opensrouce/myself/:3:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/myself/"},{"categories":null,"content":"本机运行 可以通过如下命令进行 gwz:toolkit gaoweizong$ tkctl --help tkctl is a toolkit entrypoint,run `tkctl --help` get more information. Usage: tkctl [flags] tkctl [command] Available Commands: help Help about any command replace 文本替换，支持正则替换和非正则替换，类似与linux下的sed，但比sed更好用，而且可以跨平台使用 secret 生成随机密码，支持1～100位长度，可以指定是否包含特殊字符 version tkctl version Flags: -h, --help help for tkctl -v, --version show the version and exit Use \"tkctl [command] --help\" for more information about a command. tkctl 中的子命令会不断更新，某个具体的功能请查看Available Commands:下的帮助文档，如文本替换 tkctl replace --help 文本替换，支持正则替换和非正则替换，类似与linux下的sed，但比sed更好用，而且可以跨平台使用 Usage: tkctl replace [flags] Flags: -d, --dirs string 需要替换的目录, 默认为当前路径 (default \".\") -h, --help help for replace -m, --mode string 替换的模式，支持正则（regexp）和非正则（text）两种模式，默认非正则， (default \"text\") -p, --pattern string 需要替换的pattern [required] -r, --repl string 目标字符串 [required] ","date":"2020-11-08","objectID":"/opensrouce/myself/:3:1","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/myself/"},{"categories":null,"content":"docker 如果本地有docker环境，也可以不用下载二进制的制品，可以通过docker 环境直接运行 docker run -it --rm russellgao/toolkit:latest tkctl --help # 如果有需要可以把目录挂载进去 docker run -it -v /data:/data --rm russellgao/toolkit:latest tkctl --help ","date":"2020-11-08","objectID":"/opensrouce/myself/:3:2","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/myself/"},{"categories":null,"content":"适用范围 可以跨平台使用 mac windows linux ","date":"2020-11-08","objectID":"/opensrouce/myself/:4:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/myself/"},{"categories":null,"content":"开发环境 go 1.14.2 ","date":"2020-11-08","objectID":"/opensrouce/myself/:5:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/myself/"},{"categories":null,"content":"支持的功能 ","date":"2020-11-08","objectID":"/opensrouce/myself/:6:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/myself/"},{"categories":null,"content":"1.0.0 文本正则替换 生成随机密码 ","date":"2020-11-08","objectID":"/opensrouce/myself/:6:1","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/myself/"},{"categories":null,"content":"未来展望 期望可以成为一个完整的工具箱，可以解决日常工作中的繁杂事情。 ","date":"2020-11-08","objectID":"/opensrouce/myself/:7:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/myself/"},{"categories":null,"content":"项目地址 https://github.com/russellgao/toolkit ","date":"2020-11-08","objectID":"/opensrouce/myself/:8:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/myself/"}]