[{"categories":null,"content":"git 常用命令","date":"2020-12-14","objectID":"/git-command/","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"导读 这篇文章主要记录了 git 的一些常用命令，后续会持续补充更新。 ","date":"2020-12-14","objectID":"/git-command/:1:0","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"常用命令 ","date":"2020-12-14","objectID":"/git-command/:2:0","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"检出代码 git clone url -b git_branch ","date":"2020-12-14","objectID":"/git-command/:2:1","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"查看分支 git branch -a ","date":"2020-12-14","objectID":"/git-command/:2:2","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"创建分支 git branch xxx ","date":"2020-12-14","objectID":"/git-command/:2:3","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"删除本地分支 git branch -d xxxxx ","date":"2020-12-14","objectID":"/git-command/:2:4","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"检出分支 git checkout git_branch ","date":"2020-12-14","objectID":"/git-command/:2:5","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"拉取代码 git pull ","date":"2020-12-14","objectID":"/git-command/:2:6","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"把修改文件提交到缓冲区 git add \u003cfilename\u003e ","date":"2020-12-14","objectID":"/git-command/:2:7","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"本地提交 git commit -m \"代码提交信息\" ","date":"2020-12-14","objectID":"/git-command/:2:8","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"推送代码 git push origin local_branch:remote_branch 例 : git push origin release/release:release/release ","date":"2020-12-14","objectID":"/git-command/:2:9","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"合并代码 git merge origin/remote ","date":"2020-12-14","objectID":"/git-command/:2:10","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"cherry pick git cherry-pick commit_id ","date":"2020-12-14","objectID":"/git-command/:2:11","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"跟踪 git branch --set-upstream-to=remote_branch local_branch 例 git branch --set-upstream-to=origin/release/release release/release ","date":"2020-12-14","objectID":"/git-command/:2:12","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"丢弃本地修改 git checkout -- file 例 git checkout -- test.py ","date":"2020-12-14","objectID":"/git-command/:2:13","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"取消本地提交 - git log 查找需要恢复的 commit_id - git reset --hard commit_id ","date":"2020-12-14","objectID":"/git-command/:2:14","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"本地清除git上已经删除的分支 git remote prune origin ","date":"2020-12-14","objectID":"/git-command/:2:15","tags":["git","cli"],"title":"git 常用命令","uri":"/git-command/"},{"categories":null,"content":"docker 原理之本地存储","date":"2020-12-09","objectID":"/docker-local-storage/","tags":["docker","存储"],"title":"docker 原理之本地存储","uri":"/docker-local-storage/"},{"categories":null,"content":"导读 在前面的文章docker 原理之存储驱动中简单的介绍了 Docker 的存储驱动，这篇文章接着讲存储，目前的 docker 版本中默认的是 overlay2 ，所以这篇文章就以 overlay2 为例带大家看看，在我们执行 docker build ，docker pull，docker run 等命令时本地存储有何变化。 这篇文章比较长，如果看不完可以收藏起来后续需要用到的时候再查阅，称的上是干货满满，作者自己整理也花了较长的时间。 ","date":"2020-12-09","objectID":"/docker-local-storage/:1:0","tags":["docker","存储"],"title":"docker 原理之本地存储","uri":"/docker-local-storage/"},{"categories":null,"content":"背景 查看 docker Storage Driver 可以通过 docker info | grep \"Storage Driver\"命令。 docker 的默认安装目录为： /var/lib/docker，如果要修改可以通过修改启动时的配置文件(默认为/usr/lib/systemd/system/docker.service) 中的 ExecStart， 查看 docker 启动时的配置文件: 修改 docker 的存储目录: 修改(增加) --graph 即可。 ","date":"2020-12-09","objectID":"/docker-local-storage/:2:0","tags":["docker","存储"],"title":"docker 原理之本地存储","uri":"/docker-local-storage/"},{"categories":null,"content":"本地目录 [root@iZuf685opgs9oyozju9i2bZ docker]# ll 总用量 48 drwx------ 2 root root 4096 11月 11 08:49 builder drwx--x--x 4 root root 4096 11月 11 08:49 buildkit drwx------ 3 root root 4096 12月 2 09:25 containers drwx------ 3 root root 4096 11月 11 08:49 image drwxr-x--- 3 root root 4096 11月 11 08:49 network drwx------ 9 root root 4096 12月 2 09:25 overlay2 drwx------ 4 root root 4096 11月 11 08:49 plugins drwx------ 2 root root 4096 11月 11 08:49 runtimes drwx------ 2 root root 4096 11月 11 08:49 swarm drwx------ 2 root root 4096 11月 11 13:32 tmp drwx------ 2 root root 4096 11月 11 08:49 trust drwx------ 2 root root 4096 11月 11 08:49 volumes 可以用 tree 进行展开 [root@iZuf685opgs9oyozju9i2bZ docker]# tree -L 2 . ├── builder │ └── fscache.db ├── buildkit │ ├── cache.db │ ├── content │ ├── executor │ ├── metadata.db │ └── snapshots.db ├── containers │ └── 9bd6ac07a8c962e2403203e1c45f4fb54733f9953cf318b34fc3f155bf2c0c59 ├── image │ └── overlay2 ├── network │ └── files ├── overlay2 │ ├── 00b65b9c288df8c0ae7cdacba531a7dc5cb006e6c768e19ee36055717b782acc │ ├── 1e53dddb1a0bb04ee4ebd24a8edb94b96e2fd471a72bf1b8608096b38cb16646 │ ├── 1e53dddb1a0bb04ee4ebd24a8edb94b96e2fd471a72bf1b8608096b38cb16646-init │ ├── 5da215c4f218cbb1d9825fa111c21bf381dc35a9e6c7c6cd5c3ea952316031e4 │ ├── 8cbfb8b74c887e780747c8e6f4b3b9223a513ff6d69770bac16abb76da4e314f │ ├── f1cf8b173467c98e08f3d276d7ccd8f9892c7c71dec2c4b335c39c6f175ae744 │ └── l ├── plugins │ ├── storage │ └── tmp ├── runtimes ├── swarm ├── tmp ├── trust └── volumes └── metadata.db 26 directories, 5 files 这篇文章以分析存储为主，涉及到的目录有 image,containers,overlay2，其他的目录放在后续的文章讨论。 在真正开始之前，先想想几个问题(这也是我自己问我自己的问题) : docker build 的过程是怎样的? docker pull 和 docker build 产生的镜像存放在哪了？ docker run 运行一个容器的时候过程是怎么样的? 带着这些问题我们以一个例子进行说明 russellgao/openresty:1.17.8.2-5-alpine ","date":"2020-12-09","objectID":"/docker-local-storage/:3:0","tags":["docker","存储"],"title":"docker 原理之本地存储","uri":"/docker-local-storage/"},{"categories":null,"content":"image image 目录主要存放的镜像相关的信息，我们执行 docker pull russellgao/openresty:1.17.8.2-5-alpine 看看： [root@iZuf685opgs9oyozju9i2bZ docker]# docker pull russellgao/openresty:1.17.8.2-5-alpine 1.17.8.2-5-alpine: Pulling from russellgao/openresty df20fa9351a1: Already exists 5682af42731d: Pull complete 7c6cb2b54a9d: Pull complete aa74dc345098: Pull complete Digest: sha256:224ced85b5f8b679a8664a39b69c1b8feb09f8ba4343d834bd5b69433081389e Status: Downloaded newer image for openresty/openresty:1.17.8.2-5-alpine 可以看到 pull 了 4 层下来了，我们看看 image 目录: [root@iZuf685opgs9oyozju9i2bZ docker]# tree image image └── overlay2 ├── distribution │ ├── diffid-by-digest │ │ └── sha256 │ │ ├── 5682af42731d652bd98d2456ed3da4f0595ed5d9e5b13ac8bb9590bb74f72eb8 │ │ ├── 7c6cb2b54a9d9d40c4a03dd6615b1c8e791feb5d81464a7702a9bb921f7a73e9 │ │ ├── aa74dc3450985aee599c181d650da8f8880ca1d6e2bc01a43831ca59b6e2a7b6 │ │ └── df20fa9351a15782c64e6dddb2d4a6f50bf6d3688060a34c4014b0d9a752eb4c │ └── v2metadata-by-diffid │ └── sha256 │ ├── 1680a9f16b18732726d0656b6d6ff9611a3c4460ca870827b537a87bbe10cc22 │ ├── 50644c29ef5a27c9a40c393a73ece2479de78325cae7d762ef3cdc19bf42dd0a │ ├── 8521b614863046bf4bb604e3586feeca8b7ce1372f1d6664a5545e85ad9ca472 │ └── 9c572ba82b91e3ac35c7351bdacc6876c67f5d9bc69c5e51e8b2deeafae95e4f ├── imagedb │ ├── content │ │ └── sha256 │ │ └── 1ddc7a18ba0bcc20c61447f391bfff98ac559eea590e7ac59b5b5f588f1f47ed │ └── metadata │ └── sha256 │ └── 1ddc7a18ba0bcc20c61447f391bfff98ac559eea590e7ac59b5b5f588f1f47ed │ └── lastUpdated ├── layerdb │ ├── mounts │ │ └── 9bd6ac07a8c962e2403203e1c45f4fb54733f9953cf318b34fc3f155bf2c0c59 │ │ ├── init-id │ │ ├── mount-id │ │ └── parent │ ├── sha256 │ │ ├── 228fb92e31891f472e9857ee11d13c404ff7c88e808b05ce4ebdc80d785d71f3 │ │ │ ├── cache-id │ │ │ ├── diff │ │ │ ├── parent │ │ │ ├── size │ │ │ └── tar-split.json.gz │ │ ├── 50644c29ef5a27c9a40c393a73ece2479de78325cae7d762ef3cdc19bf42dd0a │ │ │ ├── cache-id │ │ │ ├── diff │ │ │ ├── size │ │ │ └── tar-split.json.gz │ │ ├── 5f72760956a669e4c9b33aa3f2f04baa84b0f4cf1e11676049981bafcbba74da │ │ │ ├── cache-id │ │ │ ├── diff │ │ │ ├── parent │ │ │ ├── size │ │ │ └── tar-split.json.gz │ │ └── fe267088885017d5e9a4621e68617a7f35e58dc2d0d747927882da21059854e3 │ │ ├── cache-id │ │ ├── diff │ │ ├── parent │ │ ├── size │ │ └── tar-split.json.gz │ └── tmp └── repositories.json 21 directories, 33 files 看看 repositories.json 中是内容 : [root@iZuf685opgs9oyozju9i2bZ docker]# cat image/overlay2/repositories.json | jq . { \"Repositories\": { \"openresty/openresty\": { \"openresty/openresty:1.17.8.2-5-alpine\": \"sha256:1ddc7a18ba0bcc20c61447f391bfff98ac559eea590e7ac59b5b5f588f1f47ed\", \"openresty/openresty@sha256:224ced85b5f8b679a8664a39b69c1b8feb09f8ba4343d834bd5b69433081389e\": \"sha256:1ddc7a18ba0bcc20c61447f391bfff98ac559eea590e7ac59b5b5f588f1f47ed\" }, \"russellgao/openresty\": { \"russellgao/openresty:1.17.8.2-5-alpine\": \"sha256:1ddc7a18ba0bcc20c61447f391bfff98ac559eea590e7ac59b5b5f588f1f47ed\", \"russellgao/openresty@sha256:84f53dc7517e9b6695fc8fd74916a1eb5970a92fc24a984f99bfb81508f3d261\": \"sha256:1ddc7a18ba0bcc20c61447f391bfff98ac559eea590e7ac59b5b5f588f1f47ed\" } } } repositories.json 中记录了这个机器上所有的镜像，可以看到这里有两个镜像 openresty/openresty:1.17.8.2-5-alpine 和 russellgao/openresty:1.17.8.2-5-alpine ，但其实只有一个镜像，因为后面的 imageid 是相同的，这个可以 docker images 验证一下 [root@iZuf685opgs9oyozju9i2bZ docker]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE openresty/openresty 1.17.8.2-5-alpine 1ddc7a18ba0b 2 months ago 104MB russellgao/openresty 1.17.8.2-5-alpine 1ddc7a18ba0b 2 months ago 104MB openresty/openresty:1.17.8.2-5-alpine 和 russellgao/openresty:1.17.8.2-5-alpine 只是镜像 1ddc7a18ba0b 的 tag 。 那么 1ddc7a18ba0b 镜像是怎么组成的呢? image/overlay2/ 下面除了 repositories.json 还有3个目录 distribution,imagedb,layerdb，作用分别如下: distribution: 主要和镜像仓库的交互相关 imagedb: 保存了镜像的元数据 layerdb: 保存了镜像layer(层) 的数据 image/overlay2/ 保存的是数据的链接，真正的镜像数据是存放在 overlay2 目录下，先看看 distribution : ","date":"2020-12-09","objectID":"/docker-local-storage/:3:1","tags":["docker","存储"],"title":"docker 原理之本地存储","uri":"/docker-local-storage/"},{"categories":null,"content":"distribution [root@iZuf685opgs9oyozju9i2bZ docker]# tree image/overlay2/distribution/ image/overlay2/distribution/ ├── diffid-by-digest │ └── sha256 │ ├── 5682af42731d652bd98d2456ed3da4f0595ed5d9e5b13ac8bb9590bb74f72eb8 │ ├── 7c6cb2b54a9d9d40c4a03dd6615b1c8e791feb5d81464a7702a9bb921f7a73e9 │ ├── aa74dc3450985aee599c181d650da8f8880ca1d6e2bc01a43831ca59b6e2a7b6 │ └── df20fa9351a15782c64e6dddb2d4a6f50bf6d3688060a34c4014b0d9a752eb4c └── v2metadata-by-diffid └── sha256 ├── 1680a9f16b18732726d0656b6d6ff9611a3c4460ca870827b537a87bbe10cc22 ├── 50644c29ef5a27c9a40c393a73ece2479de78325cae7d762ef3cdc19bf42dd0a ├── 8521b614863046bf4bb604e3586feeca8b7ce1372f1d6664a5545e85ad9ca472 └── 9c572ba82b91e3ac35c7351bdacc6876c67f5d9bc69c5e51e8b2deeafae95e4f 4 directories, 8 files 请注意看 image/overlay2/distribution/diffid-by-digest/sha256 下面，回过头再看看 docker pull 的过程，这里的就是 digestid ，docker pull 的时候也是通过 digestid 实现的，这个id对应的是 docker repository 中的 blob id，在 docker repository 的 blobs 目录下可以找到。 可以查看具体的文件，如 cat image/overlay2/distribution/diffid-by-digest/sha256/5682af42731d652bd98d2456ed3da4f0595ed5d9e5b13ac8bb9590bb74f72eb8 [root@iZuf685opgs9oyozju9i2bZ docker]# cat image/overlay2/distribution/diffid-by-digest/sha256/5682af42731d652bd98d2456ed3da4f0595ed5d9e5b13ac8bb9590bb74f72eb8 sha256:9c572ba82b91e3ac35c7351bdacc6876c67f5d9bc69c5e51e8b2deeafae95e4f 不难发现它们之间是相互引用的，可以实现 diffid 和 digest 的相互转换。 ","date":"2020-12-09","objectID":"/docker-local-storage/:3:2","tags":["docker","存储"],"title":"docker 原理之本地存储","uri":"/docker-local-storage/"},{"categories":null,"content":"imagedb [root@iZuf685opgs9oyozju9i2bZ docker]# tree image/overlay2/imagedb/ image/overlay2/imagedb/ ├── content │ └── sha256 │ └── 1ddc7a18ba0bcc20c61447f391bfff98ac559eea590e7ac59b5b5f588f1f47ed └── metadata └── sha256 └── 1ddc7a18ba0bcc20c61447f391bfff98ac559eea590e7ac59b5b5f588f1f47ed └── lastUpdated 5 directories, 2 files 可以看到 imagedb 是以镜像为单位进行存储的，看一下 content 下面的具体内容 : [root@iZuf685opgs9oyozju9i2bZ docker]# cat image/overlay2/imagedb/content/sha256/1ddc7a18ba0bcc20c61447f391bfff98ac559eea590e7ac59b5b5f588f1f47ed | jq . { \"architecture\": \"amd64\", \"config\": { \"Hostname\": \"\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/openresty/luajit/bin:/usr/local/openresty/nginx/sbin:/usr/local/openresty/bin\" ], \"Cmd\": [ \"/usr/local/openresty/bin/openresty\", \"-g\", \"daemon off;\" ], \"ArgsEscaped\": true, \"Image\": \"sha256:0b827067ad09ab8a0b9a73a45f5b1c408b84db1ca6883a4c544078ed43b8b5e3\", \"Volumes\": null, \"WorkingDir\": \"\", \"Entrypoint\": null, \"OnBuild\": null, \"Labels\": { \"maintainer\": \"Evan Wies \u003cevan@neomantra.net\u003e\", \"resty_add_package_builddeps\": \"\", \"resty_add_package_rundeps\": \"\", \"resty_config_deps\": \"--with-pcre --with-cc-opt='-DNGX_LUA_ABORT_AT_PANIC -I/usr/local/openresty/pcre/include -I/usr/local/openresty/openssl/include' --with-ld-opt='-L/usr/local/openresty/pcre/lib -L/usr/local/openresty/openssl/lib -Wl,-rpath,/usr/local/openresty/pcre/lib:/usr/local/openresty/openssl/lib' \", \"resty_config_options\": \" --with-compat --with-file-aio --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_geoip_module=dynamic --with-http_gunzip_module --with-http_gzip_static_module --with-http_image_filter_module=dynamic --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-http_xslt_module=dynamic --with-ipv6 --with-mail --with-mail_ssl_module --with-md5-asm --with-pcre-jit --with-sha1-asm --with-stream --with-stream_ssl_module --with-threads \", \"resty_config_options_more\": \"\", \"resty_eval_post_make\": \"\", \"resty_eval_pre_configure\": \"\", \"resty_image_base\": \"alpine\", \"resty_image_tag\": \"3.12\", \"resty_openssl_patch_version\": \"1.1.1f\", \"resty_openssl_url_base\": \"https://www.openssl.org/source\", \"resty_openssl_version\": \"1.1.1g\", \"resty_pcre_version\": \"8.44\", \"resty_version\": \"1.17.8.2\" }, \"StopSignal\": \"SIGQUIT\" }, \"container\": \"0ae35046dd1afef0f1f525360939abc524dbd469a92470c5836dfbb7dc666923\", \"container_config\": { \"Hostname\": \"0ae35046dd1a\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/openresty/luajit/bin:/usr/local/openresty/nginx/sbin:/usr/local/openresty/bin\" ], \"Cmd\": [ \"/bin/sh\", \"-c\", \"#(nop) \", \"STOPSIGNAL SIGQUIT\" ], \"ArgsEscaped\": true, \"Image\": \"sha256:0b827067ad09ab8a0b9a73a45f5b1c408b84db1ca6883a4c544078ed43b8b5e3\", \"Volumes\": null, \"WorkingDir\": \"\", \"Entrypoint\": null, \"OnBuild\": null, \"Labels\": { \"maintainer\": \"Evan Wies \u003cevan@neomantra.net\u003e\", \"resty_add_package_builddeps\": \"\", \"resty_add_package_rundeps\": \"\", \"resty_config_deps\": \"--with-pcre --with-cc-opt='-DNGX_LUA_ABORT_AT_PANIC -I/usr/local/openresty/pcre/include -I/usr/local/openresty/openssl/include' --with-ld-opt='-L/usr/local/openresty/pcre/lib -L/usr/local/openresty/openssl/lib -Wl,-rpath,/usr/local/openresty/pcre/lib:/usr/local/openresty/openssl/lib' \", \"resty_config_options\": \" --with-compat --with-file-aio --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_geoip_module=dynamic --","date":"2020-12-09","objectID":"/docker-local-storage/:3:3","tags":["docker","存储"],"title":"docker 原理之本地存储","uri":"/docker-local-storage/"},{"categories":null,"content":"layerdb 前面我们说过，imagedb 存的是元数据，那么 layerdb 应该存的是 layer 相关信息?先看看这个目录下面有什么: [root@iZuf685opgs9oyozju9i2bZ docker]# ll image/overlay2/layerdb/ 总用量 12 drwxr-xr-x 3 root root 4096 12月 2 09:25 mounts drwxr-xr-x 6 root root 4096 11月 11 13:32 sha256 drwxr-xr-x 2 root root 4096 11月 11 13:32 tmp tmp tmp 是一个临时目录 sha256 sha256: 先看看这个下面有什么 ll image/overlay2/layerdb/sha256/ [root@iZuf685opgs9oyozju9i2bZ docker]# ll image/overlay2/layerdb/sha256/ 总用量 16 drwx------ 2 root root 4096 11月 11 13:32 228fb92e31891f472e9857ee11d13c404ff7c88e808b05ce4ebdc80d785d71f3 drwx------ 2 root root 4096 11月 11 13:31 50644c29ef5a27c9a40c393a73ece2479de78325cae7d762ef3cdc19bf42dd0a drwx------ 2 root root 4096 11月 11 13:32 5f72760956a669e4c9b33aa3f2f04baa84b0f4cf1e11676049981bafcbba74da drwx------ 2 root root 4096 11月 11 13:32 fe267088885017d5e9a4621e68617a7f35e58dc2d0d747927882da21059854e3 咋一看这里和 rootfs 中的 diff_id 并不相同，只有一层是一样的(只有base layer是相同)。这里的是 chain_id ，那么什么是 chain_id呢？ diff_id: 描述的是某一层的变化 chain_id: 描述的是一系列变化 diff_id 和 chain_id 的计算公式为: ChainID(A) = DiffID(A) ChainID(A | B) = Digest(ChainID(A) + \" \" + DiffID(B)) ChainID(A | B | C) = Digest(ChainID(A | B) + \" \" + DiffID(C)) 是不是有点绕，回到我们的例子看看： rootfs 中的 diff_id 为: \"diff_ids\": [ \"sha256:50644c29ef5a27c9a40c393a73ece2479de78325cae7d762ef3cdc19bf42dd0a\", \"sha256:9c572ba82b91e3ac35c7351bdacc6876c67f5d9bc69c5e51e8b2deeafae95e4f\", \"sha256:1680a9f16b18732726d0656b6d6ff9611a3c4460ca870827b537a87bbe10cc22\", \"sha256:8521b614863046bf4bb604e3586feeca8b7ce1372f1d6664a5545e85ad9ca472\" ] chain_id 为: drwx------ 2 root root 4096 11月 11 13:32 228fb92e31891f472e9857ee11d13c404ff7c88e808b05ce4ebdc80d785d71f3 drwx------ 2 root root 4096 11月 11 13:31 50644c29ef5a27c9a40c393a73ece2479de78325cae7d762ef3cdc19bf42dd0a drwx------ 2 root root 4096 11月 11 13:32 5f72760956a669e4c9b33aa3f2f04baa84b0f4cf1e11676049981bafcbba74da drwx------ 2 root root 4096 11月 11 13:32 fe267088885017d5e9a4621e68617a7f35e58dc2d0d747927882da21059854e3 根据上面的公式 base layer 的 diff_id 和 chain_id 是相同的: 50644c29ef5a27c9a40c393a73ece2479de78325cae7d762ef3cdc19bf42dd0a -\u003e 50644c29ef5a27c9a40c393a73ece2479de78325cae7d762ef3cdc19bf42dd0a 在继续看看下面的算法 [root@iZuf685opgs9oyozju9i2bZ docker]# echo -n \"sha256:50644c29ef5a27c9a40c393a73ece2479de78325cae7d762ef3cdc19bf42dd0a sha256:9c572ba82b91e3ac35c7351bdacc6876c67f5d9bc69c5e51e8b2deeafae95e4f\" | sha256sum fe267088885017d5e9a4621e68617a7f35e58dc2d0d747927882da21059854e3 - [root@iZuf685opgs9oyozju9i2bZ docker]# [root@iZuf685opgs9oyozju9i2bZ docker]# echo -n \"sha256:fe267088885017d5e9a4621e68617a7f35e58dc2d0d747927882da21059854e3 sha256:1680a9f16b18732726d0656b6d6ff9611a3c4460ca870827b537a87bbe10cc22\" | sha256sum 5f72760956a669e4c9b33aa3f2f04baa84b0f4cf1e11676049981bafcbba74da - [root@iZuf685opgs9oyozju9i2bZ docker]# echo -n \"sha256:5f72760956a669e4c9b33aa3f2f04baa84b0f4cf1e11676049981bafcbba74da sha256:8521b614863046bf4bb604e3586feeca8b7ce1372f1d6664a5545e85ad9ca472\" | sha256sum 228fb92e31891f472e9857ee11d13c404ff7c88e808b05ce4ebdc80d785d71f3 - 这么一演算就事情就变的清晰起来了: 50644c29ef5a27c9a40c393a73ece2479de78325cae7d762ef3cdc19bf42dd0a -\u003e 50644c29ef5a27c9a40c393a73ece2479de78325cae7d762ef3cdc19bf42dd0a 9c572ba82b91e3ac35c7351bdacc6876c67f5d9bc69c5e51e8b2deeafae95e4f -\u003e fe267088885017d5e9a4621e68617a7f35e58dc2d0d747927882da21059854e3 1680a9f16b18732726d0656b6d6ff9611a3c4460ca870827b537a87bbe10cc22 -\u003e 5f72760956a669e4c9b33aa3f2f04baa84b0f4cf1e11676049981bafcbba74da 8521b614863046bf4bb604e3586feeca8b7ce1372f1d6664a5545e85ad9ca472 -\u003e 228fb92e31891f472e9857ee11d13c404ff7c88e808b05ce4ebdc80d785d71f3 理清它们之间的关系就比较好办了，在看看 chain_id 目录下都有什么: [root@iZuf685opgs9oyozju9i2bZ docker]# tree image/overlay2/layerdb/sha256/ image/overlay2/layerdb/sha256/ ├── 228fb92e31891f472e9857ee11d13c404ff7c88e808b05ce4ebdc80d785d71f3 │ ├── cache-id │ ├── diff │ ├── parent │ ├── size │ └── tar-split.json.gz ├── 50644c29ef5a27c9a40c393a73ece2479de78325cae7d762ef3cdc19bf42dd0a │ ├── cache-id │ ├── diff │ ├── size │ └── tar-split.json.gz ├── 5f72760956a669e4c9b33aa3f2f04baa84b","date":"2020-12-09","objectID":"/docker-local-storage/:3:4","tags":["docker","存储"],"title":"docker 原理之本地存储","uri":"/docker-local-storage/"},{"categories":null,"content":"overlay2 overlay2 目录存放的每一层的具体数据，先看看目录结构: [root@iZuf685opgs9oyozju9i2bZ docker]# tree overlay2/ -L 2 [root@iZuf685opgs9oyozju9i2bZ docker]# tree -L 2 overlay2/ overlay2/ ├── 00b65b9c288df8c0ae7cdacba531a7dc5cb006e6c768e19ee36055717b782acc │ ├── committed │ ├── diff │ ├── link │ ├── lower │ └── work ├── 5da215c4f218cbb1d9825fa111c21bf381dc35a9e6c7c6cd5c3ea952316031e4 │ ├── committed │ ├── diff │ ├── link │ ├── lower │ └── work ├── 8cbfb8b74c887e780747c8e6f4b3b9223a513ff6d69770bac16abb76da4e314f │ ├── committed │ ├── diff │ └── link ├── b04b728c94b5a269e9d102329c930e3781212717e830e1941e1008088d823cdc │ ├── diff │ ├── link │ ├── lower │ ├── merged │ └── work ├── b04b728c94b5a269e9d102329c930e3781212717e830e1941e1008088d823cdc-init │ ├── committed │ ├── diff │ ├── link │ ├── lower │ └── work ├── f1cf8b173467c98e08f3d276d7ccd8f9892c7c71dec2c4b335c39c6f175ae744 │ ├── committed │ ├── diff │ ├── link │ ├── lower │ └── work └── l ├── 2NFRHNZBFYCUAPMTFCKUR5R4DS -\u003e ../b04b728c94b5a269e9d102329c930e3781212717e830e1941e1008088d823cdc/diff ├── 33RV26M4VMX3ZUISOG26USXBKR -\u003e ../f1cf8b173467c98e08f3d276d7ccd8f9892c7c71dec2c4b335c39c6f175ae744/diff ├── BGEYC7V6ULKFOOIITWCEKITQEU -\u003e ../b04b728c94b5a269e9d102329c930e3781212717e830e1941e1008088d823cdc-init/diff ├── HG76ICE67NTXFL7AYXCMI3EK4Y -\u003e ../00b65b9c288df8c0ae7cdacba531a7dc5cb006e6c768e19ee36055717b782acc/diff ├── L5XCYQVZ6DOSLJNP6HXCZQZ7A5 -\u003e ../5da215c4f218cbb1d9825fa111c21bf381dc35a9e6c7c6cd5c3ea952316031e4/diff └── MUHXHRXFSGNCBKQ2AUXDFOUDLF -\u003e ../8cbfb8b74c887e780747c8e6f4b3b9223a513ff6d69770bac16abb76da4e314f/diff 25 directories, 16 files 可以看到 overlay2 一级目录下有个特殊目录 l , l 下是各个layer 软链接，防止mount 命令太长而发生错误，所以就用短链接了。 细心的你一定发现了这么几个问题: 这个镜像只有 4 个层，这里为啥会有 6 个层(目录) 为啥具体layer 下的目录/文件结构不一样 有的 layer 为啥带了 -init 后缀，有的没有 有 6 个layer 层是因为我这里启动了一个容器，会生成两个层(读写层和这个镜像merged之后的只读层)，删除容器之后看看: [root@iZuf685opgs9oyozju9i2bZ docker]# docker rm -f openresty-app-1 openresty-app-1 [root@iZuf685opgs9oyozju9i2bZ docker]# ll overlay2/ 总用量 20 drwx------ 4 root root 4096 11月 11 13:32 00b65b9c288df8c0ae7cdacba531a7dc5cb006e6c768e19ee36055717b782acc drwx------ 4 root root 4096 11月 11 13:48 5da215c4f218cbb1d9825fa111c21bf381dc35a9e6c7c6cd5c3ea952316031e4 drwx------ 3 root root 4096 11月 11 13:32 8cbfb8b74c887e780747c8e6f4b3b9223a513ff6d69770bac16abb76da4e314f drwx------ 4 root root 4096 11月 11 13:32 f1cf8b173467c98e08f3d276d7ccd8f9892c7c71dec2c4b335c39c6f175ae744 drwx------ 2 root root 4096 12月 12 13:29 l 这下和之前讨论对上了， 和 cache-id 中的内容一一对应 [root@iZuf685opgs9oyozju9i2bZ docker]# ll image/overlay2/layerdb/sha256/*/cache-id -rw-r--r-- 1 root root 64 11月 11 13:32 image/overlay2/layerdb/sha256/228fb92e31891f472e9857ee11d13c404ff7c88e808b05ce4ebdc80d785d71f3/cache-id -rw-r--r-- 1 root root 64 11月 11 13:31 image/overlay2/layerdb/sha256/50644c29ef5a27c9a40c393a73ece2479de78325cae7d762ef3cdc19bf42dd0a/cache-id -rw-r--r-- 1 root root 64 11月 11 13:32 image/overlay2/layerdb/sha256/5f72760956a669e4c9b33aa3f2f04baa84b0f4cf1e11676049981bafcbba74da/cache-id -rw-r--r-- 1 root root 64 11月 11 13:32 image/overlay2/layerdb/sha256/fe267088885017d5e9a4621e68617a7f35e58dc2d0d747927882da21059854e3/cache-id 在看看具体镜像 layer 层的内容: diff: 这个层所做的改动，如通过 ADD、RUN 等指令对做文件系统做出的改变都在这里了。 link: 自己的link值，在刚刚的 overlay2/l 目录下可以看的到。 [root@iZuf685opgs9oyozju9i2bZ docker]# cat overlay2/00b65b9c288df8c0ae7cdacba531a7dc5cb006e6c768e19ee36055717b782acc/link HG76ICE67NTXFL7AYXCMI3EK4Y lower: 该层所依赖的层的所有link，base layer 不依赖任何层，所以也就不会有 lower 这个文件，最后一层依赖之前的所有层，如: [root@iZuf685opgs9oyozju9i2bZ docker]# cat overlay2/5da215c4f218cbb1d9825fa111c21bf381dc35a9e6c7c6cd5c3ea952316031e4/lower l/HG76ICE67NTXFL7AYXCMI3EK4Y:l/33RV26M4VMX3ZUISOG26USXBKR:l/MUHXHRXFSGNCBKQ2AUXDFOUDLF 这个镜像的最后一层依赖前面的层 merged:容器的最终视图，merge 了 镜像层加读写层 启动容器新建的两层在 containers 中详细说。 ","date":"2020-12-09","objectID":"/docker-local-storage/:3:5","tags":["docker","存储"],"title":"docker 原理之本地存储","uri":"/docker-local-storage/"},{"categories":null,"content":"containers 我们一直说 docker 镜像是分层的， 容器 = 镜像 + 读写层 ，如果还没有什么感觉的话不妨再来看一个图: 可以看到容器是依赖于镜像，启动容器时会先把镜像的各个 layer 联合挂载成一个统一的视图(只读层)，就是我们在 overlay2 目录中看到的 b04b728c94b5a269e9d102329c930e3781212717e830e1941e1008088d823cdc-init 目录， 去掉 -init 就是对应的读写层。 看看 containers 目录下都有什么: [root@iZuf685opgs9oyozju9i2bZ docker]# tree -L 2 containers/ containers/ └── 4ec800c3ec10654a6ea2b2317ac198514748464a217ef63bb58ef67874a79ae0 ├── 4ec800c3ec10654a6ea2b2317ac198514748464a217ef63bb58ef67874a79ae0-json.log ├── checkpoints ├── config.v2.json ├── hostconfig.json ├── hostname ├── hosts ├── mounts ├── resolv.conf └── resolv.conf.hash 3 directories, 7 files [root@iZuf685opgs9oyozju9i2bZ docker]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4ec800c3ec10 russellgao/openresty:1.17.8.2-5-alpine \"/usr/local/openrest…\" About an hour ago Up About an hour 0.0.0.0:80-\u003e80/tcp, 0.0.0.0:443-\u003e443/tcp openresty-app-1 可以看到这个下面是以容器为单位进行存放的，保存了每个容器的详细配置，在容器里看到的hostname,/etc/hosts,dns 等各种配置在这里都可以找得到，这里就不展开看每个具体文件了，有兴趣者可以自行查看。 值得一提的是，通过 docker inspect containername 得到的内容在 containers/xxx/config.v2.json 都可以找的到哦，可以查看它们的输出，会发现出奇的相似哦。 请注意好玩的事情来了 我们说到 容器=镜像+读写层 ，那是不是以为着我们在读写层做修改，容器中可以看到，反之在容器中做的修改，在读写层也应该能看到才对。 读写层时各临时的 layer 层(临时目录) ，当容器被删除时，这个 layer 也会随之被删除。 做了实验看看: 最初读写层的内容和容器的根目录如下: [root@iZuf685opgs9oyozju9i2bZ docker]# ll overlay2/b04b728c94b5a269e9d102329c930e3781212717e830e1941e1008088d823cdc/diff/ 总用量 16 drwxr-xr-x 3 root root 4096 9月 19 00:25 run drwxr-xr-x 3 root root 4096 9月 19 00:25 usr [root@iZuf685opgs9oyozju9i2bZ docker]# [root@iZuf685opgs9oyozju9i2bZ docker]# docker exec openresty-app-1 ls -l / total 64 drwxr-xr-x 1 root root 4096 Sep 18 16:25 bin drwxr-xr-x 5 root root 340 Dec 12 05:29 dev drwxr-xr-x 1 root root 4096 Dec 12 05:29 etc drwxr-xr-x 2 root root 4096 May 29 2020 home drwxr-xr-x 1 root root 4096 Sep 18 16:25 lib drwxr-xr-x 5 root root 4096 May 29 2020 media drwxr-xr-x 2 root root 4096 May 29 2020 mnt drwxr-xr-x 2 root root 4096 May 29 2020 opt dr-xr-xr-x 114 root root 0 Dec 12 05:29 proc drwx------ 2 root root 4096 May 29 2020 root drwxr-xr-x 1 root root 4096 Sep 18 16:25 run drwxr-xr-x 2 root root 4096 May 29 2020 sbin drwxr-xr-x 2 root root 4096 May 29 2020 srv dr-xr-xr-x 13 root root 0 Nov 11 00:49 sys drwxrwxrwt 1 root root 4096 Sep 18 16:25 tmp drwxr-xr-x 1 root root 4096 Sep 18 16:25 usr drwxr-xr-x 1 root root 4096 May 29 2020 var 进入到容器并在根目录生成一个文件: [root@iZuf685opgs9oyozju9i2bZ docker]# docker exec -it openresty-app-1 sh / # echo \"测试容器的读写层-20201209\" \u003e /test-layer.20201209.txt 读写层看看什么情况: [root@iZuf685opgs9oyozju9i2bZ docker]# ll overlay2/b04b728c94b5a269e9d102329c930e3781212717e830e1941e1008088d823cdc/diff/ 总用量 24 drwx------ 2 root root 4096 12月 12 15:22 root drwxr-xr-x 3 root root 4096 9月 19 00:25 run -rw-r--r-- 1 root root 34 12月 12 15:22 test-layer.20201209.txt drwxr-xr-x 3 root root 4096 9月 19 00:25 usr [root@iZuf685opgs9oyozju9i2bZ docker]# cat overlay2/b04b728c94b5a269e9d102329c930e3781212717e830e1941e1008088d823cdc/diff/test-layer.20201209.txt 测试容器的读写层-20201209 可以看到在容器中新建的文件确实在读写层中可以看到，那么反过来再试试 在读写层新建一个文件: [root@iZuf685opgs9oyozju9i2bZ docker]# echo \"测试容器的读写层-20201209-abcdefg\" \u003e overlay2/b04b728c94b5a269e9d102329c930e3781212717e830e1941e1008088d823cdc/diff/test-layer.20201209-abcdefg.txt [root@iZuf685opgs9oyozju9i2bZ docker]# ll overlay2/b04b728c94b5a269e9d102329c930e3781212717e830e1941e1008088d823cdc/diff/ 总用量 28 drwx------ 2 root root 4096 12月 12 15:22 root drwxr-xr-x 3 root root 4096 9月 19 00:25 run -rw-r--r-- 1 root root 42 12月 12 15:26 test-layer.20201209-abcdefg.txt -rw-r--r-- 1 root root 34 12月 12 15:22 test-layer.20201209.txt drwxr-xr-x 3 root root 4096 9月 19 00:25 usr 进到容器中看看: [root@iZuf685opgs9oyozju9i2bZ docker]# docker exec -it openresty-app-1 sh / # ls -l total 72 drwxr-xr-x 1 root root 4096 Sep 18 16:25 bin drwxr-xr-x 5 root root 340 Dec 12 05:29 dev drwxr-xr-x 1 root root 4096 Dec 12 05:29 etc drwxr-xr-x 2 root root 4096 May 29 2020 home drwxr-xr-x 1 root root 4096 Sep 18 16:25 lib drwxr-xr-x 5 root root 4096 May 2","date":"2020-12-09","objectID":"/docker-local-storage/:3:6","tags":["docker","存储"],"title":"docker 原理之本地存储","uri":"/docker-local-storage/"},{"categories":null,"content":"总结 这篇文章很长，难免表达逻辑上出现混乱，感谢能耐心看完的小伙伴，如果有不对之处欢迎批评指正。 image/overlay2 distribution: 和镜像分发相关，记录了diffid 与 digest 之间的关系。 imagedb: 记录了镜像的元信息，其中content中的内容和docker inspect image 结果基本一直。 layerdb: 记录了 layer 的元信息，如真正的 layerid， size 等信息。 repositories.json: 记录这个主机上所有的镜像。 overlay2: 镜像的具体layer 层的内容，包括镜像的只读层和容器的读写层。其中读写层是临时层，当容器删除时也会随之删除，在这一层的 diff 目录下做修改，容器内也会随之看到。 containers: 容器的配置信息，通过 docker inspect containerid 得到的结果和 containers/xxx 下的内容基本一直。 ","date":"2020-12-09","objectID":"/docker-local-storage/:4:0","tags":["docker","存储"],"title":"docker 原理之本地存储","uri":"/docker-local-storage/"},{"categories":null,"content":"参考 https://segmentfault.com/a/1190000017579626 ","date":"2020-12-09","objectID":"/docker-local-storage/:5:0","tags":["docker","存储"],"title":"docker 原理之本地存储","uri":"/docker-local-storage/"},{"categories":null,"content":"Python 中的迭代器与生成器","date":"2020-12-07","objectID":"/python-iter/","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python-iter/"},{"categories":null,"content":"导读 这篇文章主要介绍了 python 当中的迭代器与生成器，在涉及到大数量的场景应该考虑使用迭代器与生成器。 ","date":"2020-12-07","objectID":"/python-iter/:1:0","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python-iter/"},{"categories":null,"content":"可迭代对象 如果一个对象实现了 __iter__ 方法，那么我们就称它是一个可迭代对象。如果没有实现 __iter__ 而实现了 __getitem__ 方法，并且其参数是从0开始索引的，这种对象也是可迭代的，比如说序列。 使用 iter 内置函数可以获取迭代器的对象，当解释器需要迭代对象时，会自动调用 item(x) ： 如果对象实现了 __iter__ 方法，获取一个迭代器 如果没有实现 __iter__ ，但是实现了 __getitem__ ，python 会创建一个迭代器，尝试从索引0开始获取元素 如果获取失败，则抛出 TypeError 标准序列都实现了 __iter__ 方法，所以标准序列都是可迭代对象。如 list,dict,set,tuple。 只有实现了 __iter__ 方法的对象能通过子类测试issubclass(Object,abc.Itertor) 检查对象能否迭代最标准的方法是调用 iter() 函数，因为 iter() 会考虑到实现 __getitem__ 方法的部分可迭代对象。 ","date":"2020-12-07","objectID":"/python-iter/:2:0","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python-iter/"},{"categories":null,"content":"迭代器 迭代器主要用于从集合中取出元素，那么是什么迭代器呢? 实现了 next 方法的可迭代对象就是迭代器。 next 返回下一个可用的元素，当没有元素时抛出 StopIteration 异常。 __iter__ ，迭代器本身。 到这里应该可以看出「可迭代对象」与 「迭代器」的区别了，就是在于有没有实现next 方法 。 检查对象是不是一个迭代器 ：isinstance(object,abc.Iterator) 。 ","date":"2020-12-07","objectID":"/python-iter/:3:0","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python-iter/"},{"categories":null,"content":"迭代器模式 按需一次获取一个数据项。 迭代器模式的用途有： 访问一个聚合对象而无需暴露它的内部结构 支持对聚合对象的多种遍历 为遍历不同的聚合结构提供一个统一的接口 说了这么多，那么除了标准序列之外，如何自定义一个迭代器呢，看看下面的代码： class Books: def __init__(self, books): self.books = books.split(\",\") def __iter__(self): return BookIterator(self.books) class BookIterator: def __init__(self, books): self.books = books self.index = 0 def next(self): try : book = self.books[self.index] except IndexError: raise StopIteration() self.index += 1 return book def __iter__(self): return self books = Books(\"python,golang,vue,kubernetes,istio\") print(books) for book in books : print(book) ","date":"2020-12-07","objectID":"/python-iter/:3:1","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python-iter/"},{"categories":null,"content":"生成器 生成器是一种特殊的迭代器，这种迭代器更加优雅，不需要像上面一样写 __iter__ 和 next 方法了，只需要一个 yield 关键字即可。 生成器有两种方法用: yield () 生成 ","date":"2020-12-07","objectID":"/python-iter/:4:0","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python-iter/"},{"categories":null,"content":"yield def gen(x) : for i in range(x) : yield i * 2 g1 = gen(10) ","date":"2020-12-07","objectID":"/python-iter/:4:1","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python-iter/"},{"categories":null,"content":"() 生成器 l1 = [ i * 2 for i in range(10) ] g1 = (i * 2 for i in range(10)) for i in g1 : print(i) print(l1) l1 是一个列表推导式 g1 是一个生成器 两者的区别是 g1 生成器采用懒加载的方式，不会一次把数据加载到内存中 生成器的好处不用把数据全部加载到内存中，访问到的时候在计算出来。例如有 100w 的数据集，但是只需要访问前 100 个，是不是生成器就很有用了。 ","date":"2020-12-07","objectID":"/python-iter/:4:2","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python-iter/"},{"categories":null,"content":"特别说明 上述写法为 python2 的写法，python3 略有不同，python3 中 next 方法对应的为 __next__ ，如上面的 Books 例子对应的写法为: class Books: def __init__(self, books): self.books = books.split(\",\") def __iter__(self): return BookIterator(self.books) class BookIterator: def __init__(self, books): self.books = books self.index = 0 def __next__(self): try : book = self.books[self.index] except IndexError: raise StopIteration() self.index += 1 return book def __iter__(self): return self books = Books(\"python,golang,vue,kubernetes,istio\") print(books) for book in books : print(book) ","date":"2020-12-07","objectID":"/python-iter/:5:0","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python-iter/"},{"categories":null,"content":"总结 任何对象只要实现了 __iter__ 方法就是一个可迭代对象 任何对象只要实现了 __iter__ 和 next 方法就是一个迭代器 生成器是一个特殊的迭代器，可以通过 yield 和 () 的方式生成 在数据量大的时候使用会有奇效 ","date":"2020-12-07","objectID":"/python-iter/:6:0","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python-iter/"},{"categories":null,"content":"Python 中的迭代器与生成器","date":"2020-12-07","objectID":"/python/python-iter/","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python/python-iter/"},{"categories":null,"content":"导读 这篇文章主要介绍了 python 当中的迭代器与生成器，在涉及到大数量的场景应该考虑使用迭代器与生成器。 ","date":"2020-12-07","objectID":"/python/python-iter/:1:0","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python/python-iter/"},{"categories":null,"content":"可迭代对象 如果一个对象实现了 __iter__ 方法，那么我们就称它是一个可迭代对象。如果没有实现 __iter__ 而实现了 __getitem__ 方法，并且其参数是从0开始索引的，这种对象也是可迭代的，比如说序列。 使用 iter 内置函数可以获取迭代器的对象，当解释器需要迭代对象时，会自动调用 item(x) ： 如果对象实现了 __iter__ 方法，获取一个迭代器 如果没有实现 __iter__ ，但是实现了 __getitem__ ，python 会创建一个迭代器，尝试从索引0开始获取元素 如果获取失败，则抛出 TypeError 标准序列都实现了 __iter__ 方法，所以标准序列都是可迭代对象。如 list,dict,set,tuple。 只有实现了 __iter__ 方法的对象能通过子类测试issubclass(Object,abc.Itertor) 检查对象能否迭代最标准的方法是调用 iter() 函数，因为 iter() 会考虑到实现 __getitem__ 方法的部分可迭代对象。 ","date":"2020-12-07","objectID":"/python/python-iter/:2:0","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python/python-iter/"},{"categories":null,"content":"迭代器 迭代器主要用于从集合中取出元素，那么是什么迭代器呢? 实现了 next 方法的可迭代对象就是迭代器。 next 返回下一个可用的元素，当没有元素时抛出 StopIteration 异常。 __iter__ ，迭代器本身。 到这里应该可以看出「可迭代对象」与 「迭代器」的区别了，就是在于有没有实现next 方法 。 检查对象是不是一个迭代器 ：isinstance(object,abc.Iterator) 。 ","date":"2020-12-07","objectID":"/python/python-iter/:3:0","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python/python-iter/"},{"categories":null,"content":"迭代器模式 按需一次获取一个数据项。 迭代器模式的用途有： 访问一个聚合对象而无需暴露它的内部结构 支持对聚合对象的多种遍历 为遍历不同的聚合结构提供一个统一的接口 说了这么多，那么除了标准序列之外，如何自定义一个迭代器呢，看看下面的代码： class Books: def __init__(self, books): self.books = books.split(\",\") def __iter__(self): return BookIterator(self.books) class BookIterator: def __init__(self, books): self.books = books self.index = 0 def next(self): try : book = self.books[self.index] except IndexError: raise StopIteration() self.index += 1 return book def __iter__(self): return self books = Books(\"python,golang,vue,kubernetes,istio\") print(books) for book in books : print(book) ","date":"2020-12-07","objectID":"/python/python-iter/:3:1","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python/python-iter/"},{"categories":null,"content":"生成器 生成器是一种特殊的迭代器，这种迭代器更加优雅，不需要像上面一样写 __iter__ 和 next 方法了，只需要一个 yield 关键字即可。 生成器有两种方法用: yield () 生成 ","date":"2020-12-07","objectID":"/python/python-iter/:4:0","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python/python-iter/"},{"categories":null,"content":"yield def gen(x) : for i in range(x) : yield i * 2 g1 = gen(10) ","date":"2020-12-07","objectID":"/python/python-iter/:4:1","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python/python-iter/"},{"categories":null,"content":"() 生成器 l1 = [ i * 2 for i in range(10) ] g1 = (i * 2 for i in range(10)) for i in g1 : print(i) print(l1) l1 是一个列表推导式 g1 是一个生成器 两者的区别是 g1 生成器采用懒加载的方式，不会一次把数据加载到内存中 生成器的好处不用把数据全部加载到内存中，访问到的时候在计算出来。例如有 100w 的数据集，但是只需要访问前 100 个，是不是生成器就很有用了。 ","date":"2020-12-07","objectID":"/python/python-iter/:4:2","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python/python-iter/"},{"categories":null,"content":"特别说明 上述写法为 python2 的写法，python3 略有不同，python3 中 next 方法对应的为 __next__ ，如上面的 Books 例子对应的写法为: class Books: def __init__(self, books): self.books = books.split(\",\") def __iter__(self): return BookIterator(self.books) class BookIterator: def __init__(self, books): self.books = books self.index = 0 def __next__(self): try : book = self.books[self.index] except IndexError: raise StopIteration() self.index += 1 return book def __iter__(self): return self books = Books(\"python,golang,vue,kubernetes,istio\") print(books) for book in books : print(book) ","date":"2020-12-07","objectID":"/python/python-iter/:5:0","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python/python-iter/"},{"categories":null,"content":"总结 任何对象只要实现了 __iter__ 方法就是一个可迭代对象 任何对象只要实现了 __iter__ 和 next 方法就是一个迭代器 生成器是一个特殊的迭代器，可以通过 yield 和 () 的方式生成 在数据量大的时候使用会有奇效 ","date":"2020-12-07","objectID":"/python/python-iter/:6:0","tags":["python","迭代器","生成器"],"title":"Python 中的迭代器与生成器","uri":"/python/python-iter/"},{"categories":null,"content":"docker 原理之存储驱动","date":"2020-12-05","objectID":"/docker-storage/","tags":["docker"],"title":"docker 原理之存储驱动","uri":"/docker-storage/"},{"categories":null,"content":"导读 提起 docker 大家应该耳熟能详，如使用 docker 所带来的持续集成、版本控制、可移植性、隔离性、安全性等诸多好处。docker 的使用也很方便，但是其内部原理是什么样的？都有哪些组件？之间是如何相互协作的呢？这是 docker 系列文章，每篇讲解一个知识点，可以更好的消化。 这篇谈谈 docker 的存储驱动。受限作者水平，如有不对之处，欢迎批评之处。 ","date":"2020-12-05","objectID":"/docker-storage/:1:0","tags":["docker"],"title":"docker 原理之存储驱动","uri":"/docker-storage/"},{"categories":null,"content":"什么是 docker 存储驱动 如果执行过 docker info 命令，那么肯定看到过这些信息: ... Server: Server Version: 19.03.13 Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: true ... 请注意 Storage Driver: overlay2 ，看到这些可能会有几个疑问: 什么是 Storage Driver ？除了 overlay2 还有其他的吗？原理是什么？ 我们知道 docker 的特别是分层的，层叠镜像是 docker 最具特色的特性之一。想象这么一个场景，docker 启动容器是依赖于镜像的，假设要一个 JDK 的镜像 要启动 10 个，这个镜像本身500M，那么 10 个这些容器是共享这一个镜像呢还是把每个镜像都复制一份呢，如果是共享模式，那么如果一个容器修改了镜像中的内容 岂不是会影响其他容器？如果是各自复制一份，那岂不是会造成存储空间的浪费? 存储驱动(Storage Driver) 就是解决这个问题，到现在也有好几种解决方案。总的解决思路就是镜像是只读的，启动容器时就是镜像上面叠加一个读写层。 在了解具体的存储驱动之前先铺垫几个知识点： ","date":"2020-12-05","objectID":"/docker-storage/:2:0","tags":["docker"],"title":"docker 原理之存储驱动","uri":"/docker-storage/"},{"categories":null,"content":"写时复制（CoW） 所有驱动都用到的技术——写时复制（CoW）。CoW就是copy-on-write，表示只在需要写时才去复制，这个是针对已有文件的修改场景。比如基于一个image启动多个Container，如果为每个Container都去分配一个image一样的文件系统，那么将会占用大量的磁盘空间。而CoW技术可以让所有的容器共享image的文件系统，所有数据都从image中读取，只有当要对文件进行写操作时，才从image里把要写的文件复制到自己的文件系统进行修改。所以无论有多少个容器共享同一个image，所做的写操作都是对从image中复制到自己的文件系统中的复本上进行，并不会修改image的源文件，且多个容器操作同一个文件，会在每个容器的文件系统里生成一个复本，每个容器修改的都是自己的复本，相互隔离，相互不影响。使用CoW可以有效的提高磁盘的利用率。 ","date":"2020-12-05","objectID":"/docker-storage/:2:1","tags":["docker"],"title":"docker 原理之存储驱动","uri":"/docker-storage/"},{"categories":null,"content":"用时分配（allocate-on-demand） 而写时分配是用在原本没有这个文件的场景，只有在要新写入一个文件时才分配空间，这样可以提高存储资源的利用率。比如启动一个容器，并不会为这个容器预分配一些磁盘空间，而是当有新文件写入时，才按需分配新空间。 ","date":"2020-12-05","objectID":"/docker-storage/:2:2","tags":["docker"],"title":"docker 原理之存储驱动","uri":"/docker-storage/"},{"categories":null,"content":"联合文件系统 联合文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下。 ","date":"2020-12-05","objectID":"/docker-storage/:2:3","tags":["docker"],"title":"docker 原理之存储驱动","uri":"/docker-storage/"},{"categories":null,"content":"现有的存储驱动及其特点 ","date":"2020-12-05","objectID":"/docker-storage/:3:0","tags":["docker"],"title":"docker 原理之存储驱动","uri":"/docker-storage/"},{"categories":null,"content":"AUFS AUFS（AnotherUnionFS）是一种Union FS，是文件级的存储驱动。AUFS能透明覆盖一或多个现有文件系统的层状文件系统，把多层合并成文件系统的单层表示。简单来说就是支持将不同目录挂载到同一个虚拟文件系统下的文件系统。这种文件系统可以一层一层地叠加修改文件。无论底下有多少层都是只读的，只有最上层的文件系统是可写的。当需要修改一个文件时，AUFS创建该文件的一个副本，使用CoW将文件从只读层复制到可写层进行修改，结果也保存在可写层。在Docker中，底下的只读层就是image，可写层就是Container。结构如下图所示： ","date":"2020-12-05","objectID":"/docker-storage/:3:1","tags":["docker"],"title":"docker 原理之存储驱动","uri":"/docker-storage/"},{"categories":null,"content":"Overlay Overlay是Linux内核3.18后支持的，也是一种Union FS，和AUFS的多层不同的是Overlay只有两层：一个upper文件系统和一个lower文件系统，分别代表Docker的镜像层和容器层。当需要修改一个文件时，使用CoW将文件从只读的lower复制到可写的upper进行修改，结果也保存在upper层。在Docker中，底下的只读层就是image，可写层就是Container。结构如下图所示： OverlayFS有两种存储驱动，它们使用了相同的OverlayFS技术，但却有着不同的实现，在磁盘使用上也并不互相兼容。因为不兼容，两者之间的切换必须重新创建所有的镜像。overlay驱动是最原始的OverlayFS实现，并且，在Docker1.11之前是仅有的OverlayFS驱动选择。overlay驱动在inode消耗方面有着较明显的限制，并且会损耗一定的性能。overlay2驱动解决了这种限制，不过只能在Linux kernel 4.0以上使用它。 目前 Overlay2 是默认的存储驱动 ","date":"2020-12-05","objectID":"/docker-storage/:3:2","tags":["docker"],"title":"docker 原理之存储驱动","uri":"/docker-storage/"},{"categories":null,"content":"Device mapper Device mapper是Linux内核2.6.9后支持的，提供的一种从逻辑设备到物理设备的映射框架机制，在该机制下，用户可以很方便的根据自己的需要制定实现存储资源的管理策略。前面讲的AUFS和OverlayFS都是文件级存储，而Device mapper是块级存储，所有的操作都是直接对块进行操作，而不是文件。Device mapper驱动会先在块设备上创建一个资源池，然后在资源池上创建一个带有文件系统的基本设备，所有镜像都是这个基本设备的快照，而容器则是镜像的快照。所以在容器里看到文件系统是资源池上基本设备的文件系统的快照，并不有为容器分配空间。当要写入一个新文件时，在容器的镜像内为其分配新的块并写入数据，这个叫用时分配。当要修改已有文件时，再使用CoW为容器快照分配块空间，将要修改的数据复制到在容器快照中新的块里再进行修改。Device mapper 驱动默认会创建一个100G的文件包含镜像和容器。每一个容器被限制在10G大小的卷内，可以自己配置调整。结构如下图所示： ","date":"2020-12-05","objectID":"/docker-storage/:3:3","tags":["docker"],"title":"docker 原理之存储驱动","uri":"/docker-storage/"},{"categories":null,"content":"Btrfs Btrfs被称为下一代写时复制文件系统，并入Linux内核，也是文件级级存储，但可以像Device mapper一直接操作底层设备。Btrfs把文件系统的一部分配置为一个完整的子文件系统，称之为subvolume 。那么采用 subvolume，一个大的文件系统可以被划分为多个子文件系统，这些子文件系统共享底层的设备空间，在需要磁盘空间时便从底层设备中分配，类似应用程序调用 malloc()分配内存一样。为了灵活利用设备空间，Btrfs 将磁盘空间划分为多个chunk 。每个chunk可以使用不同的磁盘空间分配策略。比如某些chunk只存放metadata，某些chunk只存放数据。这种模型有很多优点，比如Btrfs支持动态添加设备。用户在系统中增加新的磁盘之后，可以使用Btrfs的命令将该设备添加到文件系统中。Btrfs把一个大的文件系统当成一个资源池，配置成多个完整的子文件系统，还可以往资源池里加新的子文件系统，而基础镜像则是子文件系统的快照，每个子镜像和容器都有自己的快照，这些快照则都是subvolume的快照。 当写入一个新文件时，为在容器的快照里为其分配一个新的数据块，文件写在这个空间里，这个叫用时分配。而当要修改已有文件时，使用CoW复制分配一个新的原始数据和快照，在这个新分配的空间变更数据，变结束再更新相关的数据结构指向新子文件系统和快照，原来的原始数据和快照没有指针指向，被覆盖。 ","date":"2020-12-05","objectID":"/docker-storage/:3:4","tags":["docker"],"title":"docker 原理之存储驱动","uri":"/docker-storage/"},{"categories":null,"content":"ZFS ZFS 文件系统是一个革命性的全新的文件系统，它从根本上改变了文件系统的管理方式，ZFS 完全抛弃了“卷管理”，不再创建虚拟的卷，而是把所有设备集中到一个存储池中来进行管理，用“存储池”的概念来管理物理存储空间。过去，文件系统都是构建在物理设备之上的。为了管理这些物理设备，并为数据提供冗余，“卷管理”的概念提供了一个单设备的映像。而ZFS创建在虚拟的，被称为“zpools”的存储池之上。每个存储池由若干虚拟设备（virtual devices，vdevs）组成。这些虚拟设备可以是原始磁盘，也可能是一个RAID1镜像设备，或是非标准RAID等级的多磁盘组。于是zpool上的文件系统可以使用这些虚拟设备的总存储容量。 下面看一下在Docker里ZFS的使用。首先从zpool里分配一个ZFS文件系统给镜像的基础层，而其他镜像层则是这个ZFS文件系统快照的克隆，快照是只读的，而克隆是可写的，当容器启动时则在镜像的最顶层生成一个可写层。如下图所示： 当要写一个新文件时，使用按需分配，一个新的数据快从zpool里生成，新的数据写入这个块，而这个新空间存于容器（ZFS的克隆）里。 当要修改一个已存在的文件时，使用写时复制，分配一个新空间并把原始数据复制到新空间完成修改。 ","date":"2020-12-05","objectID":"/docker-storage/:3:5","tags":["docker"],"title":"docker 原理之存储驱动","uri":"/docker-storage/"},{"categories":null,"content":"存储驱动对比 存储驱动 特点 优点 缺点 适用场景 AUFS 联合文件系统、未并入内核主线、文件级存储 作为docker的第一个存储驱动，已经有很长的历史，比较稳定，且在大量的生产中实践过，有较强的社区支持 有多层，在做写时复制操作时，如果文件比较大且存在比较低的层，可能会慢一些 大并发但少IO的场景 overlayFS 联合文件系统、并入内核主线、文件级存储 只有两层 不管修改的内容大小都会复制整个文件，对大文件进行修改显示要比小文件消耗更多的时间 大并发但少IO的场景 Devicemapper 并入内核主线、块级存储 块级无论是大文件还是小文件都只复制需要修改的块，并不是整个文件 不支持共享存储，当有多个容器读同一个文件时，需要生成多个复本，在很多容器启停的情况下可能会导致磁盘溢出 适合io密集的场景 Btrfs 并入linux内核、文件级存储 可以像devicemapper一样直接操作底层设备，支持动态添加设备 不支持共享存储，当有多个容器读同一个文件时，需要生成多个复本 不适合在高密度容器的paas平台上使用 ZFS 把所有设备集中到一个存储池中来进行管理 支持多个容器共享一个缓存块，适合内存大的环境 COW使用碎片化问题更加严重，文件在硬盘上的物理地址会变的不再连续，顺序读会变的性能比较差 适合paas和高密度的场景 ","date":"2020-12-05","objectID":"/docker-storage/:4:0","tags":["docker"],"title":"docker 原理之存储驱动","uri":"/docker-storage/"},{"categories":null,"content":"设置存储驱动 docker 安装时会有自己的默认存储驱动，在新版本的 docker 中，默认是 overlay2，centos，mac 是这样的，其他的没有验证过。 如果要更改存储驱动，方法为: dockerd --storage-driver=aufs 设置完成后可通过 docker info 进行验证。 ","date":"2020-12-05","objectID":"/docker-storage/:5:0","tags":["docker"],"title":"docker 原理之存储驱动","uri":"/docker-storage/"},{"categories":null,"content":"参考 http://dockone.io/article/1513 https://gitbook.cn/gitchat/column/5d68b823de93ed72d6eca1bc/topic/5db26784bae3b42c1fa84d5f ","date":"2020-12-05","objectID":"/docker-storage/:6:0","tags":["docker"],"title":"docker 原理之存储驱动","uri":"/docker-storage/"},{"categories":null,"content":"OSCHINA 搬迁申明","date":"2020-11-30","objectID":"/oschina-blog/","tags":[],"title":"OSCHINA 搬迁申明","uri":"/oschina-blog/"},{"categories":null,"content":"导读 我的博客即将同步至 OSCHINA 社区，这是我的 OSCHINA ID：russellgao，邀请大家一同入驻：https://www.oschina.net/sharing-plan/apply ","date":"2020-11-30","objectID":"/oschina-blog/:1:0","tags":[],"title":"OSCHINA 搬迁申明","uri":"/oschina-blog/"},{"categories":null,"content":"harbor gc 时遇到的坑","date":"2020-11-29","objectID":"/harbor-gc/","tags":["云原生","harbor"],"title":"harbor gc 时遇到的坑","uri":"/harbor-gc/"},{"categories":null,"content":"导读 Harbor 是为企业用户设计的容器镜像仓库开源项目，包括了权限管理(RBAC)、LDAP、审计、安全漏洞扫描、镜像验真、管理界面、自我注册、HA 等企业必需的功能，同时针对中国用户的特点，设计镜像复制和中文支持等功能。 在使用的过程会有 GC 的需求，可以想象下这几种场景: 在 CI 的过程，同一个版本（SNAPSHOT/latest）编译很多次，只有最后一次产生的才有 tag ，那么之前的产生 blob 去哪了，或者还有用吗 ？ 镜像的生命周期已经结束，需要从仓库中删除，应该怎么操作？要知道在 Harbor 界面上删除只是标记删除，并不会释放存储空间。 Harbor / Docker 官方已经提供比较完善的 GC 方案，可以解决 80% 的问题，但是 GC 的过程中还可能出现一些奇怪的现象，本文主要记录在 Harbor GC 过程中踩过的坑。 ","date":"2020-11-29","objectID":"/harbor-gc/:1:0","tags":["云原生","harbor"],"title":"harbor gc 时遇到的坑","uri":"/harbor-gc/"},{"categories":null,"content":"GC原理 用一个官方例子说明: A -----\u003e a \u003c----- B \\--\u003e b | c \u003c--/ 假设镜像 A 引用了层a,b ，镜像 B 引用了层 a,c ，在这个阶段，是不需要做 GC 的，接下来把 B 给删掉，如下: A -----\u003e a B \\--\u003e b c 在这个阶段层 c 是不属于任何镜像了，适合去 GC ，GC 完之后效果如下： A -----\u003e a \\--\u003e b 看着还是挺简单，很容易理解的对吧，但是当镜像数为 10,000+ 以上，存储在 TB 级别以上时，事情可能又不那么简单了。 ","date":"2020-11-29","objectID":"/harbor-gc/:2:0","tags":["云原生","harbor"],"title":"harbor gc 时遇到的坑","uri":"/harbor-gc/"},{"categories":null,"content":"Harbor 存储的目录结构 Harbor 底层还是 Docker Registry，所以它们的存储结构是一样的，可以先看看它们在磁盘上存储结构: # tree docker/registry/v2/ docker/registry/v2 │ │ ├── blogs │ │ │ └── sha256 │ │ │ └── 00 │ │ │ └── 000098c48e5c8502460fd4427fe19d9def6c3d245b46e4d3dd86a00c79ca3111 │ │ │ └── data │ │ │ └── 000098c48e5c8502460fd4427fe19d9def6c3d245b46e4d3dd86a00c79ca3112 │ │ │ └── data │ │ │ └── 01 │ │ │ └── 010098c48e5c8502460fd4427fe19d9def6c3d245b46e4d3dd86a00c79ca3111 │ │ │ └── data │ │ │ └── 010098c48e5c8502460fd4427fe19d9def6c3d245b46e4d3dd86a00c79ca3112 │ │ │ └── data │ │ ├── repositories │ │ │ └── golang │ │ │ └── golang-centos │ │ │ └── _layers │ │ │ └── sha256 │ │ │ └── _manifests │ │ │ └── revisions │ │ │ └── sha256 │ │ │ └── tags │ │ │ └── 1.14 │ │ │ └── 1.15 可以看到存储结构主要分为两个部分 blogs 和 repositories ，作用如下 : blogs 是镜像数据的真正存储。 repositories 是镜像数据的引用，换言之存储的是blogs的索引。每个镜像都会声明它引用 blogs 中的哪些层。 ","date":"2020-11-29","objectID":"/harbor-gc/:3:0","tags":["云原生","harbor"],"title":"harbor gc 时遇到的坑","uri":"/harbor-gc/"},{"categories":null,"content":"GC过程 有了上面的铺垫，GC 的过程应该很容易理解了。Harbor GC 采用的两阶段标记清除，先遍历 repositories 下的镜像，并且对引用到blogs 进行标记，遍历完成之后把没有标记的 blogs 进行删除。 看似完美的方案，在实际操作过程中却还有些坑，下面说说遇到的坑以及如何解决方案。 ","date":"2020-11-29","objectID":"/harbor-gc/:4:0","tags":["云原生","harbor"],"title":"harbor gc 时遇到的坑","uri":"/harbor-gc/"},{"categories":null,"content":"遇到的坑 ","date":"2020-11-29","objectID":"/harbor-gc/:5:0","tags":["云原生","harbor"],"title":"harbor gc 时遇到的坑","uri":"/harbor-gc/"},{"categories":null,"content":"docker pull 失败 docker pull 的时候报错如下（unknown blob）： docker pull russellgao/toolkit ... daa258f4f8c0: Already exists 0c9e9bbad61e: Already exists fa786f5d7be0: Already exists ebc05f08dcb7: Downloading f919a7128c9a: Downloading 34dfbfa16f77: Download complete 65588873bd66: Download complete fc1b74edeacc: Download complete 099607f21531: Download complete 09432885197f: Download complete 259a4564bedf: Download complete ce223372b98e: Download complete ... unknown blob 这种情况主要的原因是在 repositories 中存在对 blob 的引用，但是 blog 中却不存在，造成这种可能的原因有： GC 的时候错误的删除了 blobs （大概率如此） blob 所在的磁盘损坏 （概率较小） blob 被人为删除（概率较小） 请注意：这种情况重新推送镜像是没有用的，因为在推送的时候，harbor 认为缺失的层是存在的，因为 repositories中存在，只有在下载时才会发现。 解决的方法: 通过docker build 编译镜像时增加 --no-cache 参数，生成一个全新的镜像推送到镜像仓库，方法可能会解决问题，但也有可能解决不了，可以 想象这么一个场景，缺失的层为基础镜像，如果基础镜像缺少层，那么这种方法就失效了。 可以在部署一个镜像仓库（一般都会最少有两个仓库做互备），把编译好的镜像推送到新的仓库，然后根据缺少的 blob id 在新的仓库中找到对应的 blob 数据，然后把缺少的 copy 到之前仓库，问题即可得到解决。如： 缺少 ebc05f08dcb7 这一层，在新的仓库的中可以找到如下目录: docker/registry/v2/blobs/sha256/eb/ 通过 ebc05f08dcb7 前缀找到具体的 blob 目录，然后把找到的这个目录 copy 到对应的仓库日录，问题即可得到解决。 ","date":"2020-11-29","objectID":"/harbor-gc/:5:1","tags":["云原生","harbor"],"title":"harbor gc 时遇到的坑","uri":"/harbor-gc/"},{"categories":null,"content":"总结 这篇文章主要介绍了 harbor gc 的基本原理，然后记录在 GC 的过程中踩的坑，后续有其他坑持续补充。 ","date":"2020-11-29","objectID":"/harbor-gc/:6:0","tags":["云原生","harbor"],"title":"harbor gc 时遇到的坑","uri":"/harbor-gc/"},{"categories":null,"content":"参考 https://github.com/docker/docker.github.io/blob/master/registry/garbage-collection.md ","date":"2020-11-29","objectID":"/harbor-gc/:7:0","tags":["云原生","harbor"],"title":"harbor gc 时遇到的坑","uri":"/harbor-gc/"},{"categories":null,"content":"细谈 Golang 中那些设计优美的细节-GMP","date":"2020-11-27","objectID":"/golang-gmp/","tags":["golang","GMP","调度器"],"title":"细谈 Golang 中那些设计优美的细节-GMP","uri":"/golang-gmp/"},{"categories":null,"content":"导读 这是 Golang 系列第二篇，这篇主要谈谈 Golang 的调度模型-GMP，我们知道 Golang 在并发方面有绝对优势，现在就让我们来揭开 它神秘的面纱。 ","date":"2020-11-27","objectID":"/golang-gmp/:1:0","tags":["golang","GMP","调度器"],"title":"细谈 Golang 中那些设计优美的细节-GMP","uri":"/golang-gmp/"},{"categories":null,"content":"背景 ","date":"2020-11-27","objectID":"/golang-gmp/:2:0","tags":["golang","GMP","调度器"],"title":"细谈 Golang 中那些设计优美的细节-GMP","uri":"/golang-gmp/"},{"categories":null,"content":"如何利用 golang 操纵 oracle","date":"2020-11-25","objectID":"/golang/oracle-golang/","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/golang/oracle-golang/"},{"categories":null,"content":"导读 这篇文章主要介绍如何利用 golang 操作 oracle 数据库，包括基本的增删改查，本地 oracle 环境搭建，以及如何在 docker 中运行。 oracle client 镜像构建并不容易，花了很长时间去踩坑，文中提供了已经构建好的基础镜像，可以直接使用，这里贡献给大家。 ","date":"2020-11-25","objectID":"/golang/oracle-golang/:1:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/golang/oracle-golang/"},{"categories":null,"content":"本地环境构建 ","date":"2020-11-25","objectID":"/golang/oracle-golang/:2:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/golang/oracle-golang/"},{"categories":null,"content":"安装客户端 oracle 客户端下载页面: https://www.oracle.com/database/technologies/instant-client/downloads.html mac https://www.oracle.com/database/technologies/instant-client/macos-intel-x86-downloads.html 在上面的页面下载之后执行: # 解压 cd ~ unzip instantclient-basic-macos.x64-19.3.0.0.0dbru.zip # 创建link mkdir ~/lib ln -s ~/instantclient_19_3/libclntsh.dylib ~/lib/ 我本地环境环境是 mac ，这个亲测有用。linux 和 windows 只给出了相关参考连接，没有实际操练过。 linux https://www.oracle.com/database/technologies/instant-client/linux-x86-64-downloads.html windows https://www.oracle.com/database/technologies/instant-client/winx64-64-downloads.html ","date":"2020-11-25","objectID":"/golang/oracle-golang/:2:1","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/golang/oracle-golang/"},{"categories":null,"content":"用法 go 操作 oracle 可以使用 github.com/godror/godror ，如 package main import ( \"database/sql\" \"fmt\" _ \"github.com/godror/godror\" \"os\" ) func main() { connString := \"oracle://hd40:xxx@121.196.127.xxx:1521/ylyx?charset=utf8\" db, err := sql.Open(\"godror\", connString) if err != nil { fmt.Println(err) os.Exit(10) } // 注意不要 sql 语句不要使用 ; 号结尾，否则会报错 // dpiStmt_execute: ORA-00911: invalid character sql := \"select * from user_tables \" rows, err1 := db.Query(sql) if err1 != nil { fmt.Println(err1) os.Exit(10) } result, err2 := GetQueryResult(rows) if err2 != nil { fmt.Println(err2) os.Exit(10) } fmt.Println(result) fmt.Println(\"end\") } func GetQueryResult(query *sql.Rows) ([]map[string]string, error) { column, _ := query.Columns() //读出查询出的列字段名 values := make([][]byte, len(column)) //values是每个列的值，这里获取到byte里 scans := make([]interface{}, len(column)) //因为每次查询出来的列是不定长的，用len(column)定住当次查询的长度 for i := range values { //让每一行数据都填充到[][]byte里面 scans[i] = \u0026values[i] } results := []map[string]string{} for query.Next() { //循环，让游标往下移动 if err := query.Scan(scans...); err != nil { //query.Scan查询出来的不定长值放到scans[i] = \u0026values[i],也就是每行都放在values里 fmt.Println(err) return nil, err } row := make(map[string]string) //每行数据 for k, v := range values { //每行数据是放在values里面，现在把它挪到row里 key := column[k] row[key] = string(v) } results = append(results, row) } query.Close() return results, nil } 用法说明 : _ \"github.com/godror/godror\" 这句是说明 sql 的 driver 是 oracle ，如果要操作 mysql ，换成 mysql 的 driver (_ \"github.com/go-sql-driver/mysql\") 即可。 crud 操作还是调用 database/sql 进行完成。 暴露出来给用户的还是 *sql.DB 。查询可以调用 *sql.DB 的 Query 方法，执行其他 sql 则调用 Exec 方法。 ","date":"2020-11-25","objectID":"/golang/oracle-golang/:3:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/golang/oracle-golang/"},{"categories":null,"content":"常见报错 如果报如下错误: (cx_Oracle.DatabaseError) DPI-1047: Cannot locate a 64-bit Oracle Client library: \"dlopen(libclntsh.dylib, 1): image not found\". See https://cx-oracle.readthedocs.io/en/latest/user_guide/installation.html for help 说明oracle的 client 没有正确安装 如果报错如下: (cx_Oracle.DatabaseError) ORA-01017: invalid username/password; logon denied 说明oracle 的用户密码不正确 如果报错如下: dpiStmt_execute: ORA-00911: invalid character 说明 sql 中包含无效字符，请注意如果 sql 中包含 ; 就会报错，需要把 sql 中的 ; trim 掉。我写了个标准化 sql 的方法，可以参考: // 去掉行首和行尾的空白字符 func TrimBlankSpace(s string) string { _s := regexp.MustCompile(\"^\\\\s+\").ReplaceAll([]byte(s), []byte(\"\")) _s = regexp.MustCompile(\"\\\\s+$\").ReplaceAll(_s, []byte(\"\")) return string(_s) } // 去掉 ; 并且全部转为大写字符 func FormatSql(sql string) string { sql = TrimBlankSpace(sql) sql = strings.TrimRight(sql, \";\") return strings.ToUpper(sql) } ","date":"2020-11-25","objectID":"/golang/oracle-golang/:4:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/golang/oracle-golang/"},{"categories":null,"content":"docker 中运行 我尝试过用 alpine 做基础镜像，然后进行安装 oracle client，把 oracle client 安装完成之后，运行编译完的 golang 程序， 出现了各种缺少动态库的问题，查了很多资料，和 apline 的官方源都彻底没有解决，然后就准备在 dockerhub 找一个现成的拿过来参考， 很遗憾没有找到一个可以直接用的，最后放弃了 alpine 这条路，选择 alpine 是因为 alpine 镜像比较小，这样做出来的镜像比较小。 看了 oracle client 官方下载和安装说明，也都是 centos 的版本，所以就基于 centos 做了一个包含 oracle client 的基础镜像。 已经上传到 dockerhub 了，参见: https://hub.docker.com/r/russellgao/oracle 如果你刚好需要，而我刚好有，那不妨试用一下（如果能帮到您可以给个 star 哟）。 dockerhub 可能访问比较慢，或者可能会出现无法访问的情况，这里贴一些关键信息。 ","date":"2020-11-25","objectID":"/golang/oracle-golang/:5:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/golang/oracle-golang/"},{"categories":null,"content":"镜像说明 镜像名称 russellgao/oracle:centos7-client12.2 操作系统 centos:centos7.9.2009 oracle client 版本 oracle-instantclient12.2-basic-12.2.0.1.0-1.x86_64 基于基础镜像优化的部分 调整时区为 CST 时区 （UTC +8） 镜像用法 这个一般用作基础镜像 或者: docker run -it --rm russellgao/oracle:centos7-client12.2 date or docker run -d russellgao/oracle:centos7-client12.2 tail -f /dev/null ","date":"2020-11-25","objectID":"/golang/oracle-golang/:5:1","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/golang/oracle-golang/"},{"categories":null,"content":"如何利用 golang 操纵 oracle","date":"2020-11-25","objectID":"/oracle-golang/","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/oracle-golang/"},{"categories":null,"content":"导读 这篇文章主要介绍如何利用 golang 操作 oracle 数据库，包括基本的增删改查，本地 oracle 环境搭建，以及如何在 docker 中运行。 oracle client 镜像构建并不容易，花了很长时间去踩坑，文中提供了已经构建好的基础镜像，可以直接使用，这里贡献给大家。 ","date":"2020-11-25","objectID":"/oracle-golang/:1:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/oracle-golang/"},{"categories":null,"content":"本地环境构建 ","date":"2020-11-25","objectID":"/oracle-golang/:2:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/oracle-golang/"},{"categories":null,"content":"安装客户端 oracle 客户端下载页面: https://www.oracle.com/database/technologies/instant-client/downloads.html mac https://www.oracle.com/database/technologies/instant-client/macos-intel-x86-downloads.html 在上面的页面下载之后执行: # 解压 cd ~ unzip instantclient-basic-macos.x64-19.3.0.0.0dbru.zip # 创建link mkdir ~/lib ln -s ~/instantclient_19_3/libclntsh.dylib ~/lib/ 我本地环境环境是 mac ，这个亲测有用。linux 和 windows 只给出了相关参考连接，没有实际操练过。 linux https://www.oracle.com/database/technologies/instant-client/linux-x86-64-downloads.html windows https://www.oracle.com/database/technologies/instant-client/winx64-64-downloads.html ","date":"2020-11-25","objectID":"/oracle-golang/:2:1","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/oracle-golang/"},{"categories":null,"content":"用法 go 操作 oracle 可以使用 github.com/godror/godror ，如 package main import ( \"database/sql\" \"fmt\" _ \"github.com/godror/godror\" \"os\" ) func main() { connString := \"oracle://hd40:xxx@121.196.127.xxx:1521/ylyx?charset=utf8\" db, err := sql.Open(\"godror\", connString) if err != nil { fmt.Println(err) os.Exit(10) } // 注意不要 sql 语句不要使用 ; 号结尾，否则会报错 // dpiStmt_execute: ORA-00911: invalid character sql := \"select * from user_tables \" rows, err1 := db.Query(sql) if err1 != nil { fmt.Println(err1) os.Exit(10) } result, err2 := GetQueryResult(rows) if err2 != nil { fmt.Println(err2) os.Exit(10) } fmt.Println(result) fmt.Println(\"end\") } func GetQueryResult(query *sql.Rows) ([]map[string]string, error) { column, _ := query.Columns() //读出查询出的列字段名 values := make([][]byte, len(column)) //values是每个列的值，这里获取到byte里 scans := make([]interface{}, len(column)) //因为每次查询出来的列是不定长的，用len(column)定住当次查询的长度 for i := range values { //让每一行数据都填充到[][]byte里面 scans[i] = \u0026values[i] } results := []map[string]string{} for query.Next() { //循环，让游标往下移动 if err := query.Scan(scans...); err != nil { //query.Scan查询出来的不定长值放到scans[i] = \u0026values[i],也就是每行都放在values里 fmt.Println(err) return nil, err } row := make(map[string]string) //每行数据 for k, v := range values { //每行数据是放在values里面，现在把它挪到row里 key := column[k] row[key] = string(v) } results = append(results, row) } query.Close() return results, nil } 用法说明 : _ \"github.com/godror/godror\" 这句是说明 sql 的 driver 是 oracle ，如果要操作 mysql ，换成 mysql 的 driver (_ \"github.com/go-sql-driver/mysql\") 即可。 crud 操作还是调用 database/sql 进行完成。 暴露出来给用户的还是 *sql.DB 。查询可以调用 *sql.DB 的 Query 方法，执行其他 sql 则调用 Exec 方法。 ","date":"2020-11-25","objectID":"/oracle-golang/:3:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/oracle-golang/"},{"categories":null,"content":"常见报错 如果报如下错误: (cx_Oracle.DatabaseError) DPI-1047: Cannot locate a 64-bit Oracle Client library: \"dlopen(libclntsh.dylib, 1): image not found\". See https://cx-oracle.readthedocs.io/en/latest/user_guide/installation.html for help 说明oracle的 client 没有正确安装 如果报错如下: (cx_Oracle.DatabaseError) ORA-01017: invalid username/password; logon denied 说明oracle 的用户密码不正确 如果报错如下: dpiStmt_execute: ORA-00911: invalid character 说明 sql 中包含无效字符，请注意如果 sql 中包含 ; 就会报错，需要把 sql 中的 ; trim 掉。我写了个标准化 sql 的方法，可以参考: // 去掉行首和行尾的空白字符 func TrimBlankSpace(s string) string { _s := regexp.MustCompile(\"^\\\\s+\").ReplaceAll([]byte(s), []byte(\"\")) _s = regexp.MustCompile(\"\\\\s+$\").ReplaceAll(_s, []byte(\"\")) return string(_s) } // 去掉 ; 并且全部转为大写字符 func FormatSql(sql string) string { sql = TrimBlankSpace(sql) sql = strings.TrimRight(sql, \";\") return strings.ToUpper(sql) } ","date":"2020-11-25","objectID":"/oracle-golang/:4:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/oracle-golang/"},{"categories":null,"content":"docker 中运行 我尝试过用 alpine 做基础镜像，然后进行安装 oracle client，把 oracle client 安装完成之后，运行编译完的 golang 程序， 出现了各种缺少动态库的问题，查了很多资料，和 apline 的官方源都彻底没有解决，然后就准备在 dockerhub 找一个现成的拿过来参考， 很遗憾没有找到一个可以直接用的，最后放弃了 alpine 这条路，选择 alpine 是因为 alpine 镜像比较小，这样做出来的镜像比较小。 看了 oracle client 官方下载和安装说明，也都是 centos 的版本，所以就基于 centos 做了一个包含 oracle client 的基础镜像。 已经上传到 dockerhub 了，参见: https://hub.docker.com/r/russellgao/oracle 如果你刚好需要，而我刚好有，那不妨试用一下（如果能帮到您可以给个 star 哟）。 dockerhub 可能访问比较慢，或者可能会出现无法访问的情况，这里贴一些关键信息。 ","date":"2020-11-25","objectID":"/oracle-golang/:5:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/oracle-golang/"},{"categories":null,"content":"镜像说明 镜像名称 russellgao/oracle:centos7-client12.2 操作系统 centos:centos7.9.2009 oracle client 版本 oracle-instantclient12.2-basic-12.2.0.1.0-1.x86_64 基于基础镜像优化的部分 调整时区为 CST 时区 （UTC +8） 镜像用法 这个一般用作基础镜像 或者: docker run -it --rm russellgao/oracle:centos7-client12.2 date or docker run -d russellgao/oracle:centos7-client12.2 tail -f /dev/null ","date":"2020-11-25","objectID":"/oracle-golang/:5:1","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/oracle-golang/"},{"categories":null,"content":"kubernetes 中 pod 是如何启动的呢","date":"2020-11-24","objectID":"/kubernetes/pod-create/","tags":["kubernetes","pod","kubectl","kubelet","schedule"],"title":"kubernetes 中 pod 是如何启动的呢","uri":"/kubernetes/pod-create/"},{"categories":null,"content":"导读 Pod 应该算是 kubernetes 的基本盘，Pod 是 kubernetes 的最小调度单位，我这里有个问题，说通过 kubectl apply -f 创建一个 Pod ，从执行到 Pod 正常运行 kubernetes 做了什么事情呢？都有哪些组件参与呢？这篇文档主要讲述从提交 Pod 的创建请求到 Pod 的正常运行的这个过程追踪。 ","date":"2020-11-24","objectID":"/kubernetes/pod-create/:1:0","tags":["kubernetes","pod","kubectl","kubelet","schedule"],"title":"kubernetes 中 pod 是如何启动的呢","uri":"/kubernetes/pod-create/"},{"categories":null,"content":"kubectl 阶段 kubectl apply 阶段其实分为两个过程 ，先调用 get 方法，查看资源是否存在，存在则调用 patch, 否则执行 create 方法。 这个过程可以参考源码（文章中所有源码都截取了部分，详细可以在在给出的链接中查看）: vendor/k8s.io/kubectl/pkg/cmd/apply/apply.go // NewCmdApply creates the `apply` command func NewCmdApply(baseName string, f cmdutil.Factory, ioStreams genericclioptions.IOStreams) *cobra.Command { o := NewApplyOptions(ioStreams) cmd := \u0026cobra.Command{ Use: \"apply (-f FILENAME | -k DIRECTORY)\", DisableFlagsInUseLine: true, Short: i18n.T(\"Apply a configuration to a resource by filename or stdin\"), Long: applyLong, Example: applyExample, Run: func(cmd *cobra.Command, args []string) { cmdutil.CheckErr(o.Complete(f, cmd)) cmdutil.CheckErr(validateArgs(cmd, args)) cmdutil.CheckErr(validatePruneAll(o.Prune, o.All, o.Selector)) cmdutil.CheckErr(o.Run()) }, } ... } // Run executes the `apply` command. func (o *ApplyOptions) Run() error { ... // Iterate through all objects, applying each one. for _, info := range infos { if err := o.applyOneObject(info); err != nil { errs = append(errs, err) } } ... return nil } func (o *ApplyOptions) applyOneObject(info *resource.Info) error { ... // Get the modified configuration of the object. Embed the result // as an annotation in the modified configuration, so that it will appear // in the patch sent to the server. modified, err := util.GetModifiedConfiguration(info.Object, true, unstructured.UnstructuredJSONScheme) if err != nil { return cmdutil.AddSourceToErr(fmt.Sprintf(\"retrieving modified configuration from:\\n%s\\nfor:\", info.String()), info.Source, err) } if err := info.Get(); err != nil { if !errors.IsNotFound(err) { return cmdutil.AddSourceToErr(fmt.Sprintf(\"retrieving current configuration of:\\n%s\\nfrom server for:\", info.String()), info.Source, err) } // Create the resource if it doesn't exist // First, update the annotation used by kubectl apply if err := util.CreateApplyAnnotation(info.Object, unstructured.UnstructuredJSONScheme); err != nil { return cmdutil.AddSourceToErr(\"creating\", info.Source, err) } if o.DryRunStrategy != cmdutil.DryRunClient { // Then create the resource and skip the three-way merge obj, err := helper.Create(info.Namespace, true, info.Object) if err != nil { return cmdutil.AddSourceToErr(\"creating\", info.Source, err) } info.Refresh(obj, true) } if err := o.MarkObjectVisited(info); err != nil { return err } if o.shouldPrintObject() { return nil } printer, err := o.ToPrinter(\"created\") if err != nil { return err } if err = printer.PrintObj(info.Object, o.Out); err != nil { return err } return nil } if err := o.MarkObjectVisited(info); err != nil { return err } if o.DryRunStrategy != cmdutil.DryRunClient { metadata, _ := meta.Accessor(info.Object) annotationMap := metadata.GetAnnotations() if _, ok := annotationMap[corev1.LastAppliedConfigAnnotation]; !ok { fmt.Fprintf(o.ErrOut, warningNoLastAppliedConfigAnnotation, o.cmdBaseName) } patcher, err := newPatcher(o, info, helper) if err != nil { return err } patchBytes, patchedObject, err := patcher.Patch(info.Object, modified, info.Source, info.Namespace, info.Name, o.ErrOut) if err != nil { return cmdutil.AddSourceToErr(fmt.Sprintf(\"applying patch:\\n%s\\nto:\\n%v\\nfor:\", patchBytes, info), info.Source, err) } info.Refresh(patchedObject, true) if string(patchBytes) == \"{}\" \u0026\u0026 !o.shouldPrintObject() { printer, err := o.ToPrinter(\"unchanged\") if err != nil { return err } if err = printer.PrintObj(info.Object, o.Out); err != nil { return err } return nil } } ... return nil } apply 命令调用 o.Run() 执行 创建的动作 applyOneObject 方法是真正执行创建 Pod 的动作 在 applyOneObject 方法中通过 GetModifiedConfiguration 函数执行 get 动作 如果是 IsNotFound 异常则 执行 Create 动作 否则执行 Patch 动作 上述过程除了用 kubectl ，当然也可以自己调用 api 去创建或者更新 。 ","date":"2020-11-24","objectID":"/kubernetes/pod-create/:2:0","tags":["kubernetes","pod","kubectl","kubelet","schedule"],"title":"kubernetes 中 pod 是如何启动的呢","uri":"/kubernetes/pod-create/"},{"categories":null,"content":"apiserver 通过客户端把请求提交到 apiserver 之后，接下来就是 apiserver 表演的时候了。 apiserver 会把 pod 数据存储到 etcd 中。 ","date":"2020-11-24","objectID":"/kubernetes/pod-create/:3:0","tags":["kubernetes","pod","kubectl","kubelet","schedule"],"title":"kubernetes 中 pod 是如何启动的呢","uri":"/kubernetes/pod-create/"},{"categories":null,"content":"Schedule Schedule通过和API Server的watch机制，查看到新的Pod（通过 pod.spec.Node == nil 判断是否为新的Pod），尝试为Pod绑定Node。Schedle 的过程为 : 过滤主机：调度器用一组规则过滤掉不符合要求的主机，比如Pod指定了所需要的资源，那么就要过滤掉资源不够的主机 主机打分：对第一步筛选出的符合要求的主机进行打分，在主机打分阶段，调度器会考虑一些整体优化策略，比如把一个Replication Controller的副本分布到不同的主机上，使用最低负载的主机等 选择主机：选择打分最高的主机，进行binding操作 把调度结果通过apiserver 存储到 etcd 中 ","date":"2020-11-24","objectID":"/kubernetes/pod-create/:4:0","tags":["kubernetes","pod","kubectl","kubelet","schedule"],"title":"kubernetes 中 pod 是如何启动的呢","uri":"/kubernetes/pod-create/"},{"categories":null,"content":"kubelet kubelet从apiserver获取分配到其所在节点的Pod（watch 机制） kubelet调用Docker的 Api 创建容器，创建容器的过程为: 先按顺序启动 initContainers 按照 yaml 中申明的顺序 并发启动 containers kubelet将Pod状态更新到apiserver apiserver将状态信息写到etcd中 ","date":"2020-11-24","objectID":"/kubernetes/pod-create/:5:0","tags":["kubernetes","pod","kubectl","kubelet","schedule"],"title":"kubernetes 中 pod 是如何启动的呢","uri":"/kubernetes/pod-create/"},{"categories":null,"content":"总结 上面每个步骤单拎出来都能有好多东西可以深入下去，这里从流程上简单的介绍了一个Pod 从发起创建请求到最终创建的一个文字版流程，仅供参考。 后续再详细分析每个组件。 Pod 的创建过程 : kubectl apply 执行过程: 先通过 get 查找资源对象，如果不存在则 create pod 否则 patch pod 通过 apply 提交请求到 apiserver ，apiserver 把 pod 数据存储到 etcd 中 Schedule通过和API Server的watch机制，查看到新的Pod（通过 pod.spec.Node == nil 判断是否为新的Pod），尝试为Pod绑定Node。Schedle 的过程为: 过滤主机：调度器用一组规则过滤掉不符合要求的主机，比如Pod指定了所需要的资源，那么就要过滤掉资源不够的主机 主机打分：对第一步筛选出的符合要求的主机进行打分，在主机打分阶段，调度器会考虑一些整体优化策略，比如把一个Replication Controller的副本分布到不同的主机上，使用最低负载的主机等 选择主机：选择打分最高的主机，进行binding操作 把调度结果通过apiserver 存储到 etcd 中 kubelet从apiserver获取分配到其所在节点的Pod（watch 机制） kubelet调用Docker的 Api 创建容器，创建容器的过程为: 先按顺序启动 initContainers 按照 yaml 中申明的顺序 并发启动 containers kubelet将Pod状态更新到apiserver apiserver将状态信息写到etcd中 ","date":"2020-11-24","objectID":"/kubernetes/pod-create/:6:0","tags":["kubernetes","pod","kubectl","kubelet","schedule"],"title":"kubernetes 中 pod 是如何启动的呢","uri":"/kubernetes/pod-create/"},{"categories":null,"content":"kubernetes 中 pod 是如何启动的呢","date":"2020-11-24","objectID":"/pod-create/","tags":["kubernetes","pod","kubectl","kubelet","schedule"],"title":"kubernetes 中 pod 是如何启动的呢","uri":"/pod-create/"},{"categories":null,"content":"导读 Pod 应该算是 kubernetes 的基本盘，Pod 是 kubernetes 的最小调度单位，我这里有个问题，说通过 kubectl apply -f 创建一个 Pod ，从执行到 Pod 正常运行 kubernetes 做了什么事情呢？都有哪些组件参与呢？这篇文档主要讲述从提交 Pod 的创建请求到 Pod 的正常运行的这个过程追踪。 ","date":"2020-11-24","objectID":"/pod-create/:1:0","tags":["kubernetes","pod","kubectl","kubelet","schedule"],"title":"kubernetes 中 pod 是如何启动的呢","uri":"/pod-create/"},{"categories":null,"content":"kubectl 阶段 kubectl apply 阶段其实分为两个过程 ，先调用 get 方法，查看资源是否存在，存在则调用 patch, 否则执行 create 方法。 这个过程可以参考源码（文章中所有源码都截取了部分，详细可以在在给出的链接中查看）: vendor/k8s.io/kubectl/pkg/cmd/apply/apply.go // NewCmdApply creates the `apply` command func NewCmdApply(baseName string, f cmdutil.Factory, ioStreams genericclioptions.IOStreams) *cobra.Command { o := NewApplyOptions(ioStreams) cmd := \u0026cobra.Command{ Use: \"apply (-f FILENAME | -k DIRECTORY)\", DisableFlagsInUseLine: true, Short: i18n.T(\"Apply a configuration to a resource by filename or stdin\"), Long: applyLong, Example: applyExample, Run: func(cmd *cobra.Command, args []string) { cmdutil.CheckErr(o.Complete(f, cmd)) cmdutil.CheckErr(validateArgs(cmd, args)) cmdutil.CheckErr(validatePruneAll(o.Prune, o.All, o.Selector)) cmdutil.CheckErr(o.Run()) }, } ... } // Run executes the `apply` command. func (o *ApplyOptions) Run() error { ... // Iterate through all objects, applying each one. for _, info := range infos { if err := o.applyOneObject(info); err != nil { errs = append(errs, err) } } ... return nil } func (o *ApplyOptions) applyOneObject(info *resource.Info) error { ... // Get the modified configuration of the object. Embed the result // as an annotation in the modified configuration, so that it will appear // in the patch sent to the server. modified, err := util.GetModifiedConfiguration(info.Object, true, unstructured.UnstructuredJSONScheme) if err != nil { return cmdutil.AddSourceToErr(fmt.Sprintf(\"retrieving modified configuration from:\\n%s\\nfor:\", info.String()), info.Source, err) } if err := info.Get(); err != nil { if !errors.IsNotFound(err) { return cmdutil.AddSourceToErr(fmt.Sprintf(\"retrieving current configuration of:\\n%s\\nfrom server for:\", info.String()), info.Source, err) } // Create the resource if it doesn't exist // First, update the annotation used by kubectl apply if err := util.CreateApplyAnnotation(info.Object, unstructured.UnstructuredJSONScheme); err != nil { return cmdutil.AddSourceToErr(\"creating\", info.Source, err) } if o.DryRunStrategy != cmdutil.DryRunClient { // Then create the resource and skip the three-way merge obj, err := helper.Create(info.Namespace, true, info.Object) if err != nil { return cmdutil.AddSourceToErr(\"creating\", info.Source, err) } info.Refresh(obj, true) } if err := o.MarkObjectVisited(info); err != nil { return err } if o.shouldPrintObject() { return nil } printer, err := o.ToPrinter(\"created\") if err != nil { return err } if err = printer.PrintObj(info.Object, o.Out); err != nil { return err } return nil } if err := o.MarkObjectVisited(info); err != nil { return err } if o.DryRunStrategy != cmdutil.DryRunClient { metadata, _ := meta.Accessor(info.Object) annotationMap := metadata.GetAnnotations() if _, ok := annotationMap[corev1.LastAppliedConfigAnnotation]; !ok { fmt.Fprintf(o.ErrOut, warningNoLastAppliedConfigAnnotation, o.cmdBaseName) } patcher, err := newPatcher(o, info, helper) if err != nil { return err } patchBytes, patchedObject, err := patcher.Patch(info.Object, modified, info.Source, info.Namespace, info.Name, o.ErrOut) if err != nil { return cmdutil.AddSourceToErr(fmt.Sprintf(\"applying patch:\\n%s\\nto:\\n%v\\nfor:\", patchBytes, info), info.Source, err) } info.Refresh(patchedObject, true) if string(patchBytes) == \"{}\" \u0026\u0026 !o.shouldPrintObject() { printer, err := o.ToPrinter(\"unchanged\") if err != nil { return err } if err = printer.PrintObj(info.Object, o.Out); err != nil { return err } return nil } } ... return nil } apply 命令调用 o.Run() 执行 创建的动作 applyOneObject 方法是真正执行创建 Pod 的动作 在 applyOneObject 方法中通过 GetModifiedConfiguration 函数执行 get 动作 如果是 IsNotFound 异常则 执行 Create 动作 否则执行 Patch 动作 上述过程除了用 kubectl ，当然也可以自己调用 api 去创建或者更新 。 ","date":"2020-11-24","objectID":"/pod-create/:2:0","tags":["kubernetes","pod","kubectl","kubelet","schedule"],"title":"kubernetes 中 pod 是如何启动的呢","uri":"/pod-create/"},{"categories":null,"content":"apiserver 通过客户端把请求提交到 apiserver 之后，接下来就是 apiserver 表演的时候了。 apiserver 会把 pod 数据存储到 etcd 中。 ","date":"2020-11-24","objectID":"/pod-create/:3:0","tags":["kubernetes","pod","kubectl","kubelet","schedule"],"title":"kubernetes 中 pod 是如何启动的呢","uri":"/pod-create/"},{"categories":null,"content":"Schedule Schedule通过和API Server的watch机制，查看到新的Pod（通过 pod.spec.Node == nil 判断是否为新的Pod），尝试为Pod绑定Node。Schedle 的过程为 : 过滤主机：调度器用一组规则过滤掉不符合要求的主机，比如Pod指定了所需要的资源，那么就要过滤掉资源不够的主机 主机打分：对第一步筛选出的符合要求的主机进行打分，在主机打分阶段，调度器会考虑一些整体优化策略，比如把一个Replication Controller的副本分布到不同的主机上，使用最低负载的主机等 选择主机：选择打分最高的主机，进行binding操作 把调度结果通过apiserver 存储到 etcd 中 ","date":"2020-11-24","objectID":"/pod-create/:4:0","tags":["kubernetes","pod","kubectl","kubelet","schedule"],"title":"kubernetes 中 pod 是如何启动的呢","uri":"/pod-create/"},{"categories":null,"content":"kubelet kubelet从apiserver获取分配到其所在节点的Pod（watch 机制） kubelet调用Docker的 Api 创建容器，创建容器的过程为: 先按顺序启动 initContainers 按照 yaml 中申明的顺序 并发启动 containers kubelet将Pod状态更新到apiserver apiserver将状态信息写到etcd中 ","date":"2020-11-24","objectID":"/pod-create/:5:0","tags":["kubernetes","pod","kubectl","kubelet","schedule"],"title":"kubernetes 中 pod 是如何启动的呢","uri":"/pod-create/"},{"categories":null,"content":"总结 上面每个步骤单拎出来都能有好多东西可以深入下去，这里从流程上简单的介绍了一个Pod 从发起创建请求到最终创建的一个文字版流程，仅供参考。 后续再详细分析每个组件。 Pod 的创建过程 : kubectl apply 执行过程: 先通过 get 查找资源对象，如果不存在则 create pod 否则 patch pod 通过 apply 提交请求到 apiserver ，apiserver 把 pod 数据存储到 etcd 中 Schedule通过和API Server的watch机制，查看到新的Pod（通过 pod.spec.Node == nil 判断是否为新的Pod），尝试为Pod绑定Node。Schedle 的过程为: 过滤主机：调度器用一组规则过滤掉不符合要求的主机，比如Pod指定了所需要的资源，那么就要过滤掉资源不够的主机 主机打分：对第一步筛选出的符合要求的主机进行打分，在主机打分阶段，调度器会考虑一些整体优化策略，比如把一个Replication Controller的副本分布到不同的主机上，使用最低负载的主机等 选择主机：选择打分最高的主机，进行binding操作 把调度结果通过apiserver 存储到 etcd 中 kubelet从apiserver获取分配到其所在节点的Pod（watch 机制） kubelet调用Docker的 Api 创建容器，创建容器的过程为: 先按顺序启动 initContainers 按照 yaml 中申明的顺序 并发启动 containers kubelet将Pod状态更新到apiserver apiserver将状态信息写到etcd中 ","date":"2020-11-24","objectID":"/pod-create/:6:0","tags":["kubernetes","pod","kubectl","kubelet","schedule"],"title":"kubernetes 中 pod 是如何启动的呢","uri":"/pod-create/"},{"categories":null,"content":"openresty 配置文件 （二）","date":"2020-11-23","objectID":"/openresty-server/","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"导读 这篇是继上一篇 openresty 配置文件 （一） 介绍了 openresty 全局配置之后，介绍 openresty server 配置，server 的配置一般单独放在 conf.d 目录下。下面是我比较推荐的 conf.d 目录结构： [root@iZuf685opgs9oyozju9i2bZ conf.d]# tree . ├── 443.conf ├── 8080.conf ├── 80.conf └── upstream.conf 0 directories, 4 files upstream 放在单独的 配置文件，当然如果比较多，可以按照 service/product 的维度再进行拆分。不同的监听放在单独的配置文件，相对来说比较好维护一点，也更容易自动化程序处理。 这篇文章比较长，可以通过目录直接跳转到自己感兴趣的部分。 ","date":"2020-11-23","objectID":"/openresty-server/:1:0","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"server server 模块是位于 http 模块下面，进行端口监听，并把请求转发到 upstream 或者直接响应，先看它的配置是什么样子。 server { #配置监听端口 # listen 详细配置参考 listen 一节 listen 80; #配置访问域名，可以只有一个名称，也可以由多个名称并列，之间用空格隔开。每个名字就是一个域名，由两段或者三段组成，之间由点号“.”隔开 # 第一个名称作为此虚拟主机的主要名称 # server_name 更加详细的用法参考下面 server_name 一节 server_name russellgao.cn russellgao.com localhost 127.0.0.1; # log 在全局变量中已经配置，但是每个监听中也可以配置，这样做的好处，在分析日志时比较方便，通过日志就可以知道请求从哪个监听中进来的 # 也可以放在具体的 location 中。 access_log /usr/local/openresty/nginx/logs/access.log custom; error_log /usr/local/openresty/nginx/logs/error.log; # ssl 配置 ssl on; ssl_certificate /usr/local/openresty/nginx/ssl/4753767.pem; ssl_certificate_key /usr/local/openresty/nginx/ssl/4753767.key; ssl_session_timeout 5m; ssl_protocols SSLv2 SSLv3 TLSv1 TLSv1.2 TLSv1.1; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; # location 配置，location 介绍参考下面详细介绍 location / { root /usr/local/openresty/nginx/docs; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/local/openresty/nginx/html; } error_page 404 /404.html; location = /404.html { root /usr/local/openresty/nginx/docs; } } 一个 server 只能监听一个端口。 ","date":"2020-11-23","objectID":"/openresty-server/:2:0","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"listen listen 有三种配置语法。这个指令默认的配置值是：listen *:80 | *:8000；只能在server块种配置这个指令。 //第一种 listen address[:port] [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; //第二种 listen port [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; //第三种（可以不用重点关注） listen unix:path [default_server] [ssl] [http2 | spdy] [proxy_protocol] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; listen指令的配置非常灵活，可以单独制定ip，单独指定端口或者同时指定ip和端口。 关于上面的一些重要参数做如下说明： address：监听的IP地址（请求来源的IP地址），如果是IPv6的地址，需要使用中括号“[]”括起来，比如[fe80::1]等。 port：端口号，如果只定义了IP地址没有定义端口号，就使用80端口。这边需要做个说明：要是你压根没配置listen指令，那么那么如果nginx以超级用户权限运行，则使用*:80，否则使用*:8000。多个虚拟主机可以同时监听同一个端口,但是server_name需要设置成不一样； default_server：假如通过Host没匹配到对应的虚拟主机，则通过这台虚拟主机处理。 backlog=number：设置监听函数listen()最多允许多少网络连接同时处于挂起状态，在FreeBSD中默认为-1，其他平台默认为511。 accept_filter=filter，设置监听端口对请求的过滤，被过滤的内容不能被接收和处理。本指令只在FreeBSD和NetBSD 5.0+平台下有效。filter可以设置为dataready或httpready，感兴趣的读者可以参阅Nginx的官方文档。 bind：标识符，使用独立的bind()处理此address:port；一般情况下，对于端口相同而IP地址不同的多个连接，Nginx服务器将只使用一个监听命令，并使用bind()处理端口相同的所有连接。 ssl：标识符，设置会话连接使用SSL模式进行，此标识符和Nginx服务器提供的HTTPS服务有关。 ","date":"2020-11-23","objectID":"/openresty-server/:2:1","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"server_name 用于配置虚拟主机的名称。语法是： Syntax: server_name name ...; Default: server_name \"\"; Context: server 对于name 来说，可以只有一个名称，也可以由多个名称并列，之间用空格隔开。每个名字就是一个域名，由两段或者三段组成，之间由点号“.”隔开。比如 server_name myserver.com www.myserver.com 在该例中，此虚拟主机的名称设置为myserver.com或www. myserver.com。Nginx服务器规定，第一个名称作为此虚拟主机的主要名称。 在name 中可以使用通配符“*”，但通配符只能用在由三段字符串组成的名称的首段或尾段，或者由两段字符串组成的名称的尾段，如： server_name myserver.* *.myserver.com 另外name还支持正则表达式的形式 由于server_name指令支持使用通配符和正则表达式两种配置名称的方式，因此在包含有多个虚拟主机的配置文件中，可能会出现一个名称被多个虚拟主机的server_name匹配成功。那么，来自这个名称的请求到底要交给哪个虚拟主机处理呢？Nginx服务器做出如下规定： a. 对于匹配方式不同的，按照以下的优先级选择虚拟主机，排在前面的优先处理请求。 准确匹配server_name 通配符在开始时匹配server_name成功 通配符在结尾时匹配server_name成功 正则表达式匹配server_name成功 b. 在以上四种匹配方式中，如果server_name被处于同一优先级的匹配方式多次匹配成功，则首次匹配成功的虚拟主机处理请求。 ","date":"2020-11-23","objectID":"/openresty-server/:2:2","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"location ","date":"2020-11-23","objectID":"/openresty-server/:3:0","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"基本语法 location [=|~|~*|^~] /uri/ { ... } = : 表示精确匹配后面的url ~ : 表示正则匹配，但是区分大小写 ~* : 正则匹配，不区分大小写 ^~ : 如果把这个前缀用于一个常规字符串,那么告诉nginx 如果路径匹配那么不测试正则表达式 「=」 修饰符：要求路径完全匹配 server { server_name russellgao.cn; location = /abcd { […] } } https://russellgao.cn/abcd匹配 https://russellgao.cn/ABCD可能会匹配 ，也可以不匹配，取决于操作系统的文件系统是否大小写敏感（case-sensitive）。 https://russellgao.cn/abcd?param1\u0026param2匹配，忽略 querystring https://russellgao.cn/abcd/不匹配，带有结尾的/ https://russellgao.cn/abcde不匹配 「~」修饰符：区分大小写的正则匹配 server { server_name russellgao.cn; location ~ ^/abcd$ { […] } } ^/abcd$ 这个正则表达式表示字符串必须以/开始，以d结束，中间必须是abc，换言之只能匹配 /abcd https://russellgao.cn/abcd匹配（完全匹配） https://russellgao.cn/ABCD不匹配，大小写敏感 https://russellgao.cn/abcd?param1\u0026param2匹配 https://russellgao.cn/abcd/不匹配，不能匹配正则表达式 https://russellgao.cn/abcde不匹配，不能匹配正则表达式 「~*」不区分大小写的正则匹配 server { server_name russellgao.cn; location ~* ^/abcd$ { […] } } https://russellgao.cn/abcd匹配 (完全匹配) https://russellgao.cn/ABCD匹配 (大小写不敏感) https://russellgao.cn/abcd?param1\u0026param2匹配 https://russellgao.cn/abcd/ 不匹配，不能匹配正则表达式 https://russellgao.cn/abcde 不匹配，不能匹配正则表达式 「^~」修饰符 前缀匹配 如果该 location 是最佳的匹配，那么对于匹配这个 location 的字符串， 该修饰符不再进行正则表达式检测。注意，这不是一个正则表达式匹配，它的目的是优先于正则表达式的匹配。 ","date":"2020-11-23","objectID":"/openresty-server/:3:1","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"查找的顺序及优先级 当有多条 location 规则时，nginx 有一套比较复杂的规则，优先级如下： 精确匹配 = 前缀匹配 ^~（立刻停止后续的正则搜索） 按文件中顺序的正则匹配 ~或~* 匹配不带任何修饰的前缀匹配。 这个规则大体的思路是: 先精确匹配，没有则查找带有 ^~的前缀匹配，没有则进行正则匹配，最后才返回前缀匹配的结果（如果有的话） ","date":"2020-11-23","objectID":"/openresty-server/:3:2","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"alias 与 root 区别 root 实际访问文件路径会拼接URL中的路径 alias 实际访问文件路径不会拼接URL中的路径 看一个例子 location ^~ /sta/ { alias /usr/local/nginx/html/static/; } 请求：https://russellgao.cn/sta/index.html 实际访问：/usr/local/nginx/html/static/index.html 文件 location ^~ /static/ { root /usr/local/nginx/html/; } 请求：https://russellgao.cn/static/index.html 实际访问：/usr/local/nginx/html/static/index.html 文件 ","date":"2020-11-23","objectID":"/openresty-server/:3:3","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"rewrite rewrite 模块主要用于重定向。 指令语法：rewrite regex replacement[flag]; ，默认值为 none 。 看个简单例子 : location / { rewrite ^/(.*) https://russellgao.cn/$1 permanent; } 这是我 http 强转 https 的例子。 ","date":"2020-11-23","objectID":"/openresty-server/:3:4","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"常用正则表达式 字符 描述 \\ 将后面接着的字符标记为一个特殊字符或者一个原义字符或一个向后引用 ^ 匹配输入字符串的起始位置 $ 匹配输入字符串的结束位置 * 匹配前面的字符零次或者多次 + 匹配前面字符串一次或者多次 ? 匹配前面字符串的零次或者一次 . 匹配除“\\n”之外的所有单个字符 (pattern) 匹配括号内的pattern ","date":"2020-11-23","objectID":"/openresty-server/:3:5","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"flag参数 标记符号 说明 last 本条规则匹配完成后继续向下匹配新的location URI规则 break 本条规则匹配完成后终止，不在匹配任何规则 redirect 返回302临时重定向 permanent 返回301永久重定向 last 和 break关键字的区别 last 匹配到了还会继续向下匹配 break 匹配到了不会继续向下匹配，会终止掉 permanent 和 redirect关键字的区别 last 和 break 当出现在location 之外时，两者的作用是一致的没有任何差异 last 和 break 当出现在location 内部时： rewrite … permanent 永久性重定向，请求日志中的状态码为301 rewrite … redirect 临时重定向，请求日志中的状态码为302 ","date":"2020-11-23","objectID":"/openresty-server/:3:6","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"proxy_pass 在nginx中配置proxy_pass代理转发时，如果在proxy_pass后面的url加/，表示绝对根路径；如果没有/，表示相对路径，把匹配的路径部分也给代理走。 假设我们访问地址为 : https://russellgao.cn/proxypass/index.html 当配置为 location /proxypass/ { proxy_pass https://russellgao.cn/; } 代理到: https://russellgao.cn/index.html 当配置为 location /proxypass/ { proxy_pass https://russellgao.cn; } 代理到: https://russellgao.cn/proxypass/index.html 请注意：proxy_pass 最后没有 / 当配置为 location /proxypass/ { proxy_pass https://russellgao.cn/test/; } 代理到: https://russellgao.cn/test/index.html 当配置为 location /proxypass/ { proxy_pass https://russellgao.cn/test; } 代理到: https://russellgao.cn/testindex.html nginx 的 ngx_http_proxy_module 和 ngx_stream_proxy_module 模块都有 proxy_pass ，下面看看两者之间的关系与区别。 ngx_http_proxy_module 语法: proxy_pass URL 场景: location if in location limit_except 设置后端代理服务器的协议(protocol)和地址(address),以及location中可以匹配的一个可选的URI。协议可以是\"http\"或\"https”。地址可以是一个域名或ip地址和端口，或者一个 unix-domain socket 路径。 例: location ~* (/api/v1/blog-server) { proxy_pass_header Server; proxy_pass http://blog_server; } ngx_stream_proxy_module 语法: proxy_pass address; 场景: server 设置后端代理服务器的地址。这个地址(address)可以是一个域名或ip地址和端口，或者一个 unix-domain socket路径。 例: server { listen 127.0.0.1:12345; proxy_pass 127.0.0.1:8080; } 在两个模块中，两个proxy_pass都是用来做后端代理的指令。 ngx_stream_proxy_module模块的proxy_pass指令只能在server段使用使用, 只需要提供域名或ip地址和端口。可以理解为端口转发，可以是tcp端口，也可以是udp端口。 ngx_http_proxy_module模块的proxy_pass指令需要在location段，location中的if段，limit_except段中使用，处理需要提供域名或ip地址和端口外，还需要提供协议，如\"http\"或\"https”，还有一个可选的uri可以配置。 ","date":"2020-11-23","objectID":"/openresty-server/:3:7","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"常见 location 配置样例 静态网站 server { listen 80; server_name russellgao.cn; access_log /usr/local/openresty/nginx/logs/access.log custom; error_log /usr/local/openresty/nginx/logs/error.log; location / { rewrite ^/(.*) https://russellgao.cn/$1 permanent; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/local/openresty/nginx/html; } error_page 404 /404.html; location = /404.html { root /usr/local/openresty/nginx/blog; } } 反向代理 location ~* (/api/v1/blog-server) { access_log /var/nginx/logs/blog_access.log custom; error_log /var/nginx/logs/blog_error.log error; proxy_pass_header Server; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; # rewrite 只是举个例子，根据实际情况配置 # rewrite /api/v1/blog-server/(.*)$ /api/$1 break; proxy_pass http://blog_server; } 可以在 location 级别设置日志格式以及目录，方便精细化管理 通过proxy_pass 跳转到 upstream ","date":"2020-11-23","objectID":"/openresty-server/:3:8","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"upstream upstream 是后端服务器组，也称为虚拟服务器组，作用是负载均衡。配置样例参考 upstream blog_server { #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 server 172.19.208.76:80 weight=10; server 172.19.208.77:80 weight=50; server 172.19.208.78:80 weight=40; } nginx的upstream目前支持 5 种方式的分配: 轮询（默认）：每个请求按时间顺序逐一分配到不同的后端服务。如: upstream server { server 172.19.208.76:80; server 172.19.208.77:80; server 172.19.208.78:80; } 权重 ：指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 upstream server { server 172.19.208.76:80 weight=10; server 172.19.208.77:80 weight=50; server 172.19.208.78:80 weight=40; } ip_hash：每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 upstream server { ip_hash; server 172.19.208.76:80; server 172.19.208.77:80; server 172.19.208.78:80; } fair：按后端服务器的响应时间来分配请求，响应时间短的优先分配。 upstream server { fair; server 172.19.208.76:80; server 172.19.208.77:80; server 172.19.208.78:80; } url_hash：按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法。如: upstream server { hash $request_uri; hash_method crc32; server 172.19.208.76:80; server 172.19.208.77:80; server 172.19.208.78:80; } 在 upstream 中可以给 server 设置状态，如: upstream server { server 172.19.208.76:80 down; server 172.19.208.77:80 weight=10; server 172.19.208.78:80 backup; } 支持的状态有: down表示单前的server暂时不参与负载 weight为weight越大，负载的权重就越大。 max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误 fail_timeout:max_fails次失败后，暂停的时间。 backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。 ","date":"2020-11-23","objectID":"/openresty-server/:4:0","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"参考 https://www.cnblogs.com/54chensongxia/p/12938929.html https://juejin.cn/post/6844903849166110733 ","date":"2020-11-23","objectID":"/openresty-server/:5:0","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"openresty 配置文件 （一）","date":"2020-11-22","objectID":"/openresty-nginx.conf/","tags":["nginx","openresty","nginx.conf"],"title":"openresty 配置文件 （一）","uri":"/openresty-nginx.conf/"},{"categories":null,"content":"导读 openresty（nginx plus） 在日常工作中用的应该比较多，要想真正了解清楚其原理并不容易。我尝试着从配置的角度去分析 nginx 的基本原理。这篇主要介绍 nginx.conf 这个配置文件，后续再介绍其他的配置文件。 nginx.conf 中主要配置全局配置，配置好之后一般很少改动。 ","date":"2020-11-22","objectID":"/openresty-nginx.conf/:1:0","tags":["nginx","openresty","nginx.conf"],"title":"openresty 配置文件 （一）","uri":"/openresty-nginx.conf/"},{"categories":null,"content":"nginx.conf 配置项说明 #定义Nginx运行的用户和用户组 #user nobody; #nginx进程数，建议设置为等于CPU总核心数。 worker_processes 1; #全局错误日志定义类型，[ debug | info | notice | warn | error | crit ] #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #进程文件 #pid logs/nginx.pid; #指定进程可以打开的最大描述符 #工作模式与连接数上限 ##这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。 #这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。 worker_rlimit_nofile 65535; events { #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型 #是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。 #补充说明： #与apache相类，nginx针对不同的操作系统，有不同的事件模型 #A）标准事件模型 #Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll #B）高效事件模型 #Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。 #Epoll：使用于Linux内核2.6版本及以后的系统。 #/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。 #Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。 use epoll #单个进程最大连接数（最大连接数=连接数+进程数） worker_connections 65535; #keepalive 超时时间 keepalive_timeout 60; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。 #分页大小可以用命令getconf PAGESIZE 取得。 #[root@web001 ~]# getconf PAGESIZE #但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。 client_header_buffer_size 4k; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。 open_file_cache max=65535 inactive=60s; #这个是指多长时间检查一次缓存的有效信息。 #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息. open_file_cache_valid 80s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。 #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location 这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态. open_file_cache_min_uses 1; #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误. open_file_cache_errors on; #默认是on。设置为on后，多个worker按串行方式来处理连接，也就是一个连接只有一个worker被唤醒，其他的处于休眠状态。 #设置为off后，多个worker按并行方式来处理连接，也就是一个连接会唤醒所有的worker，知道连接分配完毕，没有取得连接的继续休眠。 #当你的服务器连接数不多时，开启这个参数会让负载有一定程度的降低。但是当服务器的吞吐量很大时，为了效率，请关闭这个参数。 multi_accept off; } #设定http服务器 http { #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; # 增加 header add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods \"GET, POST, OPTIONS\"; #默认编码 charset utf-8; #服务器名字的hash表大小 #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小. server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。 client_header_buffer_size 32k; #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。 large_client_header_buffers 4 64k; #设定通过nginx上传文件的大小 client_max_body_size 8m; #开启目录列表访问，合适下载服务器，默认关闭。 autoindex on; # 限流 limit_req_zone $server_name zone=xiaozhi_log:50m rate=40r/s; limit_req_zone $server_name zone=tico_log:50m rate=40r/s; #开启限制IP连接数的时候需要使用 #limit_zone crawler $binary_remote_addr 10m; # 日志格式定义，这里可以根据自己的日志规范进行自定义 #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; # 这里推荐一个日志格式 log_format custom '[$time_local] $remote_addr $remote_user $request ' '$status $upstream_response_time $request_time $body_bytes_sent $http_referer ' '$http_user_agent $http_x_forwarded_for ' ; #access_log logs/access.log main; #开启高效文件传输模式，sendfil","date":"2020-11-22","objectID":"/openresty-nginx.conf/:2:0","tags":["nginx","openresty","nginx.conf"],"title":"openresty 配置文件 （一）","uri":"/openresty-nginx.conf/"},{"categories":null,"content":"nginx.conf 样例 worker_processes 2; events { worker_connections 65535; } http { include mime.types; default_type application/octet-stream; log_format custom '[$time_local] $remote_addr $remote_user $request ' '$status $upstream_response_time $request_time $body_bytes_sent $http_referer ' '$http_user_agent $http_x_forwarded_for ' ; client_body_temp_path /var/run/openresty/nginx-client-body; proxy_temp_path /var/run/openresty/nginx-proxy; fastcgi_temp_path /var/run/openresty/nginx-fastcgi; uwsgi_temp_path /var/run/openresty/nginx-uwsgi; scgi_temp_path /var/run/openresty/nginx-scgi; sendfile on; keepalive_timeout 90; include /etc/nginx/conf.d/*.conf; } ","date":"2020-11-22","objectID":"/openresty-nginx.conf/:3:0","tags":["nginx","openresty","nginx.conf"],"title":"openresty 配置文件 （一）","uri":"/openresty-nginx.conf/"},{"categories":null,"content":"接下来 这是 openresty 配置文件系列篇，这篇介绍了 nginx.conf (全局配置) ，接下来还有 server 、 upstream、location 等介绍。 每天掌握一个知识点，积少成多，一周玩转 openresty 。 ","date":"2020-11-22","objectID":"/openresty-nginx.conf/:4:0","tags":["nginx","openresty","nginx.conf"],"title":"openresty 配置文件 （一）","uri":"/openresty-nginx.conf/"},{"categories":null,"content":"参考 https://juejin.cn/post/6844903741678698510 ","date":"2020-11-22","objectID":"/openresty-nginx.conf/:5:0","tags":["nginx","openresty","nginx.conf"],"title":"openresty 配置文件 （一）","uri":"/openresty-nginx.conf/"},{"categories":null,"content":"kubernetes 中patch与update比较","date":"2020-11-21","objectID":"/kubernetes/patch-update/","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"导读 不知道你有没有想过一个问题：对于一个 K8s 资源对象比如 Deployment，我们尝试在修改其中 image 镜像时，如果有其他人同时也在对这个 Deployment 做修改，会发生什么？ 当然，这里还可以引申出两个问题： 如果双方修改的是同一个字段，比如 image 字段，结果会怎样？ 如果双方修改的是不同字段，比如一个修改 image，另一个修改 replicas，又会怎么样？ 其实，对一个 Kubernetes 资源对象做“更新”操作，简单来说就是通知 kube-apiserver 组件我们希望如何修改这个对象。而 K8s 为这类需求定义了两种“通知”方式，分别是 update 和 patch。在 update 请求中，我们需要将整个修改后的对象提交给 K8s；而对于 patch 请求，我们只需要将对象中某些字段的修改提交给 K8s。 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:1:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"Update 机制 Kubernetes 中的所有资源对象，都有一个全局唯一的版本号（metadata.resourceVersion）。每个资源对象从创建开始就会有一个版本号，而后每次被修改（不管是 update 还是 patch 修改），版本号都会发生变化。 官方文档 告诉我们，这个版本号是一个 K8s 的内部机制，用户不应该假设它是一个数字或者通过比较两个版本号大小来确定资源对象的新旧，唯一能做的就是通过比较版本号相等来确定对象是否是同一个版本（即是否发生了变化）。而 resourceVersion 一个重要的用处，就是来做 update 请求的版本控制。 K8s 要求用户 update 请求中提交的对象必须带有 resourceVersion，也就是说我们提交 update 的数据必须先来源于 K8s 中已经存在的对象。因此，一次完整的 update 操作流程是： 首先，从 K8s 中拿到一个已经存在的对象（可以选择直接从 K8s 中查询；如果在客户端做了 list watch，推荐从本地 informer 中获取）； 然后，基于这个取出来的对象做一些修改，比如将 Deployment 中的 replicas 做增减，或是将 image 字段修改为一个新版本的镜像； 最后，将修改后的对象通过 update 请求提交给 K8s； 此时，kube-apiserver 会校验用户 update 请求提交对象中的 resourceVersion 一定要和当前 K8s 中这个对象最新的 resourceVersion 一致，才能接受本次 update。否则，K8s 会拒绝请求，并告诉用户发生了版本冲突（Conflict）。 上图展示了多个用户同时 update 某一个资源对象时会发生的事情。而如果如果发生了 Conflict 冲突，对于 User A 而言应该做的就是做一次重试，再次获取到最新版本的对象，修改后重新提交 update。 因此，我们上面的两个问题也都得到了解答： 用户修改 YAML 后提交 update 失败，是因为 YAML 文件中没有包含 resourceVersion 字段。对于 update 请求而言，应该取出当前 K8s 中的对象做修改后提交； 如果两个用户同时对一个资源对象做 update，不管操作的是对象中同一个字段还是不同字段，都存在版本控制的机制确保两个用户的 update 请求不会发生覆盖。 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:2:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"Patch 机制 相比于 update 的版本控制，K8s 的 patch 机制则显得更加简单。 当用户对某个资源对象提交一个 patch 请求时，kube-apiserver 不会考虑版本问题，而是“无脑”地接受用户的请求（只要请求发送的 patch 内容合法），也就是将 patch 打到对象上、同时更新版本号。 不过，patch 的复杂点在于，目前 K8s 提供了 4 种 patch 策略：json patch、merge patch、strategic merge patch、apply patch（从 K8s 1.14 支持 server-side apply 开始）。通过 kubectl patch -h 命令我们也可以看到这个策略选项（默认采用 strategic）： $ kubectl patch -h # ... --type='strategic': The type of patch being provided; one of [json merge strategic] 篇幅限制这里暂不对每个策略做详细的介绍了，我们就以一个简单的例子来看一下它们的差异性。如果针对一个已有的 Deployment 对象，假设 template 中已经有了一个名为 app 的容器： 如果要在其中新增一个 nginx 容器，如何 patch 更新？ 如果要修改 app 容器的镜像，如何 patch 更新？ ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:3:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"json patch 新增容器： kubectl patch deployment/foo --type='json' -p \\ '[{\"op\":\"add\",\"path\":\"/spec/template/spec/containers/1\",\"value\":{\"name\":\"nginx\",\"image\":\"nginx:alpine\"}}]' 修改已有容器 image： kubectl patch deployment/foo --type='json' -p \\ '[{\"op\":\"replace\",\"path\":\"/spec/template/spec/containers/0/image\",\"value\":\"app-image:v2\"}]' 这样一来，如果我们 patch 之前这个对象已经被其他人修改了，那么我们的 patch 有可能产生非预期的后果。比如在执行 app 容器镜像更新时，我们指定的序号是 0，但此时 containers 列表中第一个位置被插入了另一个容器，则更新的镜像就被错误地插入到这个非预期的容器中。 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:3:1","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"merge patch merge patch 无法单独更新一个列表中的某个元素，因此不管我们是要在 containers 里新增容器、还是修改已有容器的 image、env 等字段，都要用整个 containers 列表来提交 patch： kubectl patch deployment/foo --type='merge' -p \\ '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"app\",\"image\":\"app-image:v2\"},{\"name\":\"nginx\",\"image\":\"nginx:alpline\"}]}}}}' 显然，这个策略并不适合我们对一些列表深层的字段做更新，更适用于大片段的覆盖更新。 不过对于 labels/annotations 这些 map 类型的元素更新，merge patch 是可以单独指定 key-value 操作的，相比于 json patch 方便一些，写起来也更加直观： kubectl patch deployment/foo –type='merge’ -p ‘{“metadata”:{“labels”:{“test-key”:“foo”}}}’ ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:3:2","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"strategic merge patch 这种 patch 策略并没有一个通用的 RFC 标准，而是 K8s 独有的，不过相比前两种而言却更为强大的。 我们先从 K8s 源码看起，在 K8s 原生资源的数据结构定义中额外定义了一些的策略注解。比如以下这个截取了 podSpec 中针对 containers 列表的定义 // ... // +patchMergeKey=name // +patchStrategy=merge Containers []Container `json:\"containers\" patchStrategy:\"merge\" patchMergeKey:\"name\" protobuf:\"bytes,2,rep,name=containers\"` 可以看到其中有两个关键信息：patchStrategy:“merge” patchMergeKey:“name” 。这就代表了，containers 列表使用 strategic merge patch 策略更新时，会把下面每个元素中的 name 字段看作 key。 简单来说，在我们 patch 更新 containers 不再需要指定下标序号了，而是指定 name 来修改，K8s 会把 name 作为 key 来计算 merge。比如针对以下的 patch 操作： kubectl patch deployment/foo -p \\ '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"nginx\",\"image\":\"nginx:mainline\"}]}}}}' 如果 K8s 发现当前 containers 中已经有名字为 nginx 的容器，则只会把 image 更新上去；而如果当前 containers 中没有 nginx 容器，K8s 会把这个容器插入 containers 列表。 此外还要说明的是，目前 strategic 策略只能用于原生 K8s 资源以及 Aggregated API 方式的自定义资源，对于 CRD 定义的资源对象，是无法使用的。这很好理解，因为 kube-apiserver 无法得知 CRD 资源的结构和 merge 策略。如果用 kubectl patch 命令更新一个 CR，则默认会采用 merge patch 的策略来操作。 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:3:3","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"kubectl 封装 了解完了 K8s 的基础更新机制，我们再次回到最初的问题上。为什么用户修改 YAML 文件后无法直接调用 update 接口更新，却可以通过 kubectl apply 命令更新呢？ 其实 kubectl 为了给命令行用户提供良好的交互体感，设计了较为复杂的内部执行逻辑，诸如 apply、edit 这些常用操作其实背后并非对应一次简单的 update 请求。毕竟 update 是有版本控制的，如果发生了更新冲突对于普通用户并不友好。以下简略介绍下 kubectl 几种更新操作的逻辑，有兴趣可以看一下 link:https://github.com/kubernetes/kubectl[kubectl] 封装的源码。 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:3:4","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"apply 在使用默认参数执行 apply 时，触发的是 client-side apply。kubectl 逻辑如下： 首先解析用户提交的数据（YAML/JSON）为一个对象 A；然后调用 Get 接口从 K8s 中查询这个资源对象： 如果查询结果不存在，kubectl 将本次用户提交的数据记录到对象 A 的 annotation 中（key 为 kubectl.kubernetes.io/last-applied-configuration），最后将对象 A提交给 K8s 创建； 如果查询到 K8s 中已有这个资源，假设为对象 B：1. kubectl 尝试从对象 B 的 annotation 中取出 kubectl.kubernetes.io/last-applied-configuration 的值（对应了上一次 apply 提交的内容）；2. kubectl 根据前一次 apply 的内容和本次 apply 的内容计算出 diff（默认为 strategic merge patch 格式，如果非原生资源则采用 merge patch）；3. 将 diff 中添加本次的 kubectl.kubernetes.io/last-applied-configuration annotation，最后用 patch 请求提交给 K8s 做更新。 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:3:5","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"edit kubectl edit 逻辑上更简单一些。在用户执行命令之后，kubectl 从 K8s 中查到当前的资源对象，并打开一个命令行编辑器（默认用 vi）为用户提供编辑界面。 当用户修改完成、保存退出时，kubectl 并非直接把修改后的对象提交 update（避免 Conflict，如果用户修改的过程中资源对象又被更新），而是会把修改后的对象和初始拿到的对象计算 diff，最后将 diff 内容用 patch 请求提交给 K8s。 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:3:6","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"总结 看了上述的介绍，大家应该对 K8s 更新机制有了一个初步的了解了。接下来想一想，既然 K8s 提供了两种更新方式，我们在不同的场景下怎么选择 update 或 patch 来使用呢？这里我们的建议是： 如果要更新的字段只有我们自己会修改（比如我们有一些自定义标签，并写了 operator 来管理），则使用 patch 是最简单的方式； 如果要更新的字段可能会被其他方修改（比如我们修改的 replicas 字段，可能有一些其他组件比如 HPA 也会做修改），则建议使用 update 来更新，避免出现互相覆盖。 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:4:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"参考 https://aijishu.com/a/1060000000118183 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:5:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"kubernetes 中patch与update比较","date":"2020-11-21","objectID":"/patch-update/","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"导读 不知道你有没有想过一个问题：对于一个 K8s 资源对象比如 Deployment，我们尝试在修改其中 image 镜像时，如果有其他人同时也在对这个 Deployment 做修改，会发生什么？ 当然，这里还可以引申出两个问题： 如果双方修改的是同一个字段，比如 image 字段，结果会怎样？ 如果双方修改的是不同字段，比如一个修改 image，另一个修改 replicas，又会怎么样？ 其实，对一个 Kubernetes 资源对象做“更新”操作，简单来说就是通知 kube-apiserver 组件我们希望如何修改这个对象。而 K8s 为这类需求定义了两种“通知”方式，分别是 update 和 patch。在 update 请求中，我们需要将整个修改后的对象提交给 K8s；而对于 patch 请求，我们只需要将对象中某些字段的修改提交给 K8s。 ","date":"2020-11-21","objectID":"/patch-update/:1:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"Update 机制 Kubernetes 中的所有资源对象，都有一个全局唯一的版本号（metadata.resourceVersion）。每个资源对象从创建开始就会有一个版本号，而后每次被修改（不管是 update 还是 patch 修改），版本号都会发生变化。 官方文档 告诉我们，这个版本号是一个 K8s 的内部机制，用户不应该假设它是一个数字或者通过比较两个版本号大小来确定资源对象的新旧，唯一能做的就是通过比较版本号相等来确定对象是否是同一个版本（即是否发生了变化）。而 resourceVersion 一个重要的用处，就是来做 update 请求的版本控制。 K8s 要求用户 update 请求中提交的对象必须带有 resourceVersion，也就是说我们提交 update 的数据必须先来源于 K8s 中已经存在的对象。因此，一次完整的 update 操作流程是： 首先，从 K8s 中拿到一个已经存在的对象（可以选择直接从 K8s 中查询；如果在客户端做了 list watch，推荐从本地 informer 中获取）； 然后，基于这个取出来的对象做一些修改，比如将 Deployment 中的 replicas 做增减，或是将 image 字段修改为一个新版本的镜像； 最后，将修改后的对象通过 update 请求提交给 K8s； 此时，kube-apiserver 会校验用户 update 请求提交对象中的 resourceVersion 一定要和当前 K8s 中这个对象最新的 resourceVersion 一致，才能接受本次 update。否则，K8s 会拒绝请求，并告诉用户发生了版本冲突（Conflict）。 上图展示了多个用户同时 update 某一个资源对象时会发生的事情。而如果如果发生了 Conflict 冲突，对于 User A 而言应该做的就是做一次重试，再次获取到最新版本的对象，修改后重新提交 update。 因此，我们上面的两个问题也都得到了解答： 用户修改 YAML 后提交 update 失败，是因为 YAML 文件中没有包含 resourceVersion 字段。对于 update 请求而言，应该取出当前 K8s 中的对象做修改后提交； 如果两个用户同时对一个资源对象做 update，不管操作的是对象中同一个字段还是不同字段，都存在版本控制的机制确保两个用户的 update 请求不会发生覆盖。 ","date":"2020-11-21","objectID":"/patch-update/:2:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"Patch 机制 相比于 update 的版本控制，K8s 的 patch 机制则显得更加简单。 当用户对某个资源对象提交一个 patch 请求时，kube-apiserver 不会考虑版本问题，而是“无脑”地接受用户的请求（只要请求发送的 patch 内容合法），也就是将 patch 打到对象上、同时更新版本号。 不过，patch 的复杂点在于，目前 K8s 提供了 4 种 patch 策略：json patch、merge patch、strategic merge patch、apply patch（从 K8s 1.14 支持 server-side apply 开始）。通过 kubectl patch -h 命令我们也可以看到这个策略选项（默认采用 strategic）： $ kubectl patch -h # ... --type='strategic': The type of patch being provided; one of [json merge strategic] 篇幅限制这里暂不对每个策略做详细的介绍了，我们就以一个简单的例子来看一下它们的差异性。如果针对一个已有的 Deployment 对象，假设 template 中已经有了一个名为 app 的容器： 如果要在其中新增一个 nginx 容器，如何 patch 更新？ 如果要修改 app 容器的镜像，如何 patch 更新？ ","date":"2020-11-21","objectID":"/patch-update/:3:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"json patch 新增容器： kubectl patch deployment/foo --type='json' -p \\ '[{\"op\":\"add\",\"path\":\"/spec/template/spec/containers/1\",\"value\":{\"name\":\"nginx\",\"image\":\"nginx:alpine\"}}]' 修改已有容器 image： kubectl patch deployment/foo --type='json' -p \\ '[{\"op\":\"replace\",\"path\":\"/spec/template/spec/containers/0/image\",\"value\":\"app-image:v2\"}]' 这样一来，如果我们 patch 之前这个对象已经被其他人修改了，那么我们的 patch 有可能产生非预期的后果。比如在执行 app 容器镜像更新时，我们指定的序号是 0，但此时 containers 列表中第一个位置被插入了另一个容器，则更新的镜像就被错误地插入到这个非预期的容器中。 ","date":"2020-11-21","objectID":"/patch-update/:3:1","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"merge patch merge patch 无法单独更新一个列表中的某个元素，因此不管我们是要在 containers 里新增容器、还是修改已有容器的 image、env 等字段，都要用整个 containers 列表来提交 patch： kubectl patch deployment/foo --type='merge' -p \\ '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"app\",\"image\":\"app-image:v2\"},{\"name\":\"nginx\",\"image\":\"nginx:alpline\"}]}}}}' 显然，这个策略并不适合我们对一些列表深层的字段做更新，更适用于大片段的覆盖更新。 不过对于 labels/annotations 这些 map 类型的元素更新，merge patch 是可以单独指定 key-value 操作的，相比于 json patch 方便一些，写起来也更加直观： kubectl patch deployment/foo –type='merge’ -p ‘{“metadata”:{“labels”:{“test-key”:“foo”}}}’ ","date":"2020-11-21","objectID":"/patch-update/:3:2","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"strategic merge patch 这种 patch 策略并没有一个通用的 RFC 标准，而是 K8s 独有的，不过相比前两种而言却更为强大的。 我们先从 K8s 源码看起，在 K8s 原生资源的数据结构定义中额外定义了一些的策略注解。比如以下这个截取了 podSpec 中针对 containers 列表的定义 // ... // +patchMergeKey=name // +patchStrategy=merge Containers []Container `json:\"containers\" patchStrategy:\"merge\" patchMergeKey:\"name\" protobuf:\"bytes,2,rep,name=containers\"` 可以看到其中有两个关键信息：patchStrategy:“merge” patchMergeKey:“name” 。这就代表了，containers 列表使用 strategic merge patch 策略更新时，会把下面每个元素中的 name 字段看作 key。 简单来说，在我们 patch 更新 containers 不再需要指定下标序号了，而是指定 name 来修改，K8s 会把 name 作为 key 来计算 merge。比如针对以下的 patch 操作： kubectl patch deployment/foo -p \\ '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"nginx\",\"image\":\"nginx:mainline\"}]}}}}' 如果 K8s 发现当前 containers 中已经有名字为 nginx 的容器，则只会把 image 更新上去；而如果当前 containers 中没有 nginx 容器，K8s 会把这个容器插入 containers 列表。 此外还要说明的是，目前 strategic 策略只能用于原生 K8s 资源以及 Aggregated API 方式的自定义资源，对于 CRD 定义的资源对象，是无法使用的。这很好理解，因为 kube-apiserver 无法得知 CRD 资源的结构和 merge 策略。如果用 kubectl patch 命令更新一个 CR，则默认会采用 merge patch 的策略来操作。 ","date":"2020-11-21","objectID":"/patch-update/:3:3","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"kubectl 封装 了解完了 K8s 的基础更新机制，我们再次回到最初的问题上。为什么用户修改 YAML 文件后无法直接调用 update 接口更新，却可以通过 kubectl apply 命令更新呢？ 其实 kubectl 为了给命令行用户提供良好的交互体感，设计了较为复杂的内部执行逻辑，诸如 apply、edit 这些常用操作其实背后并非对应一次简单的 update 请求。毕竟 update 是有版本控制的，如果发生了更新冲突对于普通用户并不友好。以下简略介绍下 kubectl 几种更新操作的逻辑，有兴趣可以看一下 link:https://github.com/kubernetes/kubectl[kubectl] 封装的源码。 ","date":"2020-11-21","objectID":"/patch-update/:3:4","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"apply 在使用默认参数执行 apply 时，触发的是 client-side apply。kubectl 逻辑如下： 首先解析用户提交的数据（YAML/JSON）为一个对象 A；然后调用 Get 接口从 K8s 中查询这个资源对象： 如果查询结果不存在，kubectl 将本次用户提交的数据记录到对象 A 的 annotation 中（key 为 kubectl.kubernetes.io/last-applied-configuration），最后将对象 A提交给 K8s 创建； 如果查询到 K8s 中已有这个资源，假设为对象 B：1. kubectl 尝试从对象 B 的 annotation 中取出 kubectl.kubernetes.io/last-applied-configuration 的值（对应了上一次 apply 提交的内容）；2. kubectl 根据前一次 apply 的内容和本次 apply 的内容计算出 diff（默认为 strategic merge patch 格式，如果非原生资源则采用 merge patch）；3. 将 diff 中添加本次的 kubectl.kubernetes.io/last-applied-configuration annotation，最后用 patch 请求提交给 K8s 做更新。 ","date":"2020-11-21","objectID":"/patch-update/:3:5","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"edit kubectl edit 逻辑上更简单一些。在用户执行命令之后，kubectl 从 K8s 中查到当前的资源对象，并打开一个命令行编辑器（默认用 vi）为用户提供编辑界面。 当用户修改完成、保存退出时，kubectl 并非直接把修改后的对象提交 update（避免 Conflict，如果用户修改的过程中资源对象又被更新），而是会把修改后的对象和初始拿到的对象计算 diff，最后将 diff 内容用 patch 请求提交给 K8s。 ","date":"2020-11-21","objectID":"/patch-update/:3:6","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"总结 看了上述的介绍，大家应该对 K8s 更新机制有了一个初步的了解了。接下来想一想，既然 K8s 提供了两种更新方式，我们在不同的场景下怎么选择 update 或 patch 来使用呢？这里我们的建议是： 如果要更新的字段只有我们自己会修改（比如我们有一些自定义标签，并写了 operator 来管理），则使用 patch 是最简单的方式； 如果要更新的字段可能会被其他方修改（比如我们修改的 replicas 字段，可能有一些其他组件比如 HPA 也会做修改），则建议使用 update 来更新，避免出现互相覆盖。 ","date":"2020-11-21","objectID":"/patch-update/:4:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"参考 https://aijishu.com/a/1060000000118183 ","date":"2020-11-21","objectID":"/patch-update/:5:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"kubectl 常用命令指南","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"导读 kubectl 应该是每个接触 kubernetes 的人都会接触的一个组件，它带给我们强大的命令行体验，本篇文章就是介绍 kubectl 中的一些常用命令，在结合一些具体的使用场景说说如何利用 kubectl 实现。好记性不如烂笔头，在这里尽可能全的罗列，方便后续 用的时候查找。如果能帮到您就收藏起来吧(😄)。 本次实验环境是 kubernetes-1.16.9，本篇文档的写作思路是按照平时 的使用场景进行写作，不会详细介绍 kubectl 的命令，kubectl 详细的帮助文档参考 kubectl --help or kubectl command --help 。 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:1:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"kubectl 支持的命令 kubectl --help kubectl controls the Kubernetes cluster manager. Find more information at: https://kubernetes.io/docs/reference/kubectl/overview/ Basic Commands (Beginner): create Create a resource from a file or from stdin. expose 使用 replication controller, service, deployment 或者 pod 并暴露它作为一个 新的 Kubernetes Service run 在集群中运行一个指定的镜像 set 为 objects 设置一个指定的特征 Basic Commands (Intermediate): explain 查看资源的文档 get 显示一个或更多 resources edit 在服务器上编辑一个资源 delete Delete resources by filenames, stdin, resources and names, or by resources and label selector Deploy Commands: rollout Manage the rollout of a resource scale 为 Deployment, ReplicaSet, Replication Controller 或者 Job 设置一个新的副本数量 autoscale 自动调整一个 Deployment, ReplicaSet, 或者 ReplicationController 的副本数量 Cluster Management Commands: certificate 修改 certificate 资源. cluster-info 显示集群信息 top Display Resource (CPU/Memory/Storage) usage. cordon 标记 node 为 unschedulable uncordon 标记 node 为 schedulable drain Drain node in preparation for maintenance taint 更新一个或者多个 node 上的 taints Troubleshooting and Debugging Commands: describe 显示一个指定 resource 或者 group 的 resources 详情 logs 输出容器在 pod 中的日志 attach Attach 到一个运行中的 container exec 在一个 container 中执行一个命令 port-forward Forward one or more local ports to a pod proxy 运行一个 proxy 到 Kubernetes API server cp 复制 files 和 directories 到 containers 和从容器中复制 files 和 directories. auth Inspect authorization Advanced Commands: diff Diff live version against would-be applied version apply 通过文件名或标准输入流(stdin)对资源进行配置 patch 使用 strategic merge patch 更新一个资源的 field(s) replace 通过 filename 或者 stdin替换一个资源 wait Experimental: Wait for a specific condition on one or many resources. convert 在不同的 API versions 转换配置文件 kustomize Build a kustomization target from a directory or a remote url. Settings Commands: label 更新在这个资源上的 labels annotate 更新一个资源的注解 completion Output shell completion code for the specified shell (bash or zsh) Other Commands: api-resources Print the supported API resources on the server api-versions Print the supported API versions on the server, in the form of \"group/version\" config 修改 kubeconfig 文件 plugin Provides utilities for interacting with plugins. version 输出 client 和 server 的版本信息 Usage: kubectl [flags] [options] Use \"kubectl \u003ccommand\u003e --help\" for more information about a given command. Use \"kubectl options\" for a list of global command-line options (applies to all commands). 从上面的帮助文档可以看出， kubectl 基本格式为 kubectl verb resource options , kubectl 后跟谓语动词， 再跟要操作的资源，可以加 options ，如： 要看 monitoring namespace 下面有哪些pod : kubectl -n monitoring get po ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:2:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"pod pod 场景下，可能会有如下需求: ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看某个 namespace 下，所有的pod # 先查看有哪些namespace kubectl get namespace # 查看 pod kubectl -n $namespace get po # 或者 kubectl get po -n $namespace 上面两种写法在达到的效果上是一样的，但是有一个细节可以注意一下，如果 kubectl 环境有命令自动补全的话，资源对象又比较多 的情况下，第一种写法将会有极大的优势，可以思考这么个场景，如：要查看 monitoring namespace 下的某个pod 详情, 就可以通过: kubectl -n monitoring get po 加 tab 键，列出这个namespace 下的所有 pod 供筛选。 centos 下命令自动补全需要安装 bash-completion ，方法为 yum install -y bash-completion 如果不加 -n $namespace ，则默认是 default namespace ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:1","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看所有namespace 的pod kubectl get po --all-namespaces # or kubectl get po -A ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:2","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看某个具体的 pod 信息 ，以 wide、json、yaml 的格式输出 kubectl -n $namespace get po xxx -o wide/json/yaml # 如 查看 monitoring 下的 prometheus-0 pod 信息，并以yaml 形式输出。 kubectl -n monitoring get po prometheus-0 -o yaml ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:3","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看某个 pod 的某个字段信息 如果我们只想知道 pod 的 hostIP 或者其他的 一些字段， 可以通过 -o jsonpath or -o template or -o go-template 其中template 语法遵循 golang template 需要对 pod 的对象模型有一定的了解，如果不了解，可以 -o yaml or -o json 直接查看。 查看 hostIP 的方法如下: # -o jsonpath kubectl -n monitoring get po prometheus-k8s-0 -o jsonpath=\"{.status.hostIP}\" # -o template kubectl -n monitoring get po prometheus-k8s-0 -o template --template=\"{{.status.hostIP}}\" # -o go-template kubectl -n monitoring get po prometheus-k8s-0 -o go-template=\"{{.status.hostIP}}\" 如果需要查看其他的字段照猫画虎即可。 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:4","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"通过标签选择查看 pod 通过 -l key1=value1,key2=value2 进行选择，如 kubectl -n monitoring get po -l app=prometheus kubectl -n monitoring get po -l app=prometheus,prometheus=k8s ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:5","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看某个node 上部署的所有 pod #先获取集群内所有的node kubectl get node -o wide # 假设其中一个 node 的名称为 node-0001 kubectl get po -A -o wide | grep node-0001 通过 kubectl get po -A -o wide | grep 可以做很多事情，具体可以根据情况而定，比如查看所有状态异常的 pod （非 Running） kubectl get po -A -o wide | grep -v Running ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:6","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看 pod 的详细信息 kubectl -n monitoring describe po prometheus-k8s-0 这个命令在查看 pod 的基本信息和问题定位时特别有用，当 pod 异常，可以查看 Events 或许就能发现问题所在。 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:7","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看 pod log kubectl -n $namespace logs -f $podName $containerName # 其中 $namespace，$podName，$containerName 替换成真实值即可，当 pod 中只有一个 容器时可省略 $containerName，如： kubectl -n monitoring logs -f prometheus-k8s-0 prometheus ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:8","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"进入容器 kubectl -n $namespace exec -it $podName -c $containerName sh # 其中 $namespace，$podName，$containerName 替换成真实值即可，当 pod 中只有一个 容器时可省略 -c $containerName，如： kubectl -n monitoring exec -it prometheus-k8s-0 -c prometheus sh ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:9","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看 pod 的资源使用情况 kubectl -n $namespace top pod # 其中 $namespace 替换成真实值即可，如： kubectl -n monitoring top pod ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:10","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"删除 pod kubectl -n $namespace delete po $podName kubectl -n monitoring delete po prometheus-k8s-0 # 在某些异常情况下删除 pod 会卡住，删不掉，需要强制才能删除 ，强制删除需要增加 --grace-period=0 --force ， kubectl -n monitoring delete po prometheus-k8s-0 --grace-period=0 --force 原理如下， 默认执行 delete po 时，kubectl 会增加–grace-period=30 参数，表示预留30秒的时间给 pod 处理当前的请求， 但同时也不接收新的请求了，以一种相对优雅的方式停止容器，注意这个参数在创建 pod 时可以指定，默认是30秒。强制删除时需要把–grace-period 设置为0，表示不等待马上删除，否则强制删除就会失效。 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:11","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"pod 标签管理 pod 的大多数的情况都会由 deployment or statefulset 来管理，所以标签也会通过它们管理，实际情况下很少会通过 kubectl 对 pod label 做增删改，如有需要可参考 下面 node 的用法，只需要把资源对象换成 pod 即可。 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:12","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"文件 copy 从 pod 中 copy 文件或者 copy 到 pod 中去。 容器中需要有 tar 命令，否则会失败 # 从本地 copy 到 pod kubectl cp /tmp/foo_dir \u003csome-pod\u003e:/tmp/bar_dir kubectl -n monitoring cp abc.txt prometheus-k8s-0:/tmp/abc.txt # 如果 pod 中有多个 container 可以用 -c 指定 container kubectl cp /tmp/foo \u003csome-pod\u003e:/tmp/bar -c \u003cspecific-container\u003e kubectl -n monitoring cp abc.txt prometheus-k8s-0:/tmp/abc.txt -c prometheus # 从 pod copy 到 本地 kubectl cp \u003csome-pod\u003e:/tmp/foo /tmp/bar kubectl -n monitoring cp prometheus-k8s-0:/tmp/abc.txt /tmp/abd.txt ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:13","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"node 在 pod 一节 已经了解了 kubectl get ,kubectl describe , 等相关的用法，node 的操作和 pod 类似，只是后面接的资源对象不同。 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看有哪些node以及其基本信息 kubectl get node -o wide ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:1","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看 node 上的详细情况 # 查看所有 node 的详细信息 kubectl describe node # 也可以查看某个 node 的信息 kubectl describe node node-0001 ... 这个命令在定位 node 的问题很有用，会输出如下信息: Labels Annotations Non-terminated Pods (正在运行的 pod) Allocated resources (已经分配的资源) … ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:2","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看 node 的资源使用情况 kubectl top node ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:3","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"node 的标签管理 增加标签 kubectl label node $nodename key1=value1 key2=value2 # 如 kubectl label node node-0001 a1=bbb a2=ccc 更新标签 # 在 增加标签的基础 加 --overwrite 参数 kubectl label node node-0001 a1=bbb --overwrite # 当标签不存在也可以 加 --overwrite 参数 kubectl label node node-0001 a10=bbb --overwrite 删除标签 kubectl label node $nodename key1- key2- kubectl label node node-0001 a10- a3- ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:4","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"将一个 node 标记为不可调度/可调度 在调试过程中或者当其中的某些 node 出现问题时，需要将 node 标记为不可调度，等恢复回来再标记回来。 # 将一个 node 可以 标记为不可调度(unschedulable) ，如果只是看看效果，而不是真正标记可加 --dry-run 参数 kubectl cordon $nodeName kubectl cordon node-0001 kubectl cordon node-0001 --dry-run # 将一个 node 可以 标记为可调度(schedulable) ，如果只是看看效果，而不是真正标记可加 --dry-run 参数 kubectl uncordon $nodeName kubectl uncordon node-0001 kubectl uncordon node-0001 --dry-run ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:5","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"排空 node 上的 pod # 排空node 上的所有 pod ，即使没有被 rc 管理，但是不会排空 被 daemonset 管理的 pod， 因为排空之后又会马上创建出来 kubectl drain foo --force ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:6","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"node 上的污点（taint）管理 污点需要配合 pod 的亲和性使用，否则污点没有什么意义 # 增加/更新 taint kubectl taint nodes node-0001 dedicated=special-user:NoSchedule --overwrite # 删除 taint kubectl taint nodes foo dedicated:NoSchedule- kubectl taint nodes foo dedicated- 整体用法和 label 类似 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:7","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"node 的 annotate 管理 和 label 是类似的，只是把 verb 换成 annotate 即可 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:8","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"其他场景 上面通过 pod 和 node 的例子，穿插的介绍了大部分的 verb（如 get 、describe、top … ），这个小节再介绍其他的一些常用场景 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:5:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"apply 在准备好一个资源对象的 yaml 文件时可以用 kubectl apply -f xxx.ymal 使之生效，kubernetes 的api 中并没有 apply，api 中有的是 create 、update、patch 等，apply 是kubectl 自己封装实现的，先执行 get ，再判断是 create 还是 patch，所以用kubectl 创建或者更新资源时 都可以用 apply 命令。 # 创建资源 kubectl apply -f xxx.ymal kubectl create -f xxx.ymal # 更新资源 kubectl apply -f xxx.ymal kubectl update -f xxx.ymal kubectl patch -f xxx.ymal ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:5:1","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"滚动更新 想象这么一个场景，如果使用 configmap 或者 secret 当作 pod 的环境变量，那么当 configmap 或者 secret 更新了应该如何更新 对应的pod 呢？ pod 应该都会通过 deployment 或者 statefulset 来环境， 换言之该如何更新 deployment 或者 statefulset 呢？默认情况下 configmap 或者 secret 的更新是不会触发 deployment 或者 statefulset 的更新，一种可行的方法为: 更新 annotations 中一个无关的字段: kubectl -n $namespace patch deployment $deploymentName -p \\ \"{\\\"spec\\\":{\\\"template\\\":{\\\"metadata\\\":{\\\"annotations\\\":{\\\"test_date\\\":\\\"`date +'%s'`\\\"}}}}}\" kubectl -n monitor patch deployment prometheus -p \\ \"{\\\"spec\\\":{\\\"template\\\":{\\\"metadata\\\":{\\\"annotations\\\":{\\\"test_date\\\":\\\"`date +'%s'`\\\"}}}}}\" ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:5:2","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"总结 这篇文章介绍了 kubectl 的基本用法，常见场景中的一些操作，如果有其他场景可以通过 kubectl --help 和 kubectl command --help 查看帮助文档。 如有不正确之处欢迎指正。 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:6:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"参考 https://kubernetes.io/zh/docs/reference/kubectl/cheatsheet/ https://mp.weixin.qq.com/s/OxYbLmTKXn5jrgStIQ6ohQ ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:7:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"kubectl 常用命令指南","date":"2020-11-20","objectID":"/kubectl-command/","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"导读 kubectl 应该是每个接触 kubernetes 的人都会接触的一个组件，它带给我们强大的命令行体验，本篇文章就是介绍 kubectl 中的一些常用命令，在结合一些具体的使用场景说说如何利用 kubectl 实现。好记性不如烂笔头，在这里尽可能全的罗列，方便后续 用的时候查找。如果能帮到您就收藏起来吧(😄)。 本次实验环境是 kubernetes-1.16.9，本篇文档的写作思路是按照平时 的使用场景进行写作，不会详细介绍 kubectl 的命令，kubectl 详细的帮助文档参考 kubectl --help or kubectl command --help 。 ","date":"2020-11-20","objectID":"/kubectl-command/:1:0","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"kubectl 支持的命令 kubectl --help kubectl controls the Kubernetes cluster manager. Find more information at: https://kubernetes.io/docs/reference/kubectl/overview/ Basic Commands (Beginner): create Create a resource from a file or from stdin. expose 使用 replication controller, service, deployment 或者 pod 并暴露它作为一个 新的 Kubernetes Service run 在集群中运行一个指定的镜像 set 为 objects 设置一个指定的特征 Basic Commands (Intermediate): explain 查看资源的文档 get 显示一个或更多 resources edit 在服务器上编辑一个资源 delete Delete resources by filenames, stdin, resources and names, or by resources and label selector Deploy Commands: rollout Manage the rollout of a resource scale 为 Deployment, ReplicaSet, Replication Controller 或者 Job 设置一个新的副本数量 autoscale 自动调整一个 Deployment, ReplicaSet, 或者 ReplicationController 的副本数量 Cluster Management Commands: certificate 修改 certificate 资源. cluster-info 显示集群信息 top Display Resource (CPU/Memory/Storage) usage. cordon 标记 node 为 unschedulable uncordon 标记 node 为 schedulable drain Drain node in preparation for maintenance taint 更新一个或者多个 node 上的 taints Troubleshooting and Debugging Commands: describe 显示一个指定 resource 或者 group 的 resources 详情 logs 输出容器在 pod 中的日志 attach Attach 到一个运行中的 container exec 在一个 container 中执行一个命令 port-forward Forward one or more local ports to a pod proxy 运行一个 proxy 到 Kubernetes API server cp 复制 files 和 directories 到 containers 和从容器中复制 files 和 directories. auth Inspect authorization Advanced Commands: diff Diff live version against would-be applied version apply 通过文件名或标准输入流(stdin)对资源进行配置 patch 使用 strategic merge patch 更新一个资源的 field(s) replace 通过 filename 或者 stdin替换一个资源 wait Experimental: Wait for a specific condition on one or many resources. convert 在不同的 API versions 转换配置文件 kustomize Build a kustomization target from a directory or a remote url. Settings Commands: label 更新在这个资源上的 labels annotate 更新一个资源的注解 completion Output shell completion code for the specified shell (bash or zsh) Other Commands: api-resources Print the supported API resources on the server api-versions Print the supported API versions on the server, in the form of \"group/version\" config 修改 kubeconfig 文件 plugin Provides utilities for interacting with plugins. version 输出 client 和 server 的版本信息 Usage: kubectl [flags] [options] Use \"kubectl \u003ccommand\u003e --help\" for more information about a given command. Use \"kubectl options\" for a list of global command-line options (applies to all commands). 从上面的帮助文档可以看出， kubectl 基本格式为 kubectl verb resource options , kubectl 后跟谓语动词， 再跟要操作的资源，可以加 options ，如： 要看 monitoring namespace 下面有哪些pod : kubectl -n monitoring get po ","date":"2020-11-20","objectID":"/kubectl-command/:2:0","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"pod pod 场景下，可能会有如下需求: ","date":"2020-11-20","objectID":"/kubectl-command/:3:0","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看某个 namespace 下，所有的pod # 先查看有哪些namespace kubectl get namespace # 查看 pod kubectl -n $namespace get po # 或者 kubectl get po -n $namespace 上面两种写法在达到的效果上是一样的，但是有一个细节可以注意一下，如果 kubectl 环境有命令自动补全的话，资源对象又比较多 的情况下，第一种写法将会有极大的优势，可以思考这么个场景，如：要查看 monitoring namespace 下的某个pod 详情, 就可以通过: kubectl -n monitoring get po 加 tab 键，列出这个namespace 下的所有 pod 供筛选。 centos 下命令自动补全需要安装 bash-completion ，方法为 yum install -y bash-completion 如果不加 -n $namespace ，则默认是 default namespace ","date":"2020-11-20","objectID":"/kubectl-command/:3:1","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看所有namespace 的pod kubectl get po --all-namespaces # or kubectl get po -A ","date":"2020-11-20","objectID":"/kubectl-command/:3:2","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看某个具体的 pod 信息 ，以 wide、json、yaml 的格式输出 kubectl -n $namespace get po xxx -o wide/json/yaml # 如 查看 monitoring 下的 prometheus-0 pod 信息，并以yaml 形式输出。 kubectl -n monitoring get po prometheus-0 -o yaml ","date":"2020-11-20","objectID":"/kubectl-command/:3:3","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看某个 pod 的某个字段信息 如果我们只想知道 pod 的 hostIP 或者其他的 一些字段， 可以通过 -o jsonpath or -o template or -o go-template 其中template 语法遵循 golang template 需要对 pod 的对象模型有一定的了解，如果不了解，可以 -o yaml or -o json 直接查看。 查看 hostIP 的方法如下: # -o jsonpath kubectl -n monitoring get po prometheus-k8s-0 -o jsonpath=\"{.status.hostIP}\" # -o template kubectl -n monitoring get po prometheus-k8s-0 -o template --template=\"{{.status.hostIP}}\" # -o go-template kubectl -n monitoring get po prometheus-k8s-0 -o go-template=\"{{.status.hostIP}}\" 如果需要查看其他的字段照猫画虎即可。 ","date":"2020-11-20","objectID":"/kubectl-command/:3:4","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"通过标签选择查看 pod 通过 -l key1=value1,key2=value2 进行选择，如 kubectl -n monitoring get po -l app=prometheus kubectl -n monitoring get po -l app=prometheus,prometheus=k8s ","date":"2020-11-20","objectID":"/kubectl-command/:3:5","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看某个node 上部署的所有 pod #先获取集群内所有的node kubectl get node -o wide # 假设其中一个 node 的名称为 node-0001 kubectl get po -A -o wide | grep node-0001 通过 kubectl get po -A -o wide | grep 可以做很多事情，具体可以根据情况而定，比如查看所有状态异常的 pod （非 Running） kubectl get po -A -o wide | grep -v Running ","date":"2020-11-20","objectID":"/kubectl-command/:3:6","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看 pod 的详细信息 kubectl -n monitoring describe po prometheus-k8s-0 这个命令在查看 pod 的基本信息和问题定位时特别有用，当 pod 异常，可以查看 Events 或许就能发现问题所在。 ","date":"2020-11-20","objectID":"/kubectl-command/:3:7","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看 pod log kubectl -n $namespace logs -f $podName $containerName # 其中 $namespace，$podName，$containerName 替换成真实值即可，当 pod 中只有一个 容器时可省略 $containerName，如： kubectl -n monitoring logs -f prometheus-k8s-0 prometheus ","date":"2020-11-20","objectID":"/kubectl-command/:3:8","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"进入容器 kubectl -n $namespace exec -it $podName -c $containerName sh # 其中 $namespace，$podName，$containerName 替换成真实值即可，当 pod 中只有一个 容器时可省略 -c $containerName，如： kubectl -n monitoring exec -it prometheus-k8s-0 -c prometheus sh ","date":"2020-11-20","objectID":"/kubectl-command/:3:9","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看 pod 的资源使用情况 kubectl -n $namespace top pod # 其中 $namespace 替换成真实值即可，如： kubectl -n monitoring top pod ","date":"2020-11-20","objectID":"/kubectl-command/:3:10","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"删除 pod kubectl -n $namespace delete po $podName kubectl -n monitoring delete po prometheus-k8s-0 # 在某些异常情况下删除 pod 会卡住，删不掉，需要强制才能删除 ，强制删除需要增加 --grace-period=0 --force ， kubectl -n monitoring delete po prometheus-k8s-0 --grace-period=0 --force 原理如下， 默认执行 delete po 时，kubectl 会增加–grace-period=30 参数，表示预留30秒的时间给 pod 处理当前的请求， 但同时也不接收新的请求了，以一种相对优雅的方式停止容器，注意这个参数在创建 pod 时可以指定，默认是30秒。强制删除时需要把–grace-period 设置为0，表示不等待马上删除，否则强制删除就会失效。 ","date":"2020-11-20","objectID":"/kubectl-command/:3:11","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"pod 标签管理 pod 的大多数的情况都会由 deployment or statefulset 来管理，所以标签也会通过它们管理，实际情况下很少会通过 kubectl 对 pod label 做增删改，如有需要可参考 下面 node 的用法，只需要把资源对象换成 pod 即可。 ","date":"2020-11-20","objectID":"/kubectl-command/:3:12","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"文件 copy 从 pod 中 copy 文件或者 copy 到 pod 中去。 容器中需要有 tar 命令，否则会失败 # 从本地 copy 到 pod kubectl cp /tmp/foo_dir \u003csome-pod\u003e:/tmp/bar_dir kubectl -n monitoring cp abc.txt prometheus-k8s-0:/tmp/abc.txt # 如果 pod 中有多个 container 可以用 -c 指定 container kubectl cp /tmp/foo \u003csome-pod\u003e:/tmp/bar -c \u003cspecific-container\u003e kubectl -n monitoring cp abc.txt prometheus-k8s-0:/tmp/abc.txt -c prometheus # 从 pod copy 到 本地 kubectl cp \u003csome-pod\u003e:/tmp/foo /tmp/bar kubectl -n monitoring cp prometheus-k8s-0:/tmp/abc.txt /tmp/abd.txt ","date":"2020-11-20","objectID":"/kubectl-command/:3:13","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"node 在 pod 一节 已经了解了 kubectl get ,kubectl describe , 等相关的用法，node 的操作和 pod 类似，只是后面接的资源对象不同。 ","date":"2020-11-20","objectID":"/kubectl-command/:4:0","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看有哪些node以及其基本信息 kubectl get node -o wide ","date":"2020-11-20","objectID":"/kubectl-command/:4:1","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看 node 上的详细情况 # 查看所有 node 的详细信息 kubectl describe node # 也可以查看某个 node 的信息 kubectl describe node node-0001 ... 这个命令在定位 node 的问题很有用，会输出如下信息: Labels Annotations Non-terminated Pods (正在运行的 pod) Allocated resources (已经分配的资源) … ","date":"2020-11-20","objectID":"/kubectl-command/:4:2","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看 node 的资源使用情况 kubectl top node ","date":"2020-11-20","objectID":"/kubectl-command/:4:3","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"node 的标签管理 增加标签 kubectl label node $nodename key1=value1 key2=value2 # 如 kubectl label node node-0001 a1=bbb a2=ccc 更新标签 # 在 增加标签的基础 加 --overwrite 参数 kubectl label node node-0001 a1=bbb --overwrite # 当标签不存在也可以 加 --overwrite 参数 kubectl label node node-0001 a10=bbb --overwrite 删除标签 kubectl label node $nodename key1- key2- kubectl label node node-0001 a10- a3- ","date":"2020-11-20","objectID":"/kubectl-command/:4:4","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"将一个 node 标记为不可调度/可调度 在调试过程中或者当其中的某些 node 出现问题时，需要将 node 标记为不可调度，等恢复回来再标记回来。 # 将一个 node 可以 标记为不可调度(unschedulable) ，如果只是看看效果，而不是真正标记可加 --dry-run 参数 kubectl cordon $nodeName kubectl cordon node-0001 kubectl cordon node-0001 --dry-run # 将一个 node 可以 标记为可调度(schedulable) ，如果只是看看效果，而不是真正标记可加 --dry-run 参数 kubectl uncordon $nodeName kubectl uncordon node-0001 kubectl uncordon node-0001 --dry-run ","date":"2020-11-20","objectID":"/kubectl-command/:4:5","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"排空 node 上的 pod # 排空node 上的所有 pod ，即使没有被 rc 管理，但是不会排空 被 daemonset 管理的 pod， 因为排空之后又会马上创建出来 kubectl drain foo --force ","date":"2020-11-20","objectID":"/kubectl-command/:4:6","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"node 上的污点（taint）管理 污点需要配合 pod 的亲和性使用，否则污点没有什么意义 # 增加/更新 taint kubectl taint nodes node-0001 dedicated=special-user:NoSchedule --overwrite # 删除 taint kubectl taint nodes foo dedicated:NoSchedule- kubectl taint nodes foo dedicated- 整体用法和 label 类似 ","date":"2020-11-20","objectID":"/kubectl-command/:4:7","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"node 的 annotate 管理 和 label 是类似的，只是把 verb 换成 annotate 即可 ","date":"2020-11-20","objectID":"/kubectl-command/:4:8","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"其他场景 上面通过 pod 和 node 的例子，穿插的介绍了大部分的 verb（如 get 、describe、top … ），这个小节再介绍其他的一些常用场景 ","date":"2020-11-20","objectID":"/kubectl-command/:5:0","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"apply 在准备好一个资源对象的 yaml 文件时可以用 kubectl apply -f xxx.ymal 使之生效，kubernetes 的api 中并没有 apply，api 中有的是 create 、update、patch 等，apply 是kubectl 自己封装实现的，先执行 get ，再判断是 create 还是 patch，所以用kubectl 创建或者更新资源时 都可以用 apply 命令。 # 创建资源 kubectl apply -f xxx.ymal kubectl create -f xxx.ymal # 更新资源 kubectl apply -f xxx.ymal kubectl update -f xxx.ymal kubectl patch -f xxx.ymal ","date":"2020-11-20","objectID":"/kubectl-command/:5:1","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"滚动更新 想象这么一个场景，如果使用 configmap 或者 secret 当作 pod 的环境变量，那么当 configmap 或者 secret 更新了应该如何更新 对应的pod 呢？ pod 应该都会通过 deployment 或者 statefulset 来环境， 换言之该如何更新 deployment 或者 statefulset 呢？默认情况下 configmap 或者 secret 的更新是不会触发 deployment 或者 statefulset 的更新，一种可行的方法为: 更新 annotations 中一个无关的字段: kubectl -n $namespace patch deployment $deploymentName -p \\ \"{\\\"spec\\\":{\\\"template\\\":{\\\"metadata\\\":{\\\"annotations\\\":{\\\"test_date\\\":\\\"`date +'%s'`\\\"}}}}}\" kubectl -n monitor patch deployment prometheus -p \\ \"{\\\"spec\\\":{\\\"template\\\":{\\\"metadata\\\":{\\\"annotations\\\":{\\\"test_date\\\":\\\"`date +'%s'`\\\"}}}}}\" ","date":"2020-11-20","objectID":"/kubectl-command/:5:2","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"总结 这篇文章介绍了 kubectl 的基本用法，常见场景中的一些操作，如果有其他场景可以通过 kubectl --help 和 kubectl command --help 查看帮助文档。 如有不正确之处欢迎指正。 ","date":"2020-11-20","objectID":"/kubectl-command/:6:0","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"参考 https://kubernetes.io/zh/docs/reference/kubectl/cheatsheet/ https://mp.weixin.qq.com/s/OxYbLmTKXn5jrgStIQ6ohQ ","date":"2020-11-20","objectID":"/kubectl-command/:7:0","tags":["kubernetes","kubectl","cli"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"markdown中插入表情的方法","date":"2020-11-19","objectID":"/markdownemoji/","tags":["markdown","emoji"],"title":"markdown中插入表情的方法","uri":"/markdownemoji/"},{"categories":null,"content":"导读 markdown 中也是可以插入表情，但并不是所有的markdown 解析器都支持，我本地用的 Goland、MacDown 不支持，但是 hugo 是支持的， 写作的过程可以适当加入一些表情，可以表达当时写作的一个心情。 ","date":"2020-11-19","objectID":"/markdownemoji/:1:0","tags":["markdown","emoji"],"title":"markdown中插入表情的方法","uri":"/markdownemoji/"},{"categories":null,"content":"使用场景 markdown 中支持 emoji 的地方有 : Campfire GitHub Basecamp Redbooth Trac Flowdock Sprint.ly Kandan Textbox.io Kippt Redmine JabbR Trello Hall Qiita Zendesk Ruby China Grove Idobata NodeBB Forums Slack Streamup OrganisedMinds Hackpad Cryptbin Kato Reportedly Cheerful Ghost IRCCloud Dashcube MyVideoGameList Subrosa Sococo Quip And Bang Bonusly Discourse Ello Twemoji Awesome Got Chosen Flow ReadMe.io esa DBook Groups.io TeamworkChat Damn Bugs Let’s Chat Buildkite ChatGrape Dokuwiki Usersnap Discord Status Hero Morfy Bitbucket Gitter Yellow YouTube Habitica and Mattermost ","date":"2020-11-19","objectID":"/markdownemoji/:2:0","tags":["markdown","emoji"],"title":"markdown中插入表情的方法","uri":"/markdownemoji/"},{"categories":null,"content":"用法 emoji 的表情大全参考 : https://www.webfx.com/tools/emoji-cheat-sheet/ 如果想要在 markdown 中使用，只要在相应的地方插入 :xxx: 即可， 其中 xxx 就是表情的名字 ，例: ## 插入表情示例 - 笑： 😄 - 傻笑 😏 - 害羞 😊 ... :/play secret: ","date":"2020-11-19","objectID":"/markdownemoji/:3:0","tags":["markdown","emoji"],"title":"markdown中插入表情的方法","uri":"/markdownemoji/"},{"categories":null,"content":"参考 https://www.webfx.com/tools/emoji-cheat-sheet/ ","date":"2020-11-19","objectID":"/markdownemoji/:4:0","tags":["markdown","emoji"],"title":"markdown中插入表情的方法","uri":"/markdownemoji/"},{"categories":null,"content":"python中的多线程与多进程（二）","date":"2020-11-18","objectID":"/concurrent/","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/concurrent/"},{"categories":null,"content":"导读 在上一篇“python中的多线程与多进程(一)中介绍了进程、线程的概念、基本用法和在 python 中使用遇到的一些坑， 这在一篇中会介绍一些高级的用法，当然更多的是遇到的坑，换言之这是一片避坑指南。 ","date":"2020-11-18","objectID":"/concurrent/:1:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/concurrent/"},{"categories":null,"content":"concurrent.futures 我们都知道在 python 中，多线程的标准库是使用 threading , 如 ： # -*- coding: UTF-8 -*- import threading import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) for index,value in enumerate([\"python\", \"java\", \"golang\", \"php\"]) : thread = threading.Thread(target=runner,args=(index, value, )) thread.start() 多进程的库是 multiprocessing ,如： # -*- coding: UTF-8 -*- from multiprocessing import Process import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) for index,value in enumerate([\"python\", \"java\", \"golang\", \"php\"]) : process = Process(target=runner,args=(index, value, )) process.start() 以上两个库已经 python2 已经支持，可以很好的实现我们多进程与多线程的需求。 python3.2 提供了 concurrent.futures 库，并且已经回溯到python2，这个库在 threading 与 multiprocessing 的基础上提供了一层封装，使得多线程和多进程在使用行为上保持了一致，为什么这么说呢，且看下面分析，请先看两段代码： 多线程 # -*- coding: UTF-8 -*- from concurrent.futures._base import TimeoutError from concurrent.futures import ThreadPoolExecutor import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) max_workers = 4 print(\"执行升级任务的并发数为为： {}\".format(max_workers)) runners = [\"python\", \"java\", \"golang\", \"php\", \"rust\", \"shell\", \"c\"] with ThreadPoolExecutor(max_workers=max_workers) as executor: for index, value in enumerate(runners): result = executor.submit(runner, index, value) try: result.result(timeout=3 * 60 ) except TimeoutError as err: print(\"任务超时,\", err) 多进程 # -*- coding: UTF-8 -*- from concurrent.futures._base import TimeoutError from concurrent.futures import ProcessPoolExecutor import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) max_workers = 4 print(\"执行升级任务的并发数为为： {}\".format(max_workers)) runners = [\"python\", \"java\", \"golang\", \"php\", \"rust\", \"shell\", \"c\"] with ProcessPoolExecutor(max_workers=max_workers) as executor: for index, value in enumerate(runners): result = executor.submit(runner, index, value) try: result.result(timeout=3 * 60 ) except TimeoutError as err: print(\"任务超时,\", err) 可以看到多进程和多线程写法超级类似，一个使用的是 ProcessPoolExecutor ，一个使用的是 ThreadPoolExecutor，其他代码基本一直，查看源码可以发现 concurrent.futures 定义了一个 Executor 抽象基类，提供了 submit 、map 、shutdown 等方法 class Executor(object): \"\"\"This is an abstract base class for concrete asynchronous executors.\"\"\" def submit(self, fn, *args, **kwargs): \"\"\"Submits a callable to be executed with the given arguments. Schedules the callable to be executed as fn(*args, **kwargs) and returns a Future instance representing the execution of the callable. Returns: A Future representing the given call. \"\"\" raise NotImplementedError() def map(self, fn, *iterables, **kwargs): \"\"\"Returns a iterator equivalent to map(fn, iter). Args: fn: A callable that will take as many arguments as there are passed iterables. timeout: The maximum number of seconds to wait. If None, then there is no limit on the wait time. Returns: An iterator equivalent to: map(func, *iterables) but the calls may be evaluated out-of-order. Raises: TimeoutError: If the entire result iterator could not be generated before the given timeout. Exception: If fn(*args) raises for any values. \"\"\" timeout = kwargs.get('timeout') if timeout is not None: end_time = timeout + time.time() fs = [self.submit(fn, *args) for args in itertools.izip(*iterables)] # Yield must be hidden in closure so that the futures are submitted # before the first iterator value is required. def result_iterator(): try: for future in fs: if timeout is None: yield future.result() else: yield future.result(end_time - time.time()) finally: for future in fs: future.cancel() return result_iterator() def shutdown(self, wait=True): \"\"","date":"2020-11-18","objectID":"/concurrent/:2:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/concurrent/"},{"categories":null,"content":"concurrent 使用过程中遇到的坑 执行环境为 python-2.7.15 假设有这么一个脚本 multipy.py # -*- coding: UTF-8 -*- from concurrent.futures._base import TimeoutError from concurrent.futures import ProcessPoolExecutor import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) def main(max_workers=1) : print(\"执行升级任务的并发数为为： {}\".format(max_workers)) runners = [\"python\", \"java\", \"golang\", \"php\", \"rust\", \"shell\", \"c\"] with ProcessPoolExecutor(max_workers=max_workers) as executor: for index, value in enumerate(runners): result = executor.submit(runner, index, value) try: result.result(timeout=3 * 60) except TimeoutError as err: print(\"任务超时,\", err) if __name__ == \"__main__\" : main(3) 通过在命令行执行 python multipy.py ，大家可以在心里想象一下会输出什么。 第二个场景是：同样的脚本， 通过 setuptools 安装后执行，部分代码（setup.py）如下: #!/usr/bin/env python from setuptools import setup, find_packages setup( name=\"pyctl\", entry_points=''' [console_scripts] pyctl=pyctl.commands.shell:cli ''', classifiers=[ ... ], install_requires=[ ... 'click==7.0' ], ) 安装完成之后可以在命令行通过 pyctl xxx ... 执行，和执行系统命令是一样的，如果不熟悉 setuptools 可以先了解一下，文档参考https://pypi.org/project/setuptools/ 言归正传，通过 setuptools 打包之后再执行这个脚本，我们可以假设打包之后的执行方式为 pyctl multipy ，执行后会发生什么呢？大家也可以在心里先想象一下。 实际的结果就是直接通过 python multipy.py 的方式可以得到正确的结果，确实按照多进程的方式并发执行，但是到第二个场景时却无法运行，通过 ps -ef 查看进程，确实创建了多个进程，但这些进程都被阻塞，没有执行 runner 函数里面的内容，程序会被卡死。当时百思不解其中的原因，尝试过很多方法，包括使用原生的 multiprocessing 自己实现进程管理也是同样的效果，最后是同样的代码，换到python3.8，两种方法都可以得到正确结果。python2.7 为啥会卡死，多个进程创建出来没有执行 runner 任务至今还没有找到原因，后续有进展再更新， 欢迎知道原因的小伙伴留言告知！！！ ","date":"2020-11-18","objectID":"/concurrent/:3:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/concurrent/"},{"categories":null,"content":"总结 在python2.7的环境下面，如果通过 setuptools 打包安装，安装后多进程使用会有问题，现象是会创建多个子进程出来，但是主进程和子进程都会被阻塞而无法真正执行runner任务，一个行之有效的方法是切换到python3（python3.8亲测没有问题，其他的没测过）。 ","date":"2020-11-18","objectID":"/concurrent/:4:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/concurrent/"},{"categories":null,"content":"python中的多线程与多进程（二）","date":"2020-11-18","objectID":"/python/concurrent/","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/python/concurrent/"},{"categories":null,"content":"导读 在上一篇“python中的多线程与多进程(一)中介绍了进程、线程的概念、基本用法和在 python 中使用遇到的一些坑， 这在一篇中会介绍一些高级的用法，当然更多的是遇到的坑，换言之这是一片避坑指南。 ","date":"2020-11-18","objectID":"/python/concurrent/:1:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/python/concurrent/"},{"categories":null,"content":"concurrent.futures 我们都知道在 python 中，多线程的标准库是使用 threading , 如 ： # -*- coding: UTF-8 -*- import threading import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) for index,value in enumerate([\"python\", \"java\", \"golang\", \"php\"]) : thread = threading.Thread(target=runner,args=(index, value, )) thread.start() 多进程的库是 multiprocessing ,如： # -*- coding: UTF-8 -*- from multiprocessing import Process import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) for index,value in enumerate([\"python\", \"java\", \"golang\", \"php\"]) : process = Process(target=runner,args=(index, value, )) process.start() 以上两个库已经 python2 已经支持，可以很好的实现我们多进程与多线程的需求。 python3.2 提供了 concurrent.futures 库，并且已经回溯到python2，这个库在 threading 与 multiprocessing 的基础上提供了一层封装，使得多线程和多进程在使用行为上保持了一致，为什么这么说呢，且看下面分析，请先看两段代码： 多线程 # -*- coding: UTF-8 -*- from concurrent.futures._base import TimeoutError from concurrent.futures import ThreadPoolExecutor import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) max_workers = 4 print(\"执行升级任务的并发数为为： {}\".format(max_workers)) runners = [\"python\", \"java\", \"golang\", \"php\", \"rust\", \"shell\", \"c\"] with ThreadPoolExecutor(max_workers=max_workers) as executor: for index, value in enumerate(runners): result = executor.submit(runner, index, value) try: result.result(timeout=3 * 60 ) except TimeoutError as err: print(\"任务超时,\", err) 多进程 # -*- coding: UTF-8 -*- from concurrent.futures._base import TimeoutError from concurrent.futures import ProcessPoolExecutor import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) max_workers = 4 print(\"执行升级任务的并发数为为： {}\".format(max_workers)) runners = [\"python\", \"java\", \"golang\", \"php\", \"rust\", \"shell\", \"c\"] with ProcessPoolExecutor(max_workers=max_workers) as executor: for index, value in enumerate(runners): result = executor.submit(runner, index, value) try: result.result(timeout=3 * 60 ) except TimeoutError as err: print(\"任务超时,\", err) 可以看到多进程和多线程写法超级类似，一个使用的是 ProcessPoolExecutor ，一个使用的是 ThreadPoolExecutor，其他代码基本一直，查看源码可以发现 concurrent.futures 定义了一个 Executor 抽象基类，提供了 submit 、map 、shutdown 等方法 class Executor(object): \"\"\"This is an abstract base class for concrete asynchronous executors.\"\"\" def submit(self, fn, *args, **kwargs): \"\"\"Submits a callable to be executed with the given arguments. Schedules the callable to be executed as fn(*args, **kwargs) and returns a Future instance representing the execution of the callable. Returns: A Future representing the given call. \"\"\" raise NotImplementedError() def map(self, fn, *iterables, **kwargs): \"\"\"Returns a iterator equivalent to map(fn, iter). Args: fn: A callable that will take as many arguments as there are passed iterables. timeout: The maximum number of seconds to wait. If None, then there is no limit on the wait time. Returns: An iterator equivalent to: map(func, *iterables) but the calls may be evaluated out-of-order. Raises: TimeoutError: If the entire result iterator could not be generated before the given timeout. Exception: If fn(*args) raises for any values. \"\"\" timeout = kwargs.get('timeout') if timeout is not None: end_time = timeout + time.time() fs = [self.submit(fn, *args) for args in itertools.izip(*iterables)] # Yield must be hidden in closure so that the futures are submitted # before the first iterator value is required. def result_iterator(): try: for future in fs: if timeout is None: yield future.result() else: yield future.result(end_time - time.time()) finally: for future in fs: future.cancel() return result_iterator() def shutdown(self, wait=True): \"\"","date":"2020-11-18","objectID":"/python/concurrent/:2:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/python/concurrent/"},{"categories":null,"content":"concurrent 使用过程中遇到的坑 执行环境为 python-2.7.15 假设有这么一个脚本 multipy.py # -*- coding: UTF-8 -*- from concurrent.futures._base import TimeoutError from concurrent.futures import ProcessPoolExecutor import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) def main(max_workers=1) : print(\"执行升级任务的并发数为为： {}\".format(max_workers)) runners = [\"python\", \"java\", \"golang\", \"php\", \"rust\", \"shell\", \"c\"] with ProcessPoolExecutor(max_workers=max_workers) as executor: for index, value in enumerate(runners): result = executor.submit(runner, index, value) try: result.result(timeout=3 * 60) except TimeoutError as err: print(\"任务超时,\", err) if __name__ == \"__main__\" : main(3) 通过在命令行执行 python multipy.py ，大家可以在心里想象一下会输出什么。 第二个场景是：同样的脚本， 通过 setuptools 安装后执行，部分代码（setup.py）如下: #!/usr/bin/env python from setuptools import setup, find_packages setup( name=\"pyctl\", entry_points=''' [console_scripts] pyctl=pyctl.commands.shell:cli ''', classifiers=[ ... ], install_requires=[ ... 'click==7.0' ], ) 安装完成之后可以在命令行通过 pyctl xxx ... 执行，和执行系统命令是一样的，如果不熟悉 setuptools 可以先了解一下，文档参考https://pypi.org/project/setuptools/ 言归正传，通过 setuptools 打包之后再执行这个脚本，我们可以假设打包之后的执行方式为 pyctl multipy ，执行后会发生什么呢？大家也可以在心里先想象一下。 实际的结果就是直接通过 python multipy.py 的方式可以得到正确的结果，确实按照多进程的方式并发执行，但是到第二个场景时却无法运行，通过 ps -ef 查看进程，确实创建了多个进程，但这些进程都被阻塞，没有执行 runner 函数里面的内容，程序会被卡死。当时百思不解其中的原因，尝试过很多方法，包括使用原生的 multiprocessing 自己实现进程管理也是同样的效果，最后是同样的代码，换到python3.8，两种方法都可以得到正确结果。python2.7 为啥会卡死，多个进程创建出来没有执行 runner 任务至今还没有找到原因，后续有进展再更新， 欢迎知道原因的小伙伴留言告知！！！ ","date":"2020-11-18","objectID":"/python/concurrent/:3:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/python/concurrent/"},{"categories":null,"content":"总结 在python2.7的环境下面，如果通过 setuptools 打包安装，安装后多进程使用会有问题，现象是会创建多个子进程出来，但是主进程和子进程都会被阻塞而无法真正执行runner任务，一个行之有效的方法是切换到python3（python3.8亲测没有问题，其他的没测过）。 ","date":"2020-11-18","objectID":"/python/concurrent/:4:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/python/concurrent/"},{"categories":null,"content":"python中的多线程与多进程（一）","date":"2020-11-16","objectID":"/multithread/","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/multithread/"},{"categories":null,"content":"导读 在编码的过程，多线程、多进程、并发、并行这些概念肯定不止一次的出现在我们面前。概念理解是一回事，但是能真正用好又是另一回事。不同的编程语言，并发编程难易程度相差还是很大的，正好这几天梳理了他们之间的关系与区别，分享给大家。（基于自己的理解谈谈，如果不对欢迎指出） 灵魂拷问：什么是线程？什么是进程？ ","date":"2020-11-16","objectID":"/multithread/:1:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/multithread/"},{"categories":null,"content":"进程 进程是资源分配的最小单位。 ","date":"2020-11-16","objectID":"/multithread/:2:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/multithread/"},{"categories":null,"content":"线程 线程是 cpu 调度的最小调度。线程又分为内核线程，用户线程。 内核线程只运行在内核态，不受用户态的拖累。 用户线程是完全建立在用户空间的线程库，用户线程的创建、调度、同步和销毁在用户空间完成，不需要内核的帮助。用户线程又称为协程。 一个线程只能属于一个进程，但是一个进程可以有多个线程，多线程处理就是一个进程可以有多个线程在同一个时刻执行多个任务。 这些是比较官方的定义，简单理解就是运行一段程序，需要一定的资源，如cpu，系统内核会分配给进程，至于怎么分配这些资源可由线程去抢，如果某个线程占用资源(cpu)时间太长，内核为了平衡，会强行中断，切换给其他的线程执行，但是每次切换都是有代价的，需要把执行现场保留以确保后续恢复的时候可以正常执行，这就有了内核和用户态的切换（进程和线程都是受内核控制的）。那么问题来了，如果只在用户态切换，岂不是很好？还真是这样，go 语言就是这样实现。 ","date":"2020-11-16","objectID":"/multithread/:3:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/multithread/"},{"categories":null,"content":"python 多线程时遇到的坑 python 中如果要用多线程或者多进程时需要自己创建线程或者进程，这和go语言不一样，go语言只需要通过 go 关键字创建出协程，然后由runtime 进行调度（不需要自己处理进程与线程）。今天先看看python 中如何使用多线程与多进程。python 环境为 2.7.15 。 先看一段简单的代码 import threading import time ​ lock = threading.Lock() ​ def runner(i, p1, p2, p3=\"\", p4=\"\", **kwargs): \"\"\" :return: \"\"\" count = 0 print(\"线程{} param1:====\".format(i), p1) print(\"线程{} param2:====\".format(i), p2) print(\"线程{} param3:====\".format(i), p3) print(\"线程{} param3:====\".format(i), p4) while True: with lock: count += 1 print(\"线程{} 第 {} 秒 后: ......\".format(i, count)) time.sleep(1) if count == 5: break def main_thread(): \"\"\" 主线程的运行代码 :return: \"\"\" print(\"主线程开始执行\") time.sleep(1) print(\"主线程执行结束\") ​ def main(): \"\"\" :return: \"\"\" for i in range(5): thread = threading.Thread(target=runner, args=(i, \"a1\", \"a2\"), kwargs={\"p3\": \"p2\", \"p4\": \"p4\"}) thread.setName(\"线程{}\".format(i)) thread.start() ​ main_thread() ​ if __name__ == \"__main__\": main() ​ 这个应该能想的出来不同的线程的输出是交叉打印出来的，说明这是多个线程并发执行的。 现在假设有这么一个场景，有10台机器，每个机器上有10个容器需要重启，如果要并发的执行应该怎么做呢? 看看下面的代码有没有问题? import os ​ import threading ​ def runnner(hostip) : appIds = [ \"app-{}\".format(i) for i in range(10)] cmd = \"docker restart {}\".format(\" \".join(appIds)) print(cmd) os.system(\"ssh {hostip} {cmd}\".format(hostip=hostip,cmd=cmd)) ​ hosts = [\"10.0.0.1\", \"10.0.0.2\", \"10.0.0.3\" , \"10.0.0.4\", \"10.0.0.5\",\"10.0.0.6\", \"10.0.0.7\", \"10.0.0.8\" , \"10.0.0.9\", \"10.0.0.10\"] ​ for hostip in hosts : thread = threading.Thread(target=runnner, args=(hostip,)) thread.start() 看起来应该是没有问题的，然而真正执行的还是串行，没有到达并发执行的目的。问题出在哪里呢？ 在python 中线程执行需要先获取GIL锁（全局解释器锁），看起来是创建了多个线程，但是同一个时间点每个进程只能有一个线程获取这个锁并且执行，是一种伪多线程，如果在密集计算的场景，就会频繁的发生线程切换，这个是很耗时间的，还没有单线程效果好。那么问题又来了，什么会发生线程切换呢? 如果遇到io等待或者sleep 时肯定会发生切换，还有就是每100条指令切换一次线程。可以通过如下指令设置: sys.setcheckinterval 上面这里例子就没有触发线程的切换，当前面的线程执行完退出之后释放GIL锁，后续的线程才能执行，所以才有看起来是多线程的写法，但是确实单线程的效果。 改进的方法当然使用多进程，每个进程都有自己的GIL锁，可以真正的实现并发。进程并不是越多越好，创建进程开销比线程要大很多，如果进程之间有数据交换也比线程复杂，并且真正执行还是要落到cpu上去执行，进程多了也会造成排队，理论上和创建和cpu相同个数的进程性能最好。下面看看多进程的写法。 import os from multiprocessing import Process ​ def runnner(hostip) : appIds = [ \"app-{}\".format(i) for i in range(10)] cmd = \"docker restart {}\".format(\" \".join(appIds)) print(cmd) os.system(\"ssh {hostip} {cmd}\".format(hostip=hostip,cmd=cmd)) ​ ​ hosts = [\"10.0.0.{}\".format(i) for i in range(10)] ​ ​ for hostip in hosts : process = Process(target=runnner, args=(hostip,)) process.start() 当然可以用进程池控制进程的个数，如: import os ​ from multiprocessing import Pool ​ def runnner(hostip) : appIds = [ \"app-{}\".format(i) for i in range(10)] cmd = \"docker restart {}\".format(\" \".join(appIds)) print(cmd) os.system(\"ssh {hostip} {cmd}\".format(hostip=hostip,cmd=cmd)) ​ ​ hosts = [\"10.0.0.{}\".format(i) for i in range(10)] ​ p = Pool(4) ​ for hostip in hosts : p.apply_async(runnner, args=(hostip,)) # 异步执行 p.close() p.join() ","date":"2020-11-16","objectID":"/multithread/:4:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/multithread/"},{"categories":null,"content":"参考 https://docs.python.org/2/library/sys.html#sys.setcheckinterval ","date":"2020-11-16","objectID":"/multithread/:5:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/multithread/"},{"categories":null,"content":"python中的多线程与多进程（一）","date":"2020-11-16","objectID":"/python/multithread/","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/python/multithread/"},{"categories":null,"content":"导读 在编码的过程，多线程、多进程、并发、并行这些概念肯定不止一次的出现在我们面前。概念理解是一回事，但是能真正用好又是另一回事。不同的编程语言，并发编程难易程度相差还是很大的，正好这几天梳理了他们之间的关系与区别，分享给大家。（基于自己的理解谈谈，如果不对欢迎指出） 灵魂拷问：什么是线程？什么是进程？ ","date":"2020-11-16","objectID":"/python/multithread/:1:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/python/multithread/"},{"categories":null,"content":"进程 进程是资源分配的最小单位。 ","date":"2020-11-16","objectID":"/python/multithread/:2:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/python/multithread/"},{"categories":null,"content":"线程 线程是 cpu 调度的最小调度。线程又分为内核线程，用户线程。 内核线程只运行在内核态，不受用户态的拖累。 用户线程是完全建立在用户空间的线程库，用户线程的创建、调度、同步和销毁在用户空间完成，不需要内核的帮助。用户线程又称为协程。 一个线程只能属于一个进程，但是一个进程可以有多个线程，多线程处理就是一个进程可以有多个线程在同一个时刻执行多个任务。 这些是比较官方的定义，简单理解就是运行一段程序，需要一定的资源，如cpu，系统内核会分配给进程，至于怎么分配这些资源可由线程去抢，如果某个线程占用资源(cpu)时间太长，内核为了平衡，会强行中断，切换给其他的线程执行，但是每次切换都是有代价的，需要把执行现场保留以确保后续恢复的时候可以正常执行，这就有了内核和用户态的切换（进程和线程都是受内核控制的）。那么问题来了，如果只在用户态切换，岂不是很好？还真是这样，go 语言就是这样实现。 ","date":"2020-11-16","objectID":"/python/multithread/:3:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/python/multithread/"},{"categories":null,"content":"python 多线程时遇到的坑 python 中如果要用多线程或者多进程时需要自己创建线程或者进程，这和go语言不一样，go语言只需要通过 go 关键字创建出协程，然后由runtime 进行调度（不需要自己处理进程与线程）。今天先看看python 中如何使用多线程与多进程。python 环境为 2.7.15 。 先看一段简单的代码 import threading import time ​ lock = threading.Lock() ​ def runner(i, p1, p2, p3=\"\", p4=\"\", **kwargs): \"\"\" :return: \"\"\" count = 0 print(\"线程{} param1:====\".format(i), p1) print(\"线程{} param2:====\".format(i), p2) print(\"线程{} param3:====\".format(i), p3) print(\"线程{} param3:====\".format(i), p4) while True: with lock: count += 1 print(\"线程{} 第 {} 秒 后: ......\".format(i, count)) time.sleep(1) if count == 5: break def main_thread(): \"\"\" 主线程的运行代码 :return: \"\"\" print(\"主线程开始执行\") time.sleep(1) print(\"主线程执行结束\") ​ def main(): \"\"\" :return: \"\"\" for i in range(5): thread = threading.Thread(target=runner, args=(i, \"a1\", \"a2\"), kwargs={\"p3\": \"p2\", \"p4\": \"p4\"}) thread.setName(\"线程{}\".format(i)) thread.start() ​ main_thread() ​ if __name__ == \"__main__\": main() ​ 这个应该能想的出来不同的线程的输出是交叉打印出来的，说明这是多个线程并发执行的。 现在假设有这么一个场景，有10台机器，每个机器上有10个容器需要重启，如果要并发的执行应该怎么做呢? 看看下面的代码有没有问题? import os ​ import threading ​ def runnner(hostip) : appIds = [ \"app-{}\".format(i) for i in range(10)] cmd = \"docker restart {}\".format(\" \".join(appIds)) print(cmd) os.system(\"ssh {hostip} {cmd}\".format(hostip=hostip,cmd=cmd)) ​ hosts = [\"10.0.0.1\", \"10.0.0.2\", \"10.0.0.3\" , \"10.0.0.4\", \"10.0.0.5\",\"10.0.0.6\", \"10.0.0.7\", \"10.0.0.8\" , \"10.0.0.9\", \"10.0.0.10\"] ​ for hostip in hosts : thread = threading.Thread(target=runnner, args=(hostip,)) thread.start() 看起来应该是没有问题的，然而真正执行的还是串行，没有到达并发执行的目的。问题出在哪里呢？ 在python 中线程执行需要先获取GIL锁（全局解释器锁），看起来是创建了多个线程，但是同一个时间点每个进程只能有一个线程获取这个锁并且执行，是一种伪多线程，如果在密集计算的场景，就会频繁的发生线程切换，这个是很耗时间的，还没有单线程效果好。那么问题又来了，什么会发生线程切换呢? 如果遇到io等待或者sleep 时肯定会发生切换，还有就是每100条指令切换一次线程。可以通过如下指令设置: sys.setcheckinterval 上面这里例子就没有触发线程的切换，当前面的线程执行完退出之后释放GIL锁，后续的线程才能执行，所以才有看起来是多线程的写法，但是确实单线程的效果。 改进的方法当然使用多进程，每个进程都有自己的GIL锁，可以真正的实现并发。进程并不是越多越好，创建进程开销比线程要大很多，如果进程之间有数据交换也比线程复杂，并且真正执行还是要落到cpu上去执行，进程多了也会造成排队，理论上和创建和cpu相同个数的进程性能最好。下面看看多进程的写法。 import os from multiprocessing import Process ​ def runnner(hostip) : appIds = [ \"app-{}\".format(i) for i in range(10)] cmd = \"docker restart {}\".format(\" \".join(appIds)) print(cmd) os.system(\"ssh {hostip} {cmd}\".format(hostip=hostip,cmd=cmd)) ​ ​ hosts = [\"10.0.0.{}\".format(i) for i in range(10)] ​ ​ for hostip in hosts : process = Process(target=runnner, args=(hostip,)) process.start() 当然可以用进程池控制进程的个数，如: import os ​ from multiprocessing import Pool ​ def runnner(hostip) : appIds = [ \"app-{}\".format(i) for i in range(10)] cmd = \"docker restart {}\".format(\" \".join(appIds)) print(cmd) os.system(\"ssh {hostip} {cmd}\".format(hostip=hostip,cmd=cmd)) ​ ​ hosts = [\"10.0.0.{}\".format(i) for i in range(10)] ​ p = Pool(4) ​ for hostip in hosts : p.apply_async(runnner, args=(hostip,)) # 异步执行 p.close() p.join() ","date":"2020-11-16","objectID":"/python/multithread/:4:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/python/multithread/"},{"categories":null,"content":"参考 https://docs.python.org/2/library/sys.html#sys.setcheckinterval https://mp.weixin.qq.com/s/nrT8iIe73POFTBpCdfXupA ","date":"2020-11-16","objectID":"/python/multithread/:5:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/python/multithread/"},{"categories":null,"content":"投稿到 servicemesh 社区的文章","date":"2020-11-10","objectID":"/elk/","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"ELK 这篇文档是由我投稿的云原生社区的文章，节选自 istio-handbook，如果有兴趣可以参考这本书。 ELK 指的是由 Elasticsearch + Logstash + Kibana 组成的日志采集、存储、展示为一体的日志解决方案，简称 “ELK Stack”。ELK Stack 还包含 Beats（如Filebeat、Metricbeat、Heartbeat等）、Kafka等成员，是目前主流的一种日志解决方案。 Elasticsearch 是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。 Logstash 是免费且开放的服务器端数据处理管道，能够从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的“存储库”中。Logstash 比较耗资源，在实践中我们一般用作实时解析和转换数据。Logstash 采用可插拔框架，拥有 200 多个插件。您可以将不同的输入选择、过滤器和输出选择混合搭配、精心安排，让它们在管道中和谐地运行。 Kibana 是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。 Kafka 是由 Apache 软件基金会开发的一个开源流处理平台，由 Scala 和 Java 编写。用来做缓冲，当日志量比较大的时候可以缓解后端 Elasticsearch 的压力。 Beats 是数据采集的得力工具。Beats家族成员包括如下： Filebeat：用于日志文件采集，内置了多种模块（Apache、Cisco ASA、Microsoft Azure、NGINX、MySQL 等等）。 Metricbeat： 用于指标采集。 Packetbeat：用于网络数据采集。 Winlogbeat：用于Windows 事件采集。 Auditbeat：用于审计日志采集。 Heartbeat：用于运行时间采集。 其中 Filebeat 被经常用来收集 Node 或者 Pod 中的日志。 Beats 用于收集客户端的日志，发送给缓存队列如Kafka，目的是为了解耦数据收集与解析入库的过程，同时提高了可扩展性，使日志系统有峰值处理能力，不会因为突发的访问压力造成日志系统奔溃。缓存队列可选的还有 Redis，由于 Redis 是内存型，很容易写满，生产环境建议用 kafka。Logstash 从 缓存队列中消费日志解析处理之后写到 Elasticsearch，通过 Kibana 展示给最终用户。 ","date":"2020-11-10","objectID":"/elk/:0:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"采集方案 Filebeat 有两种部署模式，一是通过 DaemonSet 方式部署，二是通过 Sidecar 方式部署，Filebeat 采集后发送到 Kafka ，再由 Logstash 从 Kafka 中消费写到 Elasticsearch。 ","date":"2020-11-10","objectID":"/elk/:1:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"DaemonSet 方式部署 开启 Envoy 的访问日志输出到 stdout ，以 DaemonSet 的方式在每一台集群节点部署 Filebeat ，并将日志目录挂载至 Filebeat Pod，实现对 Envoy 访问日志的采集。 ","date":"2020-11-10","objectID":"/elk/:1:1","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"Sidecar 方式部署 Filebeat 和 Envoy 部署在同一个 Pod 内，共享日志数据卷， Envoy 写，Filebeat 读，实现对 Envoy 访问日志的采集。 ","date":"2020-11-10","objectID":"/elk/:1:2","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"部署 ELK 有了以上的基础，我们开始部署 ELK Stack ","date":"2020-11-10","objectID":"/elk/:2:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"部署 Kafka 首先，创建一个新的 namespace 用于部署 ELK Stack： # Logging Namespace. All below are a part of this namespace. apiVersion: v1 kind: Namespace metadata: name: logging 接下来，部署 Kafka 服务。 Kafka 通过 Zookeeper 管理集群配置，所以在部署 Kafka 需要先部署 Zookeeper。 Zookeeper 是一个分布式的，开放源码的分布式应用程序协调服务。 Kafka 与 Zookeeper 都是有状态服务，部署时需要选择 StatefulSet 。 部署 Zookeeper Service apiVersion:v1kind:Servicemetadata:name:zookeeper-clusternamespace:loggingspec:selector:app:zookeeper-clusterports:- name:httpport:2181targetPort:2181type:ClusterIP Zookeeper 在集群内使用，供 Kafka 使用，创建类型为 ClusterIP 的 Service 。 Zookeeper 的默认端口是2181。 部署 Zookeeper ConfigMap apiVersion:v1kind:ConfigMapmetadata:name:zookeeper-confignamespace:loggingdata:ZOO_CONF_DIR:/confZOO_PORT:\"2181\" Zookeeper 配置文件中的 key 都可以 以 ZOO_ 加大写的方式设置到环境变量中，使之生效。 这里仅列举部分配置。 部署 Zookeeper StatefulSet apiVersion:apps/v1kind:StatefulSetmetadata:name:zookeepernamespace:loggingspec:serviceName:zookeeper-clusterreplicas:1updateStrategy:type:RollingUpdateselector:matchLabels:app:zookeeper-clustertemplate:metadata:labels:app:zookeeper-clusterannotations:sidecar.istio.io/inject:\"false\"spec:containers:- name:zookeeperresources:requests:cpu:10mmemory:100Milimits:memory:200Miimage:zookeeperimagePullPolicy:IfNotPresentenvFrom:- configMapRef:name:zookeeper-configreadinessProbe:tcpSocket:port:2181initialDelaySeconds:5periodSeconds:10livenessProbe:tcpSocket:port:2181initialDelaySeconds:15periodSeconds:20ports:- containerPort:2181name:zk-client sidecar.istio.io/inject=false 标识此服务无需 sidecar 注入。 部署 Kafka Service apiVersion:v1kind:Servicemetadata:name:bootstrap-kafkanamespace:loggingspec:clusterIP:Noneports:- port:9092selector:app:kafka---apiVersion:v1kind:Servicemetadata:name:kafka-clusternamespace:loggingspec:ports:- name:httptargetPort:9092port:9092selector:app:kafkatype:ClusterIP 部署两个 Service 。 bootstrap-kafka 为后续部署 Kafka Statefulset 使用。 kafka-cluster 为 Kafka 的访问入口，在生产中使用可以用其他的 Service 类型。 kafka 的默认端口是9092 部署 Kafka ConfigMap apiVersion:v1kind:ConfigMapmetadata:name:kafka-confignamespace:loggingdata:KAFKA_ADVERTISED_LISTENERS:\"PLAINTEXT://kafka-cluster:9092\"KAFKA_LISTENERS:\"PLAINTEXT://0.0.0.0:9092\"KAFKA_ZOOKEEPER_CONNECT:\"zookeeper-cluster:2181\"KAFKA_LOG_RETENTION_HOURS:\"48\"KAFKA_NUM_PARTITIONS:\"30\" Kafka 配置文件（server.properties）中的 key 都可以 以 KAFKA_ 加大写的方式设置到环境变量中，使之生效。 KAFKA_ADVERTISED_LISTENERS 为 Kafka 监听的服务地址。 KAFKA_ZOOKEEPER_CONNECT 为前面部署的 Zookeeper 的服务地址。 KAFKA_LOG_RETENTION_HOURS 为 Kafka 数据保留的时间，超过这个时间将会被清理，可以根据实际情况进行调整。 KAFKA_NUM_PARTITIONS 为创建 Kafka topic 时的默认分片数，设置大一些可以增加 Kafka 的吞吐量。 这里仅列举部分配置。 部署 Kafka StatefulSet apiVersion:apps/v1kind:StatefulSetmetadata:name:kafkanamespace:loggingspec:selector:matchLabels:app:kafkaserviceName:bootstrap-kafkareplicas:1template:metadata:labels:app:kafkaannotations:sidecar.istio.io/inject:\"false\"spec:containers:- name:kafka-brokerimage:russellgao/kafka:2.12-2.0.1ports:- name:insidecontainerPort:9092resources:requests:cpu:0.1memory:1024Milimits:memory:3069MireadinessProbe:tcpSocket:port:9092timeoutSeconds:1initialDelaySeconds:5periodSeconds:10livenessProbe:tcpSocket:port:9092timeoutSeconds:1initialDelaySeconds:15periodSeconds:20envFrom:- configMapRef:name:kafka-config kafka 对磁盘的 IO 要求较高，可以选择固态硬盘或者经过IO优化的磁盘，否则可能会成为日志系统的瓶颈。 请注意，本次实践没有把数据卷映射出来，在生产实践中使用 volumeClaimTemplates 来为 Pod 提供持久化存储。resources 可以根据实际情况调整。 ","date":"2020-11-10","objectID":"/elk/:2:1","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"部署 Logstash Logstash 是一个无状态服务，通过 Deployment 进行部署。 部署 Logstash ConfigMap apiVersion:v1kind:ConfigMapmetadata:name:logstash-confnamespace:loggingdata:logstash.conf:| input {http{host=\u003e\"0.0.0.0\"# default: 0.0.0.0port =\u003e 8080 # default:8080user=\u003e\"logstash\"password=\u003e\"aoDJ0JVgkfNPjarn\"response_headers=\u003e{\"Content-Type\"=\u003e\"text/plain\"\"Access-Control-Allow-Origin\"=\u003e\"*\"\"Access-Control-Allow-Methods\"=\u003e\"GET, POST, DELETE, PUT\"\"Access-Control-Allow-Headers\"=\u003e\"authorization, content-type\"\"Access-Control-Allow-Credentials\"=\u003etrue}}kafka{topics=\u003e\"istio\"bootstrap_servers=\u003e\"kafka-cluster:9092\"auto_offset_reset=\u003e\"earliest\"group_id=\u003e\"istio_kafka_gr\"consumer_threads=\u003e3codec=\u003e\"json\"}}filter{grok{match=\u003e{\"message\"=\u003e\"(?m)\\[%{TIMESTAMP_ISO8601:timestamp}\\] \"%{NOTSPACE:method}%{NOTSPACE:path}%{NOTSPACE:protocol}\" %{NUMBER:response_code:int} %{NOTSPACE:response_flags} \"%{NOTSPACE:istio_policy_status}\" \"%{NOTSPACE:upstream_transport_failure_reason}\" %{NUMBER:bytes_received:int} %{NUMBER:bytes_sent:int} %{NUMBER:duration:int} %{NUMBER:upstream_service_time:int} \"%{NOTSPACE:x_forwarded_for}\" \"%{NOTSPACE:user_agent}\" \"%{NOTSPACE:request_id}\" \"%{NOTSPACE:authority}\" \"%{NOTSPACE:upstream_host}\" %{NOTSPACE:upstream_cluster} %{NOTSPACE:upstream_local_address} %{NOTSPACE:downstream_local_address} %{NOTSPACE:downstream_remote_address} %{NOTSPACE:requested_server_name} %{NOTSPACE:route_name}\"}remove_field=\u003e[\"message\"]}date{match=\u003e[\"timestamp\",\"yyyy-MM-ddTHH:mm:ss.SSSZ\"]timezone=\u003e\"Asia/Shanghai\"}ruby{code=\u003e\"event.set('[@metadata][index_day]',(event.get('@timestamp').time.localtime + 8*60*60 ).strftime('%Y.%m.%d'))\"}}output{if\"_grokparsefailure\"notin[tags]{elasticsearch{user=\u003e\"elastic\"password=\u003e\"elastic\"hosts=\u003e[\"elasticsearch.com:9200\"]index=\u003e\"istio-%{[@metadata][index_day]}\"}}} Logstash 配置由3部分组成： input Logstash input 支持非常多的数据源，如 File、Elasticsearch、Beats、Redis、Kafka、Http等。 Http input 用于Logstash 的健康检查，也可通过 http 接口将日志直接发送到 Logstash，主要用于移动端的场景。 Kafka input 用于收集日志，一个input只能从一个 Topic 中读取数据，需要和后续的 Filebeat output 对应。 filter Logstash filter 支持非常多的插件，可以对数据进行解析、加工、转换，如 grok、date、ruby、json、drop等。 grok 用于对日志进行解析。 date 用于把 timestamp 转化成 elasticsearch 中的 @timestamp 字段，可以指定时区。 ruby 插件支持执行 ruby 代码，可以进行复杂逻辑的处理，此处的用法是 @timestamp 字段的时间加8小时，解决自动生成的索引时差问题。 output Logstash output 支持非常多的数据源，如 elasticsearch、cvs、jdbc 等。 此处是把 grok 解析成功的日志写到 elasticsearch 。 部署 Logstash Deployment apiVersion:apps/v1beta2kind:Deploymentmetadata:name:logstashnamespace:loggingspec:replicas:2selector:matchLabels:app:logstashtemplate:metadata:labels:app:logstashannotations:sidecar.istio.io/inject:\"false\"spec:volumes:- name:configconfigMap:name:logstash-confhostname:logstashcontainers:- name:logstashimage:logstash:7.2.0args:[\"-f\",\"/usr/share/logstash/pipeline/logstash.conf\",]imagePullPolicy:IfNotPresentvolumeMounts:- name:configmountPath:\"/usr/share/logstash/pipeline/logstash.conf\"readOnly:truesubPath:logstash.confresources:requests:cpu:0.5memory:1024Milimits:cpu:1.5memory:3072MireadinessProbe:tcpSocket:port:8080initialDelaySeconds:5periodSeconds:10livenessProbe:tcpSocket:port:8080initialDelaySeconds:15periodSeconds:20 Logstash 不需要对外发布服务，即不需要创建 Service，从 Kafka 中消费日志，处理完成之后写到 Elasticsearch 。 Logstash 只需要把配置文件挂载进去，无需挂载其他目录，排查错误时可通过 Logstash Console Log 进行查看。 部署 Logstash HorizontalPodAutoscaler apiVersion:autoscaling/v2beta1kind:HorizontalPodAutoscalermetadata:name:logstashnamespace:loggingspec:scaleTargetRef:apiVersion:apps/v1beta2kind:Deploymentname:logstashminReplicas:2maxReplicas:10metrics:- type:Resourceresource:name:cputargetAverageUtilization:80 Logstash 比较消费 CPU ，可以部署 HPA，可以根据日志量动态的扩所容。 Logstash 的压力对 CPU 比较敏感，可以只根据 CPU 这一个指标进行 HPA。 Logstash 的配置文件支持if/else条件判断，通过这种方式，一个 Logstash 集群可以支持比较多的日志格式。另外 Logstash 的 grok 语法相对复杂，可以使用 Kibana Dev Tools 工具进行调试，如下图： ","date":"2020-11-10","objectID":"/elk/:2:2","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"部署 Filebeat 这里仅给出 Filebeat DaemonSet 的部署过程。 部署 Filebeat ConfigMap apiVersion:v1kind:ConfigMapmetadata:name:filebeat-confnamespace:loggingdata:filebeat.yml:| filebeat:inputs:- paths:- /var/log- /var/lib/docker/containersignore_older:1hforce_close_files:true#强制filebeat在文件名改变时，关闭文件，会有丢失日志的风险close_older:1mfields_under_root:trueoutput:kafka:enabled:truehosts:[\"kafka-cluster:9092\"]topic:\"istio\"version:\"2.0.0\"partition.round_robin:reachable_only:falseworker:2max_retries:3bulk_max_size:2048timeout:30sbroker_timeout:10schannel_buffer_size:256keep_alive:60compression:gzipmax_message_bytes:1000000required_acks:1 input.paths 代表 Filebeat 监听的日志路径。 input.ignore_older 代表日志文件的修改时间超过这个之间，将会忽略，这个在 Filebeat 重启时很有效果，解决重复读取日志的问题。 out.kafka.hosts 和之前部署的 Kafka Service 对应。 out.kafka.topic 和之前部署的 Logstash ConfigMap 中的 input 对应。 部署 Filebeat DaemonSet apiVersion:apps/v1kind:DaemonSetmetadata:name:filebeatnamespace:logginglabels:app:filebeatspec:selector:matchLabels:app:filebeattemplate:metadata:labels:app:filebeatannotations:sidecar.istio.io/inject:\"false\"spec:containers:- name:filebeatimage:elastic/filebeat:7.2.0imagePullPolicy:IfNotPresentvolumeMounts:- name:configmountPath:\"/usr/share/filebeat/filebeat.yml\"readOnly:truesubPath:filebeat.yml- name:varlogmountPath:/var/log- name:varlibdockercontainersmountPath:/var/lib/docker/containersresources:requests:cpu:0.1memory:200Milimits:cpu:0.3memory:600Mivolumes:- name:varloghostPath:path:/var/log- name:varlibdockercontainershostPath:path:/var/lib/docker/containers- name:configconfigMap:name:filebeat-conf 这里声明了两个 hostPath 类型的数据卷，路径为日志存储的路径。 将宿主机的 /var/log 和 /var/lib/docker/containers 挂载到了 Filebeat Pod 内便于 Filebeat 收集日志。 Filebeat 不需要部署 Service 。 Filebeat 对资源消耗比较少，可忽略对 Node 的资源消耗。 ","date":"2020-11-10","objectID":"/elk/:2:3","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"小结 本节为大家介绍了 ELK 的原理和安装部署，以及如何收集日志。 ","date":"2020-11-10","objectID":"/elk/:3:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"参考 Beats Logstash Zookeeper ","date":"2020-11-10","objectID":"/elk/:4:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"Hugo, the world's fastest framework for building websites","date":"2020-11-08","objectID":"/about/","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"简介 高维宗（russellgao），现就职于上海海鼎信息工程股份有限公司，担任运维开发经理。 ","date":"2020-11-08","objectID":"/about/:1:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"关注领域 专注于devops，aiops，golong，python，kubernetes，servicemesh，云原生，算法等领域，热衷于参与开源软件和开源社区。 ","date":"2020-11-08","objectID":"/about/:2:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"个人公众号 ","date":"2020-11-08","objectID":"/about/:3:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"投稿 如果有好的文章需要分享也可以投稿给作者哟！ ","date":"2020-11-08","objectID":"/about/:4:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"投稿指南 文章须为原创的技术文章 须包含作者的姓名，公司头衔和简要介绍 须通过在 github 提交 PR 的方式提供 ","date":"2020-11-08","objectID":"/about/:4:1","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"原创申明 本博客上的所有文档均为原创，在写入过程中不免参考其他人优秀的文章，一般都会在文末申明参考的文章，如有侵犯到您的权益请联系作者第一时间修改。 ","date":"2020-11-08","objectID":"/about/:5:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"转载说明 如需转载，请加注原文出处。 ","date":"2020-11-08","objectID":"/about/:6:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"Hugo, the world's fastest framework for building websites","date":"2020-11-08","objectID":"/golang/defer/","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"背景 在学习和使用 Go 的过程中发现，Go 在语言层面的设计有很多有趣的地方，所以准备用一个系列来细数这些有趣的地方。写这个系列一是为了加深自己的理解，二是愿意分享，分享 Go 中有趣的设计细节。每篇都会通过一个例子讲述一个细节，感兴趣的话可以关注一下哟！ ","date":"2020-11-08","objectID":"/golang/defer/:1:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"Go 介绍 Go（又称 Golang）是 Google 的 Robert Griesemer，Rob Pike 及 Ken Thompson 开发的一种静态强类型、编译型语言。Go 语言语法与 C 相近，但功能上有：内存安全，GC（垃圾回收），结构形态及 CSP-style 并发计算。 Go 是由这3位大佬从2007年9月开始设计Go，2009年正式推出，到目前为止已经发了15个大版本，最新版为1.15.4。Go 现在广泛应用于云原生、中间件、还有各个业务平台，如 docker、kubernetes、etcd等都是Go语言编写。所以还是很有必要了解一下哟！ 下面简单说说Go的优缺点，俗话说：一万个人眼中有一万个哈姆雷特，所以优缺点都是相对而言，就谈谈自己使用过程中的感受，具体的优缺点会在后面的系列文章中一一提到，这里是抛砖引玉。 ","date":"2020-11-08","objectID":"/golang/defer/:2:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"Go 优点 语言层面支持并发：一个 go 关键字即可实现并发，其他编程语言依赖于库实现并发，这是有本质的区别 高性能 编译完之后生成二进制文件，可免去环境依赖 defer 机制 内置runtime 内嵌C支持，Go里面也可以直接包含C代码，利用现有的丰富的C库 跨平台编译 。。。 ","date":"2020-11-08","objectID":"/golang/defer/:3:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"Go 缺点 包管理 。。。 ","date":"2020-11-08","objectID":"/golang/defer/:4:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"defer 说起 Go 语言的最强大的地方，不得不说 Go 的并发机制和调度原理，但是今天不讲这些高深的理论，先从简单的开始。先思考这么几个问题（可以用自己熟悉的语言思考如何解决）: 对于文件的打开关闭，网络连接的建立断开场景，当打开时候应该何时关闭? 当调用一个函数，希望在函数返回时修改它的值，该如何解决? 先看看defer 的官方定义 ： A “defer” statement invokes a function whose execution is deferred to the moment the surrounding function returns, either because the surrounding function executed a return statement, reached the end of its function body, or because the corresponding goroutine is panicking. 意思是说，当包裹defer 的函数返回时或者包裹defer的函数执行到末尾时或者所在的goroutine发生panic时才会执行。 换句话说就是当函数执行完之后或者发生异常时再执行defer语句，就是说在被调函数返回之后，赋值给调用函数之前，还有机会执行其他指令，是不是很神奇。先看一段python 代码 : def f(x,y) : z = x / y z += 1 return z ​ if __name__ == \"__main__\" : result = f(4 /2) 当调用函数f，f返回给z并且赋值给result，在这时间，是没有任何机会执行其他的函数代码的。再看一段go代码: package main func main() { result := f(4, 2) fmt.Println(result) } ​ func f(x, y int) (r int) { r = x / y r += 1 defer func() { r += 2 }() return } 当调用函数f，f返回之后，在赋值之前执行了r +=2 。现在回想一下之前的两个问题，如果有defer 机制，是不是可以很好的解决。如对于第一个问题，在defer 语句中处理文件的关闭，连接的释放等，而不用考虑一些异常情况。 那defer的实现原理是怎样的呢? defer 其实是调用runtime.deferproc 进行实现，在defer 出现的地方，插入了call runtime.deferproc，然后在函数返回之前的地方，插入指令call runtime.deferreturn。 普通函数返回时，汇编代码类似于: add xx SP return 如果包含了defer 语句，汇编代码类似于: call runtime.deferreturn， add xx SP return goroutine的控制结构中，有一张表记录defer，调用runtime.deferproc时会将需要defer的表达式记录在表中，而在调用runtime.deferreturn的时候，则会依次从defer表中出栈并执行。 defer 在使用过程中也存在一些坑，看几个例子: 例1: func f() (result int) { defer func() { result++ }() return 10 } 例2: func f() (result int) { t := 10 defer func() { t = t + 1 }() return t } 例3: func f() (result int) { defer func(result int) { result = result + 1 }(result) return 10 } 大家可以先心里默默算一下他们的结果 第一个是11，第二个是10，第三个是10。 defer表达式可能会在设置函数返回值之后，在返回到调用函数之前，修改返回值，使最终的函数返回值与你想象的不一致。其实使用defer时，用一个简单的转换规则改写一下，就不会迷糊了。改写规则是将return语句拆成两句写，return xxx会被改写成: 返回值 = xxx 调用defer函数 空的return 例1 会被改写成: func f() (result int) { result = 10 // return语句不是一条原子调用，return xxx其实是赋值＋ret指令 defer func() { result++ }() return // 空的return指令 } 所以返回值是11 例2 会被改写成: func f() (result int) { t := 10 result = t // 赋值指令 defer func() { t = t + 1 //defer被插入到赋值与返回之间执行，这个例子中返回值 result没被修改过 }() return // 空的return指令 } 所以返回值是10 例3 就留给大家自己改写一下啦，有兴趣可以私我沟通哟！ ","date":"2020-11-08","objectID":"/golang/defer/:5:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"总结 这篇主要做了对Go语言的介绍和优缺点，分析了defer 的用法以及实现原理，最后用例子展示了使用过程中可能会存在的坑。下篇预告: Go 的调度模型，欢迎关注!!! 如果有理解不正确的地方，欢迎指出。 ","date":"2020-11-08","objectID":"/golang/defer/:6:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"Hugo, the world's fastest framework for building websites","date":"2020-11-08","objectID":"/defer/","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"背景 在学习和使用 Go 的过程中发现，Go 在语言层面的设计有很多有趣的地方，所以准备用一个系列来细数这些有趣的地方。写这个系列一是为了加深自己的理解，二是愿意分享，分享 Go 中有趣的设计细节。每篇都会通过一个例子讲述一个细节，感兴趣的话可以关注一下哟！ ","date":"2020-11-08","objectID":"/defer/:1:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"Go 介绍 Go（又称 Golang）是 Google 的 Robert Griesemer，Rob Pike 及 Ken Thompson 开发的一种静态强类型、编译型语言。Go 语言语法与 C 相近，但功能上有：内存安全，GC（垃圾回收），结构形态及 CSP-style 并发计算。 Go 是由这3位大佬从2007年9月开始设计Go，2009年正式推出，到目前为止已经发了15个大版本，最新版为1.15.4。Go 现在广泛应用于云原生、中间件、还有各个业务平台，如 docker、kubernetes、etcd等都是Go语言编写。所以还是很有必要了解一下哟！ 下面简单说说Go的优缺点，俗话说：一万个人眼中有一万个哈姆雷特，所以优缺点都是相对而言，就谈谈自己使用过程中的感受，具体的优缺点会在后面的系列文章中一一提到，这里是抛砖引玉。 ","date":"2020-11-08","objectID":"/defer/:2:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"Go 优点 语言层面支持并发：一个 go 关键字即可实现并发，其他编程语言依赖于库实现并发，这是有本质的区别 高性能 编译完之后生成二进制文件，可免去环境依赖 defer 机制 内置runtime 内嵌C支持，Go里面也可以直接包含C代码，利用现有的丰富的C库 跨平台编译 。。。 ","date":"2020-11-08","objectID":"/defer/:3:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"Go 缺点 包管理 。。。 ","date":"2020-11-08","objectID":"/defer/:4:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"defer 说起 Go 语言的最强大的地方，不得不说 Go 的并发机制和调度原理，但是今天不讲这些高深的理论，先从简单的开始。先思考这么几个问题（可以用自己熟悉的语言思考如何解决）: 对于文件的打开关闭，网络连接的建立断开场景，当打开时候应该何时关闭? 当调用一个函数，希望在函数返回时修改它的值，该如何解决? 先看看defer 的官方定义 ： A “defer” statement invokes a function whose execution is deferred to the moment the surrounding function returns, either because the surrounding function executed a return statement, reached the end of its function body, or because the corresponding goroutine is panicking. 意思是说，当包裹defer 的函数返回时或者包裹defer的函数执行到末尾时或者所在的goroutine发生panic时才会执行。 换句话说就是当函数执行完之后或者发生异常时再执行defer语句，就是说在被调函数返回之后，赋值给调用函数之前，还有机会执行其他指令，是不是很神奇。先看一段python 代码 : def f(x,y) : z = x / y z += 1 return z ​ if __name__ == \"__main__\" : result = f(4 /2) 当调用函数f，f返回给z并且赋值给result，在这时间，是没有任何机会执行其他的函数代码的。再看一段go代码: package main func main() { result := f(4, 2) fmt.Println(result) } ​ func f(x, y int) (r int) { r = x / y r += 1 defer func() { r += 2 }() return } 当调用函数f，f返回之后，在赋值之前执行了r +=2 。现在回想一下之前的两个问题，如果有defer 机制，是不是可以很好的解决。如对于第一个问题，在defer 语句中处理文件的关闭，连接的释放等，而不用考虑一些异常情况。 那defer的实现原理是怎样的呢? defer 其实是调用runtime.deferproc 进行实现，在defer 出现的地方，插入了call runtime.deferproc，然后在函数返回之前的地方，插入指令call runtime.deferreturn。 普通函数返回时，汇编代码类似于: add xx SP return 如果包含了defer 语句，汇编代码类似于: call runtime.deferreturn， add xx SP return goroutine的控制结构中，有一张表记录defer，调用runtime.deferproc时会将需要defer的表达式记录在表中，而在调用runtime.deferreturn的时候，则会依次从defer表中出栈并执行。 defer 在使用过程中也存在一些坑，看几个例子: 例1: func f() (result int) { defer func() { result++ }() return 10 } 例2: func f() (result int) { t := 10 defer func() { t = t + 1 }() return t } 例3: func f() (result int) { defer func(result int) { result = result + 1 }(result) return 10 } 大家可以先心里默默算一下他们的结果 第一个是11，第二个是10，第三个是10。 defer表达式可能会在设置函数返回值之后，在返回到调用函数之前，修改返回值，使最终的函数返回值与你想象的不一致。其实使用defer时，用一个简单的转换规则改写一下，就不会迷糊了。改写规则是将return语句拆成两句写，return xxx会被改写成: 返回值 = xxx 调用defer函数 空的return 例1 会被改写成: func f() (result int) { result = 10 // return语句不是一条原子调用，return xxx其实是赋值＋ret指令 defer func() { result++ }() return // 空的return指令 } 所以返回值是11 例2 会被改写成: func f() (result int) { t := 10 result = t // 赋值指令 defer func() { t = t + 1 //defer被插入到赋值与返回之间执行，这个例子中返回值 result没被修改过 }() return // 空的return指令 } 所以返回值是10 例3 就留给大家自己改写一下啦，有兴趣可以私我沟通哟！ ","date":"2020-11-08","objectID":"/defer/:5:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"总结 这篇主要做了对Go语言的介绍和优缺点，分析了defer 的用法以及实现原理，最后用例子展示了使用过程中可能会存在的坑。下篇预告: Go 的调度模型，欢迎关注!!! 如果有理解不正确的地方，欢迎指出。 ","date":"2020-11-08","objectID":"/defer/:6:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"自己开源的项目","date":"2020-11-08","objectID":"/opensrouce/toolkit/","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"toolkit ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:0:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"作用 用于提供工作效率的工具箱，里面有各种工具，就比如真实工具箱中里面有扳手，各种大小的起子，钳子等 某些场景下确实可以达到事半功倍的效果 ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:1:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"安装 ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:2:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"源码安装 有 go 语言环境的可以直接用源码进行编译运行 git clone https://github.com/russellgao/toolkit.git cd toolkit make ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:2:1","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"二进制 可以直接在release 页面进行下载对应的操作系统的二进制文件 https://github.com/russellgao/toolkit/releases/ ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:2:2","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"用法 ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:3:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"本机运行 可以通过如下命令进行 gwz:toolkit gaoweizong$ tkctl --help tkctl is a toolkit entrypoint,run `tkctl --help` get more information. Usage: tkctl [flags] tkctl [command] Available Commands: help Help about any command replace 文本替换，支持正则替换和非正则替换，类似与linux下的sed，但比sed更好用，而且可以跨平台使用 secret 生成随机密码，支持1～100位长度，可以指定是否包含特殊字符 version tkctl version Flags: -h, --help help for tkctl -v, --version show the version and exit Use \"tkctl [command] --help\" for more information about a command. tkctl 中的子命令会不断更新，某个具体的功能请查看Available Commands:下的帮助文档，如文本替换 tkctl replace --help 文本替换，支持正则替换和非正则替换，类似与linux下的sed，但比sed更好用，而且可以跨平台使用 Usage: tkctl replace [flags] Flags: -d, --dirs string 需要替换的目录, 默认为当前路径 (default \".\") -h, --help help for replace -m, --mode string 替换的模式，支持正则（regexp）和非正则（text）两种模式，默认非正则， (default \"text\") -p, --pattern string 需要替换的pattern [required] -r, --repl string 目标字符串 [required] ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:3:1","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"docker 如果本地有docker环境，也可以不用下载二进制的制品，可以通过docker 环境直接运行 docker run -it --rm russellgao/toolkit:latest tkctl --help # 如果有需要可以把目录挂载进去 docker run -it -v /data:/data --rm russellgao/toolkit:latest tkctl --help ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:3:2","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"适用范围 可以跨平台使用 mac windows linux ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:4:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"开发环境 go 1.14.2 ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:5:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"支持的功能 ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:6:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"1.0.0 文本正则替换 生成随机密码 ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:6:1","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"未来展望 期望可以成为一个完整的工具箱，可以解决日常工作中的繁杂事情。 ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:7:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"项目地址 https://github.com/russellgao/toolkit ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:8:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"如何利用 python 操纵 oracle","date":"2020-07-09","objectID":"/oracle/","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"安装库 pip3 install sqlalchemy pip3 install cx_Oracle ","date":"2020-07-09","objectID":"/oracle/:1:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"安装客户端 oracle 客户端下载页面: https://www.oracle.com/database/technologies/instant-client/downloads.html ","date":"2020-07-09","objectID":"/oracle/:2:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"mac https://www.oracle.com/database/technologies/instant-client/macos-intel-x86-downloads.html 在上面的页面下载之后执行: # 解压 cd ~ unzip instantclient-basic-macos.x64-19.3.0.0.0dbru.zip # 创建link mkdir ~/lib ln -s ~/instantclient_19_3/libclntsh.dylib ~/lib/ ","date":"2020-07-09","objectID":"/oracle/:2:1","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"linux https://www.oracle.com/database/technologies/instant-client/linux-x86-64-downloads.html ","date":"2020-07-09","objectID":"/oracle/:2:2","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"windows https://www.oracle.com/database/technologies/instant-client/winx64-64-downloads.html ","date":"2020-07-09","objectID":"/oracle/:2:3","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"使用 在上面装好库和oracle client 就可以用python 操作 oracle 了 简单用法参见 : from sqlalchemy import * # 连接oracle engine = create_engine('oracle://username:passwoed@xxxxx', encoding=\"utf8\",echo=True) connection = engine.connect() # table, 会根据表名自动生成Table 对象 meta = MetaData() t = Table(\"abcd\",meta,autoload=True,autoload_with=engine) # 获取列 columns = t.c print(columns) # 查询 # s = select([t]) # s = select([t]).where(t.c.name == \"xxxx\") s = select([t]).where(t.c.code == \"xxxx\") result = connection.execute(s) for row in result : print(row[t.c.gid],row[t.c.code],row[t.c.name],row[t.c.note]) result.close() print(\"end\") ","date":"2020-07-09","objectID":"/oracle/:3:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"报错 如果报如下错误: sqlalchemy.exc.DatabaseError: (cx_Oracle.DatabaseError) DPI-1047: Cannot locate a 64-bit Oracle Client library: \"dlopen(libclntsh.dylib, 1): image not found\". See https://cx-oracle.readthedocs.io/en/latest/user_guide/installation.html for help (Background on this error at: http://sqlalche.me/e/13/4xp6) 说明oracle的 client 没有正确安装 如果报错如下: sqlalchemy.exc.DatabaseError: (cx_Oracle.DatabaseError) ORA-01017: invalid username/password; logon denied (Background on this error at: http://sqlalche.me/e/13/4xp6) 说明oracle 的用户密码不正确 ","date":"2020-07-09","objectID":"/oracle/:4:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"参考 https://docs.sqlalchemy.org/en/13/dialects/oracle.html https://www.cnblogs.com/iupoint/p/10932069.html ","date":"2020-07-09","objectID":"/oracle/:5:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"如何利用 python 操纵 oracle","date":"2020-07-09","objectID":"/python/oracle/","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"安装库 pip3 install sqlalchemy pip3 install cx_Oracle ","date":"2020-07-09","objectID":"/python/oracle/:1:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"安装客户端 oracle 客户端下载页面: https://www.oracle.com/database/technologies/instant-client/downloads.html ","date":"2020-07-09","objectID":"/python/oracle/:2:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"mac https://www.oracle.com/database/technologies/instant-client/macos-intel-x86-downloads.html 在上面的页面下载之后执行: # 解压 cd ~ unzip instantclient-basic-macos.x64-19.3.0.0.0dbru.zip # 创建link mkdir ~/lib ln -s ~/instantclient_19_3/libclntsh.dylib ~/lib/ ","date":"2020-07-09","objectID":"/python/oracle/:2:1","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"linux https://www.oracle.com/database/technologies/instant-client/linux-x86-64-downloads.html ","date":"2020-07-09","objectID":"/python/oracle/:2:2","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"windows https://www.oracle.com/database/technologies/instant-client/winx64-64-downloads.html ","date":"2020-07-09","objectID":"/python/oracle/:2:3","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"使用 在上面装好库和oracle client 就可以用python 操作 oracle 了 简单用法参见 : from sqlalchemy import * # 连接oracle engine = create_engine('oracle://username:passwoed@xxxxx', encoding=\"utf8\",echo=True) connection = engine.connect() # table, 会根据表名自动生成Table 对象 meta = MetaData() t = Table(\"abcd\",meta,autoload=True,autoload_with=engine) # 获取列 columns = t.c print(columns) # 查询 # s = select([t]) # s = select([t]).where(t.c.name == \"xxxx\") s = select([t]).where(t.c.code == \"xxxx\") result = connection.execute(s) for row in result : print(row[t.c.gid],row[t.c.code],row[t.c.name],row[t.c.note]) result.close() print(\"end\") ","date":"2020-07-09","objectID":"/python/oracle/:3:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"报错 如果报如下错误: sqlalchemy.exc.DatabaseError: (cx_Oracle.DatabaseError) DPI-1047: Cannot locate a 64-bit Oracle Client library: \"dlopen(libclntsh.dylib, 1): image not found\". See https://cx-oracle.readthedocs.io/en/latest/user_guide/installation.html for help (Background on this error at: http://sqlalche.me/e/13/4xp6) 说明oracle的 client 没有正确安装 如果报错如下: sqlalchemy.exc.DatabaseError: (cx_Oracle.DatabaseError) ORA-01017: invalid username/password; logon denied (Background on this error at: http://sqlalche.me/e/13/4xp6) 说明oracle 的用户密码不正确 ","date":"2020-07-09","objectID":"/python/oracle/:4:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"参考 https://docs.sqlalchemy.org/en/13/dialects/oracle.html https://www.cnblogs.com/iupoint/p/10932069.html ","date":"2020-07-09","objectID":"/python/oracle/:5:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"pod 配置文件说明","date":"2020-06-18","objectID":"/kubernetes/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/","tags":["kubernetes","pod"],"title":"pod 配置文件说明","uri":"/kubernetes/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/"},{"categories":null,"content":"Pod的定义文件 apiVersion:v1kind:Podmetadata:name:stringnamaspace:stringlabels:- name:stringannotations:- name:stringspec:containers:- name:string# 使用的镜像image:stringimagePullPolicy:[Always|Never|IfNotPresent]command:[string]args:[string]# 工作目录workingDir:stringvolumeMounts:- name:stringmountPath:stringreadOnly:booleanports:- name:stringcontainerPort:inthostPort:intprotocol:stringenv:- name:stringvalue:stringresources:limits:cpu:stringmemory:stringrequests:cpu:stringmemory:stringlivenessProbe:exec:command:[string]httpGet:path:stringport:inthost:stringscheme:stringhttpHeaders:- name:stringvalue:stringtcpSocket:port:int# 多久之后去检查initialDelaySeconds:number# 健康检查超时时间timeoutSeconds:number# 多长时间检查一次periodSeconds:number# 成功的阀值，检查几次成功才算成功successThreshold:0# 失败的阀值，检查几次失败才算失败failureThreshold:0securityContext:# 详细参见 pod_SecurityContext 章节# securityContext 可以配置pod 或者container 级别runAsUser:1000# 运行的用户runAsGroup:3000# 运行的用户组fsGroup:2000privileged:bool# 是否以privileged 权限运行，即这是这个进程拥有特权allowPrivilegeEscalation:bool# 控制一个进程是否能比其父进程获取更多的权限，如果一个容器以privileged权限运行或具有CAP_SYS_ADMIN权限，则AllowPrivilegeEscalation的值将总是truecapabilities:add:[\"NET_ADMIN\",\"SYS_TIME\",\"...\"]# 给某个特定的进程privileged权限，而不用给root用户所有的privileged权限terminationMessagePath:/dev/termination-log# 容器终止的日志文件terminationMessagePolicy:[File|FallbackToLogsOnError]# 默认为File, 容器终止消息输出到文件restartPolicy:[Always|Never|OnFailure]# 重启策略，默认为 AlwaysnodeSelector:object# 通过label 选取nodednsPolicy:ClusterFirst# pod 的 dns 策略 ,可以配置如下值# Default : 和宿主机的DNS完全一致# ClusterFirst: 把集群的DNS写入到Pod的DNS配置，但是如果设置了HostNetwork=true，就会强制设置为Default# ClusterFirstWithHostNet: 把集群的DNS写入到Pod的DNS配置，不管是否设置HostNetwork# None: 忽略所有的DNS配置，一般来说，设置了None之后会自己手动再设置dnsConfigenableServiceLinks:true# Kubernetes支持两种查找服务的主要模式: 环境变量和DNS, 如果不需要服务环境变量, 将 `enableServiceLinks` 标志设置为 `false` 来禁用此模式terminationGracePeriodSeconds:10# 发出删除pod指令后多久之后真正的删除podserviceAccountName:jenkins# pod 绑定的serviceAccountpriorityClassName:# 给pod 设置优先级，参考 : https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/schedulerName:default-scheduler# 如果不配置则使用kubernetes 默认的default-scheduler，如果这个不满足要求则可以自定义一个scheduler# https://kubernetes.io/zh/docs/tasks/administer-cluster/configure-multiple-schedulers/affinity:# 亲和性设置tolerations:- effect:NoExecutekey:node.kubernetes.io/not-readyoperator:ExiststolerationSeconds:300- effect:NoExecutekey:node.kubernetes.io/unreachableoperator:ExiststolerationSeconds:300# 容忍设置imagePullSecrets:- name:string# 镜像拉取策略hostNetwork:false# 是否使用主机网络，默认为false，如果为true，pod直接用主机网络，在pod中可以看到主机的网络接口volumes:- name:stringemptyDir:{}hostPath:path:stringsecret:secretName:stringitems:- key:stringpath:stringconfigMap:name:stringitems:- key:stringpath:string# 目录挂载 ","date":"2020-06-18","objectID":"/kubernetes/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/:1:0","tags":["kubernetes","pod"],"title":"pod 配置文件说明","uri":"/kubernetes/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/"},{"categories":null,"content":"pod 具体的样例 apiVersion:v1kind:Podmetadata:labels:app:elastic-clustername:enode-0spec:containers:- env:- name:ES_JAVA_OPTSvalueFrom:configMapKeyRef:key:ES_JAVA_OPTSname:es-configimage:elasticsearch:6.7.2imagePullPolicy:IfNotPresentlivenessProbe:failureThreshold:3httpGet:path:/_cluster/health?local=trueport:9200scheme:HTTPperiodSeconds:600successThreshold:1timeoutSeconds:1name:elasticsearchports:- containerPort:9200name:es-httpprotocol:TCP- containerPort:9300name:es-transportprotocol:TCPreadinessProbe:failureThreshold:3httpGet:path:/_cluster/health?local=trueport:9200scheme:HTTPinitialDelaySeconds:30periodSeconds:20successThreshold:1timeoutSeconds:1resources:limits:cpu:\"2\"memory:10Girequests:cpu:\"1\"memory:8GisecurityContext:capabilities:add:- IPC_LOCK- SYS_RESOURCEprivileged:truerunAsUser:1000terminationMessagePath:/dev/termination-logterminationMessagePolicy:FilevolumeMounts:- mountPath:/usr/share/elasticsearch/dataname:es-data- mountPath:/usr/share/elasticsearch/logsname:es-logs- mountPath:/usr/share/elasticsearch/config/elasticsearch.ymlname:elasticsearch-configsubPath:elasticsearch.yml- mountPath:/var/run/secrets/kubernetes.io/serviceaccountname:default-token-k4r6freadOnly:truednsPolicy:ClusterFirstenableServiceLinks:truehostname:enode-0initContainers:- command:- sysctl- -w- vm.max_map_count=262144image:busyboximagePullPolicy:IfNotPresentname:init-sysctlresources:{}securityContext:privileged:trueterminationMessagePath:/dev/termination-logterminationMessagePolicy:FilevolumeMounts:- mountPath:/var/run/secrets/kubernetes.io/serviceaccountname:default-token-k4r6freadOnly:truepriority:0restartPolicy:AlwaysschedulerName:default-schedulersecurityContext:fsGroup:1000serviceAccount:defaultserviceAccountName:defaultsubdomain:elasticsearch-clusterterminationGracePeriodSeconds:30tolerations:- effect:NoExecutekey:node.kubernetes.io/not-readyoperator:ExiststolerationSeconds:300- effect:NoExecutekey:node.kubernetes.io/unreachableoperator:ExiststolerationSeconds:300volumes:- name:es-datapersistentVolumeClaim:claimName:es-data-enode-0- name:es-logspersistentVolumeClaim:claimName:es-logs-enode-0- configMap:defaultMode:420items:- key:elasticsearch.ymlpath:elasticsearch.ymlname:es-configname:elasticsearch-config- name:default-token-k4r6fsecret:defaultMode:420secretName:default-token-k4r6f ","date":"2020-06-18","objectID":"/kubernetes/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/:2:0","tags":["kubernetes","pod"],"title":"pod 配置文件说明","uri":"/kubernetes/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/"},{"categories":null,"content":"pod 配置文件说明","date":"2020-06-18","objectID":"/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/","tags":["kubernetes","pod"],"title":"pod 配置文件说明","uri":"/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/"},{"categories":null,"content":"Pod的定义文件 apiVersion:v1kind:Podmetadata:name:stringnamaspace:stringlabels:- name:stringannotations:- name:stringspec:containers:- name:string# 使用的镜像image:stringimagePullPolicy:[Always|Never|IfNotPresent]command:[string]args:[string]# 工作目录workingDir:stringvolumeMounts:- name:stringmountPath:stringreadOnly:booleanports:- name:stringcontainerPort:inthostPort:intprotocol:stringenv:- name:stringvalue:stringresources:limits:cpu:stringmemory:stringrequests:cpu:stringmemory:stringlivenessProbe:exec:command:[string]httpGet:path:stringport:inthost:stringscheme:stringhttpHeaders:- name:stringvalue:stringtcpSocket:port:int# 多久之后去检查initialDelaySeconds:number# 健康检查超时时间timeoutSeconds:number# 多长时间检查一次periodSeconds:number# 成功的阀值，检查几次成功才算成功successThreshold:0# 失败的阀值，检查几次失败才算失败failureThreshold:0securityContext:# 详细参见 pod_SecurityContext 章节# securityContext 可以配置pod 或者container 级别runAsUser:1000# 运行的用户runAsGroup:3000# 运行的用户组fsGroup:2000privileged:bool# 是否以privileged 权限运行，即这是这个进程拥有特权allowPrivilegeEscalation:bool# 控制一个进程是否能比其父进程获取更多的权限，如果一个容器以privileged权限运行或具有CAP_SYS_ADMIN权限，则AllowPrivilegeEscalation的值将总是truecapabilities:add:[\"NET_ADMIN\",\"SYS_TIME\",\"...\"]# 给某个特定的进程privileged权限，而不用给root用户所有的privileged权限terminationMessagePath:/dev/termination-log# 容器终止的日志文件terminationMessagePolicy:[File|FallbackToLogsOnError]# 默认为File, 容器终止消息输出到文件restartPolicy:[Always|Never|OnFailure]# 重启策略，默认为 AlwaysnodeSelector:object# 通过label 选取nodednsPolicy:ClusterFirst# pod 的 dns 策略 ,可以配置如下值# Default : 和宿主机的DNS完全一致# ClusterFirst: 把集群的DNS写入到Pod的DNS配置，但是如果设置了HostNetwork=true，就会强制设置为Default# ClusterFirstWithHostNet: 把集群的DNS写入到Pod的DNS配置，不管是否设置HostNetwork# None: 忽略所有的DNS配置，一般来说，设置了None之后会自己手动再设置dnsConfigenableServiceLinks:true# Kubernetes支持两种查找服务的主要模式: 环境变量和DNS, 如果不需要服务环境变量, 将 `enableServiceLinks` 标志设置为 `false` 来禁用此模式terminationGracePeriodSeconds:10# 发出删除pod指令后多久之后真正的删除podserviceAccountName:jenkins# pod 绑定的serviceAccountpriorityClassName:# 给pod 设置优先级，参考 : https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/schedulerName:default-scheduler# 如果不配置则使用kubernetes 默认的default-scheduler，如果这个不满足要求则可以自定义一个scheduler# https://kubernetes.io/zh/docs/tasks/administer-cluster/configure-multiple-schedulers/affinity:# 亲和性设置tolerations:- effect:NoExecutekey:node.kubernetes.io/not-readyoperator:ExiststolerationSeconds:300- effect:NoExecutekey:node.kubernetes.io/unreachableoperator:ExiststolerationSeconds:300# 容忍设置imagePullSecrets:- name:string# 镜像拉取策略hostNetwork:false# 是否使用主机网络，默认为false，如果为true，pod直接用主机网络，在pod中可以看到主机的网络接口volumes:- name:stringemptyDir:{}hostPath:path:stringsecret:secretName:stringitems:- key:stringpath:stringconfigMap:name:stringitems:- key:stringpath:string# 目录挂载 ","date":"2020-06-18","objectID":"/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/:1:0","tags":["kubernetes","pod"],"title":"pod 配置文件说明","uri":"/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/"},{"categories":null,"content":"pod 具体的样例 apiVersion:v1kind:Podmetadata:labels:app:elastic-clustername:enode-0spec:containers:- env:- name:ES_JAVA_OPTSvalueFrom:configMapKeyRef:key:ES_JAVA_OPTSname:es-configimage:elasticsearch:6.7.2imagePullPolicy:IfNotPresentlivenessProbe:failureThreshold:3httpGet:path:/_cluster/health?local=trueport:9200scheme:HTTPperiodSeconds:600successThreshold:1timeoutSeconds:1name:elasticsearchports:- containerPort:9200name:es-httpprotocol:TCP- containerPort:9300name:es-transportprotocol:TCPreadinessProbe:failureThreshold:3httpGet:path:/_cluster/health?local=trueport:9200scheme:HTTPinitialDelaySeconds:30periodSeconds:20successThreshold:1timeoutSeconds:1resources:limits:cpu:\"2\"memory:10Girequests:cpu:\"1\"memory:8GisecurityContext:capabilities:add:- IPC_LOCK- SYS_RESOURCEprivileged:truerunAsUser:1000terminationMessagePath:/dev/termination-logterminationMessagePolicy:FilevolumeMounts:- mountPath:/usr/share/elasticsearch/dataname:es-data- mountPath:/usr/share/elasticsearch/logsname:es-logs- mountPath:/usr/share/elasticsearch/config/elasticsearch.ymlname:elasticsearch-configsubPath:elasticsearch.yml- mountPath:/var/run/secrets/kubernetes.io/serviceaccountname:default-token-k4r6freadOnly:truednsPolicy:ClusterFirstenableServiceLinks:truehostname:enode-0initContainers:- command:- sysctl- -w- vm.max_map_count=262144image:busyboximagePullPolicy:IfNotPresentname:init-sysctlresources:{}securityContext:privileged:trueterminationMessagePath:/dev/termination-logterminationMessagePolicy:FilevolumeMounts:- mountPath:/var/run/secrets/kubernetes.io/serviceaccountname:default-token-k4r6freadOnly:truepriority:0restartPolicy:AlwaysschedulerName:default-schedulersecurityContext:fsGroup:1000serviceAccount:defaultserviceAccountName:defaultsubdomain:elasticsearch-clusterterminationGracePeriodSeconds:30tolerations:- effect:NoExecutekey:node.kubernetes.io/not-readyoperator:ExiststolerationSeconds:300- effect:NoExecutekey:node.kubernetes.io/unreachableoperator:ExiststolerationSeconds:300volumes:- name:es-datapersistentVolumeClaim:claimName:es-data-enode-0- name:es-logspersistentVolumeClaim:claimName:es-logs-enode-0- configMap:defaultMode:420items:- key:elasticsearch.ymlpath:elasticsearch.ymlname:es-configname:elasticsearch-config- name:default-token-k4r6fsecret:defaultMode:420secretName:default-token-k4r6f ","date":"2020-06-18","objectID":"/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/:2:0","tags":["kubernetes","pod"],"title":"pod 配置文件说明","uri":"/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/"},{"categories":null,"content":"位运算合集","date":"2020-05-30","objectID":"/argorithm/bit/","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位运算 计算机中的数在内存中都是以二进制形式进行存储的，用位运算就是直接对整数在内存中的二进制位进行操作，因此其执行效率非常高，在程序中尽量使用位运算进行操作，这会大大提高程序的性能。 ","date":"2020-05-30","objectID":"/argorithm/bit/:0:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位操作符 ","date":"2020-05-30","objectID":"/argorithm/bit/:1:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"\u0026 与运算 \u0026 与运算 两个位都是 1 时，结果才为 1，否则为 0，如 1 0 0 1 1 \u0026 1 1 0 0 1 ------------------------------ 1 0 0 0 1 ","date":"2020-05-30","objectID":"/argorithm/bit/:1:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"| 或运算 两个位都是 0 时，结果才为 0，否则为 1，如 1 0 0 1 1 | 1 1 0 0 1 ------------------------------ 1 1 0 1 1 ","date":"2020-05-30","objectID":"/argorithm/bit/:1:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"^ 异或运算 两个位相同则为 0，不同则为 1，如 1 0 0 1 1 ^ 1 1 0 0 1 ----------------------------- 0 1 0 1 0 ","date":"2020-05-30","objectID":"/argorithm/bit/:1:3","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"~ 取反运算 0 则变为 1，1 则变为 0，如 ~ 1 0 0 1 1 ----------------------------- 0 1 1 0 0 ","date":"2020-05-30","objectID":"/argorithm/bit/:1:4","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"« 左移运算 向左进行移位操作，高位丢弃，低位补 0,如 int a = 8; a \u003c\u003c 3; 移位前：0000 0000 0000 0000 0000 0000 0000 1000 移位后：0000 0000 0000 0000 0000 0000 0100 0000 左移n为的值即为当前值*2^n, 如: a = 8 b = a\u003c\u003c3 # 64 c = a * (2 ** 3) # 64 ","date":"2020-05-30","objectID":"/argorithm/bit/:1:5","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"»右移运算 向右进行移位操作，对无符号数，高位补 0，对于有符号数，高位补符号位，如 unsigned int a = 8; a \u003e\u003e 3; 移位前：0000 0000 0000 0000 0000 0000 0000 1000 移位后：0000 0000 0000 0000 0000 0000 0000 0001 ​ int a = -8; a \u003e\u003e 3; 移位前：1111 1111 1111 1111 1111 1111 1111 1000 移位前：1111 1111 1111 1111 1111 1111 1111 1111 ","date":"2020-05-30","objectID":"/argorithm/bit/:1:6","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"有符号数和无符号数 ","date":"2020-05-30","objectID":"/argorithm/bit/:2:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"有符号数 有符号数的定义是：字节的最高位作为符号位，其余的是数值位。例如一个字节中存储的二进制数为1100 1000，最高位1作为符号位，其余的7为 100 1000 作为数值为。 那么，符号位占据1位，就有0和1这样的两种数值，就有： 如果符号位为0，那么字节中存储的数值是正数 如果符号位为1，那么字节中存储的数值是负数 对于1100 1000这样的二进制数据，符号位是1，就表示负数。 在有符号数中，表示负数的算法是： 把数值位中存储的二进制数据，每个位都取反，就是原来为0的值变为1，原来为1的值变为0； 给对取反后的二进制数据加1，得到的数值就得到负数值； ","date":"2020-05-30","objectID":"/argorithm/bit/:2:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"无符号数 无符号数的定义是：没有符号位，所有的位数都是数值位。所以表示的都是正数。 ","date":"2020-05-30","objectID":"/argorithm/bit/:2:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"例子 例一 1100 1000这个数值，如果作为有符号数看待，那么符号位是1，数值位是100 1000。所以，符号位是1，所以，这个数据是负数。然后，表示成十进制时，对数值位的操作是： 数值位取反，得到011 0111； 对取反后的数值 011 0111加1得到011 1000，数值位的值为56； 那么，1100 1000这个二进制数据表示为“有符号数”时，就是-56这个数值。 如果作为无符号数看待，那么，就没有符号位，所有的位数都是数值位，所以11001000都作为数值位，表示的十进制数值是200 例二 例如，0111 0011这个数值，如果当做“有符号数”看待，那么，其符号位是0，所以，表示整数，数值位是115，所以，表示正115这个数值。如果当做无符号数看待，所有位都是数值位，计算得到115这个数值，所以，表示正115。所以我们可以总结 ","date":"2020-05-30","objectID":"/argorithm/bit/:2:3","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"总结 无符号数，总是表示正数。所有位数都表示数值位。 有符号数，可以表示正数和负数，最高位是符号位，其余位都是数值位。如果符号位是0，则表示正数；如果符号位是1，则表示负数。对于负数的表示方法是：数值位全部取反，再加1，得到的数值就是负数值。 ","date":"2020-05-30","objectID":"/argorithm/bit/:2:4","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"原码、反码、补码 ","date":"2020-05-30","objectID":"/argorithm/bit/:3:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"原码 原码的表示范围-127~-0, +0~+127, 共256个数字 正0的原码是0000 0000, 负0的原码是1000 0000, 有正0负0之分, 不符合人的习惯, 待解决. 原码有几个缺点，零分两种 +0 和 -0 。还有，在进行不同符号的加法运算或者同符号的减法运算的时候，不能直接判断出结果的正负。你需要将两个值的绝对值进行比较，然后进行加减操作 ，最后符号位由绝对值大的决定。于是反码就产生了。 ","date":"2020-05-30","objectID":"/argorithm/bit/:3:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"反码 除符号位, 原码其余位取反而得 +0：0000 0000，-0：1111 1111 仍然有正0负0之分。 正数的反码就是原码，负数的反码等于原码除符号位以外所有的位取反 举例说明： int类型的 3 的反码是 00000000 00000000 00000000 00000011 和原码一样没什么可说的 int类型的 -3 的反码是 11111111 11111111 11111111 11111100 除开符号位 所有位 取反 解决了加减运算的问题，但还是有正负零之分，然后就到补码了 ","date":"2020-05-30","objectID":"/argorithm/bit/:3:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"补码 在反码的基础上加1而得 对原码的两种0同时末位加1 +0：0000 0000，-0：0000 0000(因为溢出导致8位全0) 消除了正0负0之别, 如此一来, 便节省出一个数值表示方式1000 0000, 不能浪费, 用来表示-128, -128特殊之处在于没有相应的反码原码。也可以这样考虑: -1： 1111 1111 -2： 1111 1110（在-1的基础上减1，直接将补码减1即可） -3： 1111 1101（在-2补码基础上减1，以下类似） -4： 1111 1100 …… -127：1000 0001 -128：1000 0000 如此以来：8位补码表示范围是-128~+127因为0只有一种形式所以，仍然是256个数 若8位代表无符号数, 则表示范围是 : 0~255, 这就是为什么高级语言讲到数据类型， 正数的补码与原码相同，负数的补码为 其原码除符号位外所有位取反（得到反码了），然后最低位加1 ","date":"2020-05-30","objectID":"/argorithm/bit/:3:3","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"原码，反码，补码总结 正数的反码和补码都与原码相同。 负数的反码为对该数的原码除符号位外各位取反。 负数的补码为对该数的原码除符号位外各位取反，然后在最后一位加1　 优缺点: 原码最好理解了，但是加减法不够方便，还有两个零。。 反码稍微困难一些，解决了加减法的问题，但还是有有个零 补码理解困难，其他就没什么缺点了 ","date":"2020-05-30","objectID":"/argorithm/bit/:3:4","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"存储 计算机中的整数是用补码存储的，最高位为符号位 如果最高位为0则为正数，求值的时候，直接转为10进制即可。 最高位如果为1代表为负数，求值的时候，需要先把二进制的值按位取反，然后加1得到负数绝对值(相反数)的二进制码，然后转为10进制，加上负号即可。 ","date":"2020-05-30","objectID":"/argorithm/bit/:3:5","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"原码，反码，补码的应用 ","date":"2020-05-30","objectID":"/argorithm/bit/:3:6","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"负数的十进制和二进制转换 ","date":"2020-05-30","objectID":"/argorithm/bit/:4:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"十进制转二进制 方法为: 先转换为二进制 对二进制数求反 再将该二进制数加一 总而言之: 十进制数转换为二进制数求补码即为结果 例子 -32 转换为二进制 第一步：32（10）=00100000（2） 第二步：求反：11011111 第三步：加1:11100000 所以-32（10）=11100000（2） ","date":"2020-05-30","objectID":"/argorithm/bit/:4:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"二进制转十进制 方法为: 数值为取反 对该二进制加一 转换为10进制 例子 11001000 转换为十进制 第一步（数值位取反）： 10110111 第二步（加一）：10111000 第三步（十进制）：-56 所以11001000（2）=-56（10） ","date":"2020-05-30","objectID":"/argorithm/bit/:4:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"十进制数求反的规律 下面都是以10进制表示: ","date":"2020-05-30","objectID":"/argorithm/bit/:5:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"负数求反 负数求反等于其绝对值 -1 如: num = -5 num1 = ~num # 4 ","date":"2020-05-30","objectID":"/argorithm/bit/:5:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"正数求反 正数求反等于其值 +1 的负数 如: num = 4 num1 = ~num # -5 ","date":"2020-05-30","objectID":"/argorithm/bit/:5:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"二进制的应用场景 ","date":"2020-05-30","objectID":"/argorithm/bit/:6:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位操作实现乘除法 数 a 向右移一位，相当于将 a 除以 2；数 a 向左移一位，相当于将 a 乘以 2 a = 2 a \u003e\u003e 1 # ---\u003e 1 a \u003c\u003c 1 # ---\u003e 4 ","date":"2020-05-30","objectID":"/argorithm/bit/:6:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位操作交换两数 位操作交换两数可以不需要第三个临时变量，虽然普通操作也可以做到，但是没有其效率高 # 普通操作 def swap(a: int, b: int) -\u003e(int,int): a = a + b b = a - b a = a - b return a,b # 位与操作 def swap(a: int, b: int) -\u003e (int, int): \"\"\" 交换两个数 :param a: :param b: :return: \"\"\" a ^= b # a = (a^b) b ^= a # b = b ^ a = b ^ a ^ b a ^= b # a = a ^ b = a ^ a ^ b return a, b ","date":"2020-05-30","objectID":"/argorithm/bit/:6:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位操作判断奇偶数 只要根据数的最后一位是 0 还是 1 来决定即可，为 0 就是偶数，为 1 就是奇数 if(0 == (a \u0026 1)) { //偶数 } ","date":"2020-05-30","objectID":"/argorithm/bit/:6:3","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位操作交换符号 交换符号将正数变成负数，负数变成正数 func reversal(a int) int { return ^a + 1 } def reversal(a: int) -\u003e int: \"\"\" 求相反数 :param a: :return: \"\"\" return ~a + 1 正数取反加1，正好变成其对应的负数(补码表示)；负数取反加一，则变为其原码，即正数 ","date":"2020-05-30","objectID":"/argorithm/bit/:6:4","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位操作求绝对值 正数的绝对值是其本身，负数的绝对值正好可以对其进行取反加一求得，即我们首先判断其符号位（整数右移 31 位得到 0，负数右移 31 位得到 -1,即 0xffffffff），然后根据符号进行相应的操作 def abs(a: int) -\u003e int: i = a \u003e\u003e 31 result = a if i == 0 else ~a + 1 return result 上面的操作可以进行优化，可以将 i == 0 的条件判断语句去掉。我们都知道符号位 i 只有两种情况，即 i = 0 为正，i = -1 为负。对于任何数与 0 异或都会保持不变，与 -1 即 0xffffffff 进行异或就相当于对此数进行取反,因此可以将上面三目元算符转换为((a^i)-i)，即整数时 a 与 0 异或得到本身，再减去 0，负数时与 0xffffffff 异或将 a 进行取反，然后在加上 1，即减去 i(i =-1) def abs(a: int) -\u003e int: \"\"\" 求绝对值 :param a: :return: \"\"\" i = a \u003e\u003e 31 result = (a ^ i) - i return result or func abs(a int) int { i := a \u003e\u003e 31 return (a ^ i) - i } ","date":"2020-05-30","objectID":"/argorithm/bit/:6:5","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位操作进行高低位交换 给定一个 16 位的无符号整数，将其高 8 位与低 8 位进行交换，求出交换后的值，如 从上面移位操作我们可以知道，只要将无符号数 a»8 即可得到其高 8 位移到低 8 位，高位补 0；将 a « 8 即可将 低 8 位移到高 8 位，低 8 位补 0，然后将 a » 8 和 a«8 进行或操作既可求得交换后的结果 。 unsigned short a = 34520; a = (a \u003e\u003e 8) | (a \u003c\u003c 8); ","date":"2020-05-30","objectID":"/argorithm/bit/:6:6","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位操作统计二进制中 1 的个数 统计二进制1的个数可以分别获取每个二进制位数，然后再统计其1的个数，此方法效率比较低。 这里介绍另外一种高效的方法，同样以 34520 为例， 我们计算其 a \u0026= (a-1)的结果： 第一次：计算前：1000 0110 1101 1000 计算后：1000 0110 1101 0000 第二次：计算前：1000 0110 1101 0000 计算后：1000 0110 1100 0000 第三次：计算前：1000 0110 1100 0000 计算后：1000 0110 1000 0000 我们发现，每计算一次二进制中就少了一个 1，则我们可以通过下面方法去统计：count = 0 def count_1(a: int) -\u003e int: \"\"\" 计算数值的二进制表示的1的数量 :param a: :return: \"\"\" count = 0 while (a): a = a \u0026 a - 1 count += 1 return count ","date":"2020-05-30","objectID":"/argorithm/bit/:6:7","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"求和 两数求和 func add(a int, b int) int { for b != 0 { sum := a ^ b carry := (a \u0026 b) \u003c\u003c 1 a = sum b = carry } return a } ","date":"2020-05-30","objectID":"/argorithm/bit/:6:8","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"比特位计数 给定一个非负整数 num。对于 0 ≤ i ≤ num 范围中的每个数字 i ，计算其二进制数中的 1 的数目并将它们作为数组返回。 示例 1: 输入: 2 输出: [0,1,1] 示例 2: 输入: 5 输出: [0,1,1,2,1,2] def countBits(num: int) -\u003e [int]: result = [0] * (num + 1) for i in range(1, num + 1): result[i] = result[i \u0026 i - 1] + 1 return result func countBits(num int) []int { result := make([]int, num+1) for i := 1; i \u003c num+1 ; i ++ { result[i] = result[i \u0026 (i-1)] + 1 } return result } ","date":"2020-05-30","objectID":"/argorithm/bit/:6:9","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"常用的特殊的数 0xaaaaaaaa = 10101010101010101010101010101010 (偶数位为1，奇数位为0） 0x55555555 = 1010101010101010101010101010101 (偶数位为0，奇数位为1） 0x33333333 = 110011001100110011001100110011 (1和0每隔两位交替出现) 0xcccccccc = 11001100110011001100110011001100 (0和1每隔两位交替出现) 0x0f0f0f0f = 00001111000011110000111100001111 (1和0每隔四位交替出现) 0xf0f0f0f0 = 11110000111100001111000011110000 (0和1每隔四位交替出现) 0xffffffff = 11111111111111111111111111111111 ","date":"2020-05-30","objectID":"/argorithm/bit/:7:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位运算合集","date":"2020-05-30","objectID":"/bit/","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位运算 计算机中的数在内存中都是以二进制形式进行存储的，用位运算就是直接对整数在内存中的二进制位进行操作，因此其执行效率非常高，在程序中尽量使用位运算进行操作，这会大大提高程序的性能。 ","date":"2020-05-30","objectID":"/bit/:0:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位操作符 ","date":"2020-05-30","objectID":"/bit/:1:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"\u0026 与运算 \u0026 与运算 两个位都是 1 时，结果才为 1，否则为 0，如 1 0 0 1 1 \u0026 1 1 0 0 1 ------------------------------ 1 0 0 0 1 ","date":"2020-05-30","objectID":"/bit/:1:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"| 或运算 两个位都是 0 时，结果才为 0，否则为 1，如 1 0 0 1 1 | 1 1 0 0 1 ------------------------------ 1 1 0 1 1 ","date":"2020-05-30","objectID":"/bit/:1:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"^ 异或运算 两个位相同则为 0，不同则为 1，如 1 0 0 1 1 ^ 1 1 0 0 1 ----------------------------- 0 1 0 1 0 ","date":"2020-05-30","objectID":"/bit/:1:3","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"~ 取反运算 0 则变为 1，1 则变为 0，如 ~ 1 0 0 1 1 ----------------------------- 0 1 1 0 0 ","date":"2020-05-30","objectID":"/bit/:1:4","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"« 左移运算 向左进行移位操作，高位丢弃，低位补 0,如 int a = 8; a \u003c\u003c 3; 移位前：0000 0000 0000 0000 0000 0000 0000 1000 移位后：0000 0000 0000 0000 0000 0000 0100 0000 左移n为的值即为当前值*2^n, 如: a = 8 b = a\u003c\u003c3 # 64 c = a * (2 ** 3) # 64 ","date":"2020-05-30","objectID":"/bit/:1:5","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"»右移运算 向右进行移位操作，对无符号数，高位补 0，对于有符号数，高位补符号位，如 unsigned int a = 8; a \u003e\u003e 3; 移位前：0000 0000 0000 0000 0000 0000 0000 1000 移位后：0000 0000 0000 0000 0000 0000 0000 0001 ​ int a = -8; a \u003e\u003e 3; 移位前：1111 1111 1111 1111 1111 1111 1111 1000 移位前：1111 1111 1111 1111 1111 1111 1111 1111 ","date":"2020-05-30","objectID":"/bit/:1:6","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"有符号数和无符号数 ","date":"2020-05-30","objectID":"/bit/:2:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"有符号数 有符号数的定义是：字节的最高位作为符号位，其余的是数值位。例如一个字节中存储的二进制数为1100 1000，最高位1作为符号位，其余的7为 100 1000 作为数值为。 那么，符号位占据1位，就有0和1这样的两种数值，就有： 如果符号位为0，那么字节中存储的数值是正数 如果符号位为1，那么字节中存储的数值是负数 对于1100 1000这样的二进制数据，符号位是1，就表示负数。 在有符号数中，表示负数的算法是： 把数值位中存储的二进制数据，每个位都取反，就是原来为0的值变为1，原来为1的值变为0； 给对取反后的二进制数据加1，得到的数值就得到负数值； ","date":"2020-05-30","objectID":"/bit/:2:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"无符号数 无符号数的定义是：没有符号位，所有的位数都是数值位。所以表示的都是正数。 ","date":"2020-05-30","objectID":"/bit/:2:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"例子 例一 1100 1000这个数值，如果作为有符号数看待，那么符号位是1，数值位是100 1000。所以，符号位是1，所以，这个数据是负数。然后，表示成十进制时，对数值位的操作是： 数值位取反，得到011 0111； 对取反后的数值 011 0111加1得到011 1000，数值位的值为56； 那么，1100 1000这个二进制数据表示为“有符号数”时，就是-56这个数值。 如果作为无符号数看待，那么，就没有符号位，所有的位数都是数值位，所以11001000都作为数值位，表示的十进制数值是200 例二 例如，0111 0011这个数值，如果当做“有符号数”看待，那么，其符号位是0，所以，表示整数，数值位是115，所以，表示正115这个数值。如果当做无符号数看待，所有位都是数值位，计算得到115这个数值，所以，表示正115。所以我们可以总结 ","date":"2020-05-30","objectID":"/bit/:2:3","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"总结 无符号数，总是表示正数。所有位数都表示数值位。 有符号数，可以表示正数和负数，最高位是符号位，其余位都是数值位。如果符号位是0，则表示正数；如果符号位是1，则表示负数。对于负数的表示方法是：数值位全部取反，再加1，得到的数值就是负数值。 ","date":"2020-05-30","objectID":"/bit/:2:4","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"原码、反码、补码 ","date":"2020-05-30","objectID":"/bit/:3:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"原码 原码的表示范围-127~-0, +0~+127, 共256个数字 正0的原码是0000 0000, 负0的原码是1000 0000, 有正0负0之分, 不符合人的习惯, 待解决. 原码有几个缺点，零分两种 +0 和 -0 。还有，在进行不同符号的加法运算或者同符号的减法运算的时候，不能直接判断出结果的正负。你需要将两个值的绝对值进行比较，然后进行加减操作 ，最后符号位由绝对值大的决定。于是反码就产生了。 ","date":"2020-05-30","objectID":"/bit/:3:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"反码 除符号位, 原码其余位取反而得 +0：0000 0000，-0：1111 1111 仍然有正0负0之分。 正数的反码就是原码，负数的反码等于原码除符号位以外所有的位取反 举例说明： int类型的 3 的反码是 00000000 00000000 00000000 00000011 和原码一样没什么可说的 int类型的 -3 的反码是 11111111 11111111 11111111 11111100 除开符号位 所有位 取反 解决了加减运算的问题，但还是有正负零之分，然后就到补码了 ","date":"2020-05-30","objectID":"/bit/:3:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"补码 在反码的基础上加1而得 对原码的两种0同时末位加1 +0：0000 0000，-0：0000 0000(因为溢出导致8位全0) 消除了正0负0之别, 如此一来, 便节省出一个数值表示方式1000 0000, 不能浪费, 用来表示-128, -128特殊之处在于没有相应的反码原码。也可以这样考虑: -1： 1111 1111 -2： 1111 1110（在-1的基础上减1，直接将补码减1即可） -3： 1111 1101（在-2补码基础上减1，以下类似） -4： 1111 1100 …… -127：1000 0001 -128：1000 0000 如此以来：8位补码表示范围是-128~+127因为0只有一种形式所以，仍然是256个数 若8位代表无符号数, 则表示范围是 : 0~255, 这就是为什么高级语言讲到数据类型， 正数的补码与原码相同，负数的补码为 其原码除符号位外所有位取反（得到反码了），然后最低位加1 ","date":"2020-05-30","objectID":"/bit/:3:3","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"原码，反码，补码总结 正数的反码和补码都与原码相同。 负数的反码为对该数的原码除符号位外各位取反。 负数的补码为对该数的原码除符号位外各位取反，然后在最后一位加1　 优缺点: 原码最好理解了，但是加减法不够方便，还有两个零。。 反码稍微困难一些，解决了加减法的问题，但还是有有个零 补码理解困难，其他就没什么缺点了 ","date":"2020-05-30","objectID":"/bit/:3:4","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"存储 计算机中的整数是用补码存储的，最高位为符号位 如果最高位为0则为正数，求值的时候，直接转为10进制即可。 最高位如果为1代表为负数，求值的时候，需要先把二进制的值按位取反，然后加1得到负数绝对值(相反数)的二进制码，然后转为10进制，加上负号即可。 ","date":"2020-05-30","objectID":"/bit/:3:5","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"原码，反码，补码的应用 ","date":"2020-05-30","objectID":"/bit/:3:6","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"负数的十进制和二进制转换 ","date":"2020-05-30","objectID":"/bit/:4:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"十进制转二进制 方法为: 先转换为二进制 对二进制数求反 再将该二进制数加一 总而言之: 十进制数转换为二进制数求补码即为结果 例子 -32 转换为二进制 第一步：32（10）=00100000（2） 第二步：求反：11011111 第三步：加1:11100000 所以-32（10）=11100000（2） ","date":"2020-05-30","objectID":"/bit/:4:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"二进制转十进制 方法为: 数值为取反 对该二进制加一 转换为10进制 例子 11001000 转换为十进制 第一步（数值位取反）： 10110111 第二步（加一）：10111000 第三步（十进制）：-56 所以11001000（2）=-56（10） ","date":"2020-05-30","objectID":"/bit/:4:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"十进制数求反的规律 下面都是以10进制表示: ","date":"2020-05-30","objectID":"/bit/:5:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"负数求反 负数求反等于其绝对值 -1 如: num = -5 num1 = ~num # 4 ","date":"2020-05-30","objectID":"/bit/:5:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"正数求反 正数求反等于其值 +1 的负数 如: num = 4 num1 = ~num # -5 ","date":"2020-05-30","objectID":"/bit/:5:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"二进制的应用场景 ","date":"2020-05-30","objectID":"/bit/:6:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位操作实现乘除法 数 a 向右移一位，相当于将 a 除以 2；数 a 向左移一位，相当于将 a 乘以 2 a = 2 a \u003e\u003e 1 # ---\u003e 1 a \u003c\u003c 1 # ---\u003e 4 ","date":"2020-05-30","objectID":"/bit/:6:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位操作交换两数 位操作交换两数可以不需要第三个临时变量，虽然普通操作也可以做到，但是没有其效率高 # 普通操作 def swap(a: int, b: int) -\u003e(int,int): a = a + b b = a - b a = a - b return a,b # 位与操作 def swap(a: int, b: int) -\u003e (int, int): \"\"\" 交换两个数 :param a: :param b: :return: \"\"\" a ^= b # a = (a^b) b ^= a # b = b ^ a = b ^ a ^ b a ^= b # a = a ^ b = a ^ a ^ b return a, b ","date":"2020-05-30","objectID":"/bit/:6:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位操作判断奇偶数 只要根据数的最后一位是 0 还是 1 来决定即可，为 0 就是偶数，为 1 就是奇数 if(0 == (a \u0026 1)) { //偶数 } ","date":"2020-05-30","objectID":"/bit/:6:3","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位操作交换符号 交换符号将正数变成负数，负数变成正数 func reversal(a int) int { return ^a + 1 } def reversal(a: int) -\u003e int: \"\"\" 求相反数 :param a: :return: \"\"\" return ~a + 1 正数取反加1，正好变成其对应的负数(补码表示)；负数取反加一，则变为其原码，即正数 ","date":"2020-05-30","objectID":"/bit/:6:4","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位操作求绝对值 正数的绝对值是其本身，负数的绝对值正好可以对其进行取反加一求得，即我们首先判断其符号位（整数右移 31 位得到 0，负数右移 31 位得到 -1,即 0xffffffff），然后根据符号进行相应的操作 def abs(a: int) -\u003e int: i = a \u003e\u003e 31 result = a if i == 0 else ~a + 1 return result 上面的操作可以进行优化，可以将 i == 0 的条件判断语句去掉。我们都知道符号位 i 只有两种情况，即 i = 0 为正，i = -1 为负。对于任何数与 0 异或都会保持不变，与 -1 即 0xffffffff 进行异或就相当于对此数进行取反,因此可以将上面三目元算符转换为((a^i)-i)，即整数时 a 与 0 异或得到本身，再减去 0，负数时与 0xffffffff 异或将 a 进行取反，然后在加上 1，即减去 i(i =-1) def abs(a: int) -\u003e int: \"\"\" 求绝对值 :param a: :return: \"\"\" i = a \u003e\u003e 31 result = (a ^ i) - i return result or func abs(a int) int { i := a \u003e\u003e 31 return (a ^ i) - i } ","date":"2020-05-30","objectID":"/bit/:6:5","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位操作进行高低位交换 给定一个 16 位的无符号整数，将其高 8 位与低 8 位进行交换，求出交换后的值，如 从上面移位操作我们可以知道，只要将无符号数 a»8 即可得到其高 8 位移到低 8 位，高位补 0；将 a « 8 即可将 低 8 位移到高 8 位，低 8 位补 0，然后将 a » 8 和 a«8 进行或操作既可求得交换后的结果 。 unsigned short a = 34520; a = (a \u003e\u003e 8) | (a \u003c\u003c 8); ","date":"2020-05-30","objectID":"/bit/:6:6","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位操作统计二进制中 1 的个数 统计二进制1的个数可以分别获取每个二进制位数，然后再统计其1的个数，此方法效率比较低。 这里介绍另外一种高效的方法，同样以 34520 为例， 我们计算其 a \u0026= (a-1)的结果： 第一次：计算前：1000 0110 1101 1000 计算后：1000 0110 1101 0000 第二次：计算前：1000 0110 1101 0000 计算后：1000 0110 1100 0000 第三次：计算前：1000 0110 1100 0000 计算后：1000 0110 1000 0000 我们发现，每计算一次二进制中就少了一个 1，则我们可以通过下面方法去统计：count = 0 def count_1(a: int) -\u003e int: \"\"\" 计算数值的二进制表示的1的数量 :param a: :return: \"\"\" count = 0 while (a): a = a \u0026 a - 1 count += 1 return count ","date":"2020-05-30","objectID":"/bit/:6:7","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"求和 两数求和 func add(a int, b int) int { for b != 0 { sum := a ^ b carry := (a \u0026 b) \u003c\u003c 1 a = sum b = carry } return a } ","date":"2020-05-30","objectID":"/bit/:6:8","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"比特位计数 给定一个非负整数 num。对于 0 ≤ i ≤ num 范围中的每个数字 i ，计算其二进制数中的 1 的数目并将它们作为数组返回。 示例 1: 输入: 2 输出: [0,1,1] 示例 2: 输入: 5 输出: [0,1,1,2,1,2] def countBits(num: int) -\u003e [int]: result = [0] * (num + 1) for i in range(1, num + 1): result[i] = result[i \u0026 i - 1] + 1 return result func countBits(num int) []int { result := make([]int, num+1) for i := 1; i \u003c num+1 ; i ++ { result[i] = result[i \u0026 (i-1)] + 1 } return result } ","date":"2020-05-30","objectID":"/bit/:6:9","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"常用的特殊的数 0xaaaaaaaa = 10101010101010101010101010101010 (偶数位为1，奇数位为0） 0x55555555 = 1010101010101010101010101010101 (偶数位为0，奇数位为1） 0x33333333 = 110011001100110011001100110011 (1和0每隔两位交替出现) 0xcccccccc = 11001100110011001100110011001100 (0和1每隔两位交替出现) 0x0f0f0f0f = 00001111000011110000111100001111 (1和0每隔四位交替出现) 0xf0f0f0f0 = 11110000111100001111000011110000 (0和1每隔四位交替出现) 0xffffffff = 11111111111111111111111111111111 ","date":"2020-05-30","objectID":"/bit/:7:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"二叉搜索树","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"定义及特点 二叉查找树（英语：Binary Search Tree），也称为 二叉搜索树、有序二叉树（Ordered Binary Tree）或排序二叉树（Sorted Binary Tree），是指一棵空树或者具有下列性质的二叉树： 若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 二叉查找树相比于其他数据结构的优势在于查找、插入的时间复杂度较低。为 O(logn)。二叉查找树是基础性数据结构，用于构建更为抽象的数据结构，如集合、多重集、关联数组等。 二叉查找树的查找过程和次优二叉树类似，通常采取二叉链表作为二叉查找树的存储结构。中序遍历二叉查找树可得到一个关键字的有序序列，一个无序序列可以通过构造一棵二叉查找树变成一个有序序列，构造树的过程即为对无序序列进行查找的过程。每次插入的新的结点都是二叉查找树上新的叶子结点，在进行插入操作时，不必移动其它结点，只需改动某个结点的指针，由空变为非空即可。搜索、插入、删除的复杂度等于树高，期望 O(\\log n)O(logn)，最坏 O(n)O(n)（数列有序，树退化成线性表）。 虽然二叉查找树的最坏效率是 O(n)O(n)，但它支持动态查询，且有很多改进版的二叉查找树可以使树高为 O(\\log n)O(logn)，从而将最坏效率降至 O(\\log n)O(logn)，如 AVL 树、红黑树等。 ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:1:0","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"常用操作 ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:2:0","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"树节点定义: class TreeNode: def __init__(self, val): self.val = val self.left = None self.right = None or type TreeNode struct { Val int Left *TreeNode Right *TreeNode } ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:2:1","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"查找 在二叉搜索树b中查找x的过程为： 若b是空树，则搜索失败，否则： 若x等于b的根节点的数据域之值，则查找成功；否则： 若x小于b的根节点的数据域之值，则递归搜索左子树；否则: 递归查找右子树 ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:2:2","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"插入 向一个二叉搜索树b中插入一个节点s的算法，过程为： 若b是空树，则将s所指结点作为根节点插入，否则： 若s.val等于b的根节点的数据域之值，则返回，否则： 若s.val小于b的根节点的数据域之值，则把s所指节点插入到左子树中，否则： 把s所指节点插入到右子树中（新插入节点总是叶子节点） ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:2:3","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"删除 二叉搜索树的删除操作分三种情况讨论: 如果待删除的节点是叶子节点，那么可以立即被删除，如下图所示： 例：删除数据为16的节点，是叶子节点，可以直接删除 如果有一个子节点，要将下一个子节点上移到当前节点，即替换之 例：删除数据为25的节点，它下面有唯一一个子节点35, 上移到替换之 如果有两个子节点，则将其右子树的最小数据代替此节点的数据，并将其右子树的最小数据删除，如下图所示 例：删除节点数据为5的节点，找到被删除节点右子树的最小节点。需要一个临时变量successor，将11节点下面的子节点进行查询，找到右子树最小节点7，并把右子树最小节点7替换被删除节点，维持二叉树结构。如下图 ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:2:4","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"遍历 可以采用前序，中序，后序来遍历该二叉搜索树，或者使用广度优先搜索的方式。这里用中序遍历来实现，可以保证按从小到大的顺序打印。 ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:2:5","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"构造一颗二叉查找树 用一组数值建造一棵二叉查找树的同时，也把这组数值进行了排序。其最差时间复杂度为 O(n2)。例如，若该组数值经是有序的（从小到大），则建造出来的二叉查找树的所有节点，都没有左子树 ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:2:6","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"常用操作的实现 python版 # 节点定义 class TreeNode: def __init__(self, x): self.val = x self.left = None self.right = None # 查找 def search(root: TreeNode, val: int) -\u003e (bool, TreeNode): if root == None: return False, None elif val \u003e root.val: return search(root.right, val) elif val \u003c root.val: return search(root.left, val) else: return True, root # 插入 def insert(root: TreeNode, node: TreeNode) -\u003e TreeNode: \"\"\"insert inplace\"\"\" if root == None: root = node return root elif node.val \u003e root.val: root.right = insert(root.right, node) else: root.left = insert(root.left, node) return root # 删除 def deleteNode(root: TreeNode, key: int) -\u003e TreeNode: \"\"\" :type root: TreeNode :type key: int :rtype: TreeNode \"\"\" if root == None: return None if key \u003c root.val: root.left = deleteNode(root.left, key) elif key \u003e root.val: root.right = deleteNode(root.right, key) else: if root.left == None: return root.right elif root.right == None: return root.left else: min_node = findMinNode(root.right) root.val = min_node.val root.right = deleteNode(root.right, root.val) return root def findMinNode(node: TreeNode) -\u003e TreeNode: while node.left: node = node.left return node # 中序遍历 def traverse_binary_tree(root: TreeNode): if root is None: return traverse_binary_tree(root.left) print(root.val) traverse_binary_tree(root.right) # 构建二叉树 def build_binary_tree(values: [int]): tree = None for v in values: tree = insert(tree, TreeNode(v)) return tree if __name__ == \"__main__\": values = [17, 5, 35, 2, 11, 29, 38, 9, 16, 7] # 构造二叉树 node = build_binary_tree(values) # 查找 node_7 = search(node, 35) # 遍历 traverse_binary_tree(node) # 删除 a = deleteNode(node, 5) print() golang版: package main import \"fmt\" type TreeNode struct { Val int Left *TreeNode Right *TreeNode } func main() { values := []int{17, 5, 35, 2, 11, 29, 38, 9, 16, 7} // 测试构造二叉树 node := buildBinarySearchTree(values) // 遍历 traverseBinarySearchTree(node) // 搜索 ok, child := search(node, 11) // 删除 new_node := deleteTreenode(node, 35) fmt.Println(new_node) fmt.Println(ok, child) } // 查找 func search(root *TreeNode, val int) (bool, *TreeNode) { if root == nil { return false, nil } if root.Val == val { return true, root } else if root.Val \u003c val { return search(root.Right, val) } else { return search(root.Left, val) } } // 插入 func insert(root, node *TreeNode) *TreeNode { if root == nil { root = node return root } if root.Val \u003e node.Val { root.Left = insert(root.Left, node) } else { root.Right = insert(root.Right, node) } return root } // 删除 func deleteTreenode(root *TreeNode, val int) *TreeNode { if root == nil { return nil } if root.Val \u003e val { root.Left = deleteTreenode(root.Left, val) } else if root.Val \u003c val { root.Right = deleteTreenode(root.Right, val) } else { if root.Left == nil { return root.Right } else if root.Right == nil { return root.Left } else { min_node := findMinNode(root.Right) root.Val = min_node.Val root.Right = deleteTreenode(root.Right, min_node.Val) } } return root } func findMinNode(root *TreeNode) *TreeNode { for root.Left != nil { root = root.Left } return root } // 中序遍历 func traverseBinarySearchTree(root *TreeNode) { if root == nil { return } traverseBinarySearchTree(root.Left) fmt.Println(root.Val) traverseBinarySearchTree(root.Right) } // 构建二叉搜索树 func buildBinarySearchTree(values []int) *TreeNode { var node *TreeNode = nil for _, value := range values { node = insert(node, \u0026TreeNode{Val: value}) } return node } ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:3:0","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"性能分析 查找：最佳情况Olog(n), 最坏情况O(n) 插入：最佳情况Olog(n), 最坏情况O(n) 删除：最佳情况Olog(n), 最坏情况O(n) ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:4:0","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"二叉搜索树","date":"2020-05-05","objectID":"/binarysearchtree/","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"定义及特点 二叉查找树（英语：Binary Search Tree），也称为 二叉搜索树、有序二叉树（Ordered Binary Tree）或排序二叉树（Sorted Binary Tree），是指一棵空树或者具有下列性质的二叉树： 若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 二叉查找树相比于其他数据结构的优势在于查找、插入的时间复杂度较低。为 O(logn)。二叉查找树是基础性数据结构，用于构建更为抽象的数据结构，如集合、多重集、关联数组等。 二叉查找树的查找过程和次优二叉树类似，通常采取二叉链表作为二叉查找树的存储结构。中序遍历二叉查找树可得到一个关键字的有序序列，一个无序序列可以通过构造一棵二叉查找树变成一个有序序列，构造树的过程即为对无序序列进行查找的过程。每次插入的新的结点都是二叉查找树上新的叶子结点，在进行插入操作时，不必移动其它结点，只需改动某个结点的指针，由空变为非空即可。搜索、插入、删除的复杂度等于树高，期望 O(\\log n)O(logn)，最坏 O(n)O(n)（数列有序，树退化成线性表）。 虽然二叉查找树的最坏效率是 O(n)O(n)，但它支持动态查询，且有很多改进版的二叉查找树可以使树高为 O(\\log n)O(logn)，从而将最坏效率降至 O(\\log n)O(logn)，如 AVL 树、红黑树等。 ","date":"2020-05-05","objectID":"/binarysearchtree/:1:0","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"常用操作 ","date":"2020-05-05","objectID":"/binarysearchtree/:2:0","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"树节点定义: class TreeNode: def __init__(self, val): self.val = val self.left = None self.right = None or type TreeNode struct { Val int Left *TreeNode Right *TreeNode } ","date":"2020-05-05","objectID":"/binarysearchtree/:2:1","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"查找 在二叉搜索树b中查找x的过程为： 若b是空树，则搜索失败，否则： 若x等于b的根节点的数据域之值，则查找成功；否则： 若x小于b的根节点的数据域之值，则递归搜索左子树；否则: 递归查找右子树 ","date":"2020-05-05","objectID":"/binarysearchtree/:2:2","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"插入 向一个二叉搜索树b中插入一个节点s的算法，过程为： 若b是空树，则将s所指结点作为根节点插入，否则： 若s.val等于b的根节点的数据域之值，则返回，否则： 若s.val小于b的根节点的数据域之值，则把s所指节点插入到左子树中，否则： 把s所指节点插入到右子树中（新插入节点总是叶子节点） ","date":"2020-05-05","objectID":"/binarysearchtree/:2:3","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"删除 二叉搜索树的删除操作分三种情况讨论: 如果待删除的节点是叶子节点，那么可以立即被删除，如下图所示： 例：删除数据为16的节点，是叶子节点，可以直接删除 如果有一个子节点，要将下一个子节点上移到当前节点，即替换之 例：删除数据为25的节点，它下面有唯一一个子节点35, 上移到替换之 如果有两个子节点，则将其右子树的最小数据代替此节点的数据，并将其右子树的最小数据删除，如下图所示 例：删除节点数据为5的节点，找到被删除节点右子树的最小节点。需要一个临时变量successor，将11节点下面的子节点进行查询，找到右子树最小节点7，并把右子树最小节点7替换被删除节点，维持二叉树结构。如下图 ","date":"2020-05-05","objectID":"/binarysearchtree/:2:4","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"遍历 可以采用前序，中序，后序来遍历该二叉搜索树，或者使用广度优先搜索的方式。这里用中序遍历来实现，可以保证按从小到大的顺序打印。 ","date":"2020-05-05","objectID":"/binarysearchtree/:2:5","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"构造一颗二叉查找树 用一组数值建造一棵二叉查找树的同时，也把这组数值进行了排序。其最差时间复杂度为 O(n2)。例如，若该组数值经是有序的（从小到大），则建造出来的二叉查找树的所有节点，都没有左子树 ","date":"2020-05-05","objectID":"/binarysearchtree/:2:6","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"常用操作的实现 python版 # 节点定义 class TreeNode: def __init__(self, x): self.val = x self.left = None self.right = None # 查找 def search(root: TreeNode, val: int) -\u003e (bool, TreeNode): if root == None: return False, None elif val \u003e root.val: return search(root.right, val) elif val \u003c root.val: return search(root.left, val) else: return True, root # 插入 def insert(root: TreeNode, node: TreeNode) -\u003e TreeNode: \"\"\"insert inplace\"\"\" if root == None: root = node return root elif node.val \u003e root.val: root.right = insert(root.right, node) else: root.left = insert(root.left, node) return root # 删除 def deleteNode(root: TreeNode, key: int) -\u003e TreeNode: \"\"\" :type root: TreeNode :type key: int :rtype: TreeNode \"\"\" if root == None: return None if key \u003c root.val: root.left = deleteNode(root.left, key) elif key \u003e root.val: root.right = deleteNode(root.right, key) else: if root.left == None: return root.right elif root.right == None: return root.left else: min_node = findMinNode(root.right) root.val = min_node.val root.right = deleteNode(root.right, root.val) return root def findMinNode(node: TreeNode) -\u003e TreeNode: while node.left: node = node.left return node # 中序遍历 def traverse_binary_tree(root: TreeNode): if root is None: return traverse_binary_tree(root.left) print(root.val) traverse_binary_tree(root.right) # 构建二叉树 def build_binary_tree(values: [int]): tree = None for v in values: tree = insert(tree, TreeNode(v)) return tree if __name__ == \"__main__\": values = [17, 5, 35, 2, 11, 29, 38, 9, 16, 7] # 构造二叉树 node = build_binary_tree(values) # 查找 node_7 = search(node, 35) # 遍历 traverse_binary_tree(node) # 删除 a = deleteNode(node, 5) print() golang版: package main import \"fmt\" type TreeNode struct { Val int Left *TreeNode Right *TreeNode } func main() { values := []int{17, 5, 35, 2, 11, 29, 38, 9, 16, 7} // 测试构造二叉树 node := buildBinarySearchTree(values) // 遍历 traverseBinarySearchTree(node) // 搜索 ok, child := search(node, 11) // 删除 new_node := deleteTreenode(node, 35) fmt.Println(new_node) fmt.Println(ok, child) } // 查找 func search(root *TreeNode, val int) (bool, *TreeNode) { if root == nil { return false, nil } if root.Val == val { return true, root } else if root.Val \u003c val { return search(root.Right, val) } else { return search(root.Left, val) } } // 插入 func insert(root, node *TreeNode) *TreeNode { if root == nil { root = node return root } if root.Val \u003e node.Val { root.Left = insert(root.Left, node) } else { root.Right = insert(root.Right, node) } return root } // 删除 func deleteTreenode(root *TreeNode, val int) *TreeNode { if root == nil { return nil } if root.Val \u003e val { root.Left = deleteTreenode(root.Left, val) } else if root.Val \u003c val { root.Right = deleteTreenode(root.Right, val) } else { if root.Left == nil { return root.Right } else if root.Right == nil { return root.Left } else { min_node := findMinNode(root.Right) root.Val = min_node.Val root.Right = deleteTreenode(root.Right, min_node.Val) } } return root } func findMinNode(root *TreeNode) *TreeNode { for root.Left != nil { root = root.Left } return root } // 中序遍历 func traverseBinarySearchTree(root *TreeNode) { if root == nil { return } traverseBinarySearchTree(root.Left) fmt.Println(root.Val) traverseBinarySearchTree(root.Right) } // 构建二叉搜索树 func buildBinarySearchTree(values []int) *TreeNode { var node *TreeNode = nil for _, value := range values { node = insert(node, \u0026TreeNode{Val: value}) } return node } ","date":"2020-05-05","objectID":"/binarysearchtree/:3:0","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"性能分析 查找：最佳情况Olog(n), 最坏情况O(n) 插入：最佳情况Olog(n), 最坏情况O(n) 删除：最佳情况Olog(n), 最坏情况O(n) ","date":"2020-05-05","objectID":"/binarysearchtree/:4:0","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"How to run jenkins on kubernetes","date":"2020-02-08","objectID":"/opensrouce/k8s_jenkins/","tags":["kubernetes","jenkins"],"title":"How to run jenkins on kubernetes","uri":"/opensrouce/k8s_jenkins/"},{"categories":null,"content":"作用 如何在Kubernetes环境中运行jenkins ","date":"2020-02-08","objectID":"/opensrouce/k8s_jenkins/:1:0","tags":["kubernetes","jenkins"],"title":"How to run jenkins on kubernetes","uri":"/opensrouce/k8s_jenkins/"},{"categories":null,"content":"项目地址 https://github.com/russellgao/k8s_jenkins ","date":"2020-02-08","objectID":"/opensrouce/k8s_jenkins/:2:0","tags":["kubernetes","jenkins"],"title":"How to run jenkins on kubernetes","uri":"/opensrouce/k8s_jenkins/"},{"categories":null,"content":"参考 https://mp.weixin.qq.com/s/7YFlmcUH5iOB2XOBIZ2_rA ","date":"2020-02-08","objectID":"/opensrouce/k8s_jenkins/:3:0","tags":["kubernetes","jenkins"],"title":"How to run jenkins on kubernetes","uri":"/opensrouce/k8s_jenkins/"},{"categories":null,"content":"在k8s 中运行EKL","date":"2020-01-04","objectID":"/opensrouce/k8s_elk/","tags":["kubernetes","ELK"],"title":"ELK stack on kubernetes","uri":"/opensrouce/k8s_elk/"},{"categories":null,"content":"作用 如何在Kubernetes环境中运行ELK Stack ","date":"2020-01-04","objectID":"/opensrouce/k8s_elk/:1:0","tags":["kubernetes","ELK"],"title":"ELK stack on kubernetes","uri":"/opensrouce/k8s_elk/"},{"categories":null,"content":"项目地址 https://github.com/russellgao/k8s_elk ","date":"2020-01-04","objectID":"/opensrouce/k8s_elk/:2:0","tags":["kubernetes","ELK"],"title":"ELK stack on kubernetes","uri":"/opensrouce/k8s_elk/"},{"categories":null,"content":"用法 manifests Can run in production environment experimental In the experimental stage 使用之前需要修改各个yaml文件的Storage，Service相关的参数，根据实际情况选择合适的介质，修改完之后执行kubectl -f manifests 即可。 详细信息参考 github ","date":"2020-01-04","objectID":"/opensrouce/k8s_elk/:3:0","tags":["kubernetes","ELK"],"title":"ELK stack on kubernetes","uri":"/opensrouce/k8s_elk/"},{"categories":null,"content":"支持的组件 es logstash kibana kafka zookeeper ","date":"2020-01-04","objectID":"/opensrouce/k8s_elk/:4:0","tags":["kubernetes","ELK"],"title":"ELK stack on kubernetes","uri":"/opensrouce/k8s_elk/"},{"categories":null,"content":"More https://mp.weixin.qq.com/s/93_Jf8P69Q0nkw1Ip7MsFQ ","date":"2020-01-04","objectID":"/opensrouce/k8s_elk/:5:0","tags":["kubernetes","ELK"],"title":"ELK stack on kubernetes","uri":"/opensrouce/k8s_elk/"}]