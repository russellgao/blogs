[{"categories":null,"content":"如何利用 golang 操纵 oracle","date":"2020-11-25","objectID":"/golang/oracle-golang/","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/golang/oracle-golang/"},{"categories":null,"content":"导读 这篇文章主要介绍如何利用 golang 操作 oracle 数据库，包括基本的增删改查，本地 oracle 环境搭建，以及如何在 docker 中运行。 oracle client 镜像构建并不容易，花了很长时间去踩坑，文中提供了已经构建好的基础镜像，可以直接使用，这里贡献给大家。 ","date":"2020-11-25","objectID":"/golang/oracle-golang/:1:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/golang/oracle-golang/"},{"categories":null,"content":"本地环境构建 ","date":"2020-11-25","objectID":"/golang/oracle-golang/:2:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/golang/oracle-golang/"},{"categories":null,"content":"安装客户端 oracle 客户端下载页面: https://www.oracle.com/database/technologies/instant-client/downloads.html mac https://www.oracle.com/database/technologies/instant-client/macos-intel-x86-downloads.html 在上面的页面下载之后执行: # 解压 cd ~ unzip instantclient-basic-macos.x64-19.3.0.0.0dbru.zip # 创建link mkdir ~/lib ln -s ~/instantclient_19_3/libclntsh.dylib ~/lib/ 我本地环境环境是 mac ，这个亲测有用。linux 和 windows 只给出了相关参考连接，没有实际操练过。 linux https://www.oracle.com/database/technologies/instant-client/linux-x86-64-downloads.html windows https://www.oracle.com/database/technologies/instant-client/winx64-64-downloads.html ","date":"2020-11-25","objectID":"/golang/oracle-golang/:2:1","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/golang/oracle-golang/"},{"categories":null,"content":"用法 go 操作 oracle 可以使用 github.com/godror/godror ，如 package main import ( \"database/sql\" \"fmt\" _ \"github.com/godror/godror\" \"os\" ) func main() { connString := \"oracle://hd40:xxx@121.196.127.xxx:1521/ylyx?charset=utf8\" db, err := sql.Open(\"godror\", connString) if err != nil { fmt.Println(err) os.Exit(10) } // 注意不要 sql 语句不要使用 ; 号结尾，否则会报错 // dpiStmt_execute: ORA-00911: invalid character sql := \"select * from user_tables \" rows, err1 := db.Query(sql) if err1 != nil { fmt.Println(err1) os.Exit(10) } result, err2 := GetQueryResult(rows) if err2 != nil { fmt.Println(err2) os.Exit(10) } fmt.Println(result) fmt.Println(\"end\") } func GetQueryResult(query *sql.Rows) ([]map[string]string, error) { column, _ := query.Columns() //读出查询出的列字段名 values := make([][]byte, len(column)) //values是每个列的值，这里获取到byte里 scans := make([]interface{}, len(column)) //因为每次查询出来的列是不定长的，用len(column)定住当次查询的长度 for i := range values { //让每一行数据都填充到[][]byte里面 scans[i] = \u0026values[i] } results := []map[string]string{} for query.Next() { //循环，让游标往下移动 if err := query.Scan(scans...); err != nil { //query.Scan查询出来的不定长值放到scans[i] = \u0026values[i],也就是每行都放在values里 fmt.Println(err) return nil, err } row := make(map[string]string) //每行数据 for k, v := range values { //每行数据是放在values里面，现在把它挪到row里 key := column[k] row[key] = string(v) } results = append(results, row) } query.Close() return results, nil } 用法说明 : _ \"github.com/godror/godror\" 这句是说明 sql 的 driver 是 oracle ，如果要操作 mysql ，换成 mysql 的 driver (_ \"github.com/go-sql-driver/mysql\") 即可。 crud 操作还是调用 database/sql 进行完成。 暴露出来给用户的还是 *sql.DB 。查询可以调用 *sql.DB 的 Query 方法，执行其他 sql 则调用 Exec 方法。 ","date":"2020-11-25","objectID":"/golang/oracle-golang/:3:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/golang/oracle-golang/"},{"categories":null,"content":"常见报错 如果报如下错误: (cx_Oracle.DatabaseError) DPI-1047: Cannot locate a 64-bit Oracle Client library: \"dlopen(libclntsh.dylib, 1): image not found\". See https://cx-oracle.readthedocs.io/en/latest/user_guide/installation.html for help 说明oracle的 client 没有正确安装 如果报错如下: (cx_Oracle.DatabaseError) ORA-01017: invalid username/password; logon denied 说明oracle 的用户密码不正确 如果报错如下: dpiStmt_execute: ORA-00911: invalid character 说明 sql 中包含无效字符，请注意如果 sql 中包含 ; 就会报错，需要把 sql 中的 ; trim 掉。我写了个标准化 sql 的方法，可以参考: // 去掉行首和行尾的空白字符 func TrimBlankSpace(s string) string { _s := regexp.MustCompile(\"^\\\\s+\").ReplaceAll([]byte(s), []byte(\"\")) _s = regexp.MustCompile(\"\\\\s+$\").ReplaceAll(_s, []byte(\"\")) return string(_s) } // 去掉 ; 并且全部转为大写字符 func FormatSql(sql string) string { sql = TrimBlankSpace(sql) sql = strings.TrimRight(sql, \";\") return strings.ToUpper(sql) } ","date":"2020-11-25","objectID":"/golang/oracle-golang/:4:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/golang/oracle-golang/"},{"categories":null,"content":"docker 中运行 我尝试过用 alpine 做基础镜像，然后进行安装 oracle client，把 oracle client 安装完成之后，运行编译完的 golang 程序， 出现了各种缺少动态库的问题，查了很多资料，和 apline 的官方源都彻底没有解决，然后就准备在 dockerhub 找一个现成的拿过来参考， 很遗憾没有找到一个可以直接用的，最后放弃了 alpine 这条路，选择 alpine 是因为 alpine 镜像比较小，这样做出来的镜像比较小。 看了 oracle client 官方下载和安装说明，也都是 centos 的版本，所以就基于 centos 做了一个包含 oracle client 的基础镜像。 已经上传到 dockerhub 了，参见: https://hub.docker.com/r/russellgao/oracle 如果你刚好需要，而我刚好有，那不妨试用一下（如果能帮到您可以给个 star 哟）。 dockerhub 可能访问比较慢，或者可能会出现无法访问的情况，这里贴一些关键信息。 ","date":"2020-11-25","objectID":"/golang/oracle-golang/:5:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/golang/oracle-golang/"},{"categories":null,"content":"镜像说明 镜像名称 russellgao/oracle:centos7-client12.2 操作系统 centos:centos7.9.2009 oracle client 版本 oracle-instantclient12.2-basic-12.2.0.1.0-1.x86_64 基于基础镜像优化的部分 调整时区为 CST 时区 （UTC +8） 镜像用法 这个一般用作基础镜像 或者: docker run -it --rm russellgao/oracle:centos7-client12.2 date or docker run -d russellgao/oracle:centos7-client12.2 tail -f /dev/null ","date":"2020-11-25","objectID":"/golang/oracle-golang/:5:1","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/golang/oracle-golang/"},{"categories":null,"content":"如何利用 golang 操纵 oracle","date":"2020-11-25","objectID":"/oracle-golang/","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/oracle-golang/"},{"categories":null,"content":"导读 这篇文章主要介绍如何利用 golang 操作 oracle 数据库，包括基本的增删改查，本地 oracle 环境搭建，以及如何在 docker 中运行。 oracle client 镜像构建并不容易，花了很长时间去踩坑，文中提供了已经构建好的基础镜像，可以直接使用，这里贡献给大家。 ","date":"2020-11-25","objectID":"/oracle-golang/:1:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/oracle-golang/"},{"categories":null,"content":"本地环境构建 ","date":"2020-11-25","objectID":"/oracle-golang/:2:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/oracle-golang/"},{"categories":null,"content":"安装客户端 oracle 客户端下载页面: https://www.oracle.com/database/technologies/instant-client/downloads.html mac https://www.oracle.com/database/technologies/instant-client/macos-intel-x86-downloads.html 在上面的页面下载之后执行: # 解压 cd ~ unzip instantclient-basic-macos.x64-19.3.0.0.0dbru.zip # 创建link mkdir ~/lib ln -s ~/instantclient_19_3/libclntsh.dylib ~/lib/ 我本地环境环境是 mac ，这个亲测有用。linux 和 windows 只给出了相关参考连接，没有实际操练过。 linux https://www.oracle.com/database/technologies/instant-client/linux-x86-64-downloads.html windows https://www.oracle.com/database/technologies/instant-client/winx64-64-downloads.html ","date":"2020-11-25","objectID":"/oracle-golang/:2:1","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/oracle-golang/"},{"categories":null,"content":"用法 go 操作 oracle 可以使用 github.com/godror/godror ，如 package main import ( \"database/sql\" \"fmt\" _ \"github.com/godror/godror\" \"os\" ) func main() { connString := \"oracle://hd40:xxx@121.196.127.xxx:1521/ylyx?charset=utf8\" db, err := sql.Open(\"godror\", connString) if err != nil { fmt.Println(err) os.Exit(10) } // 注意不要 sql 语句不要使用 ; 号结尾，否则会报错 // dpiStmt_execute: ORA-00911: invalid character sql := \"select * from user_tables \" rows, err1 := db.Query(sql) if err1 != nil { fmt.Println(err1) os.Exit(10) } result, err2 := GetQueryResult(rows) if err2 != nil { fmt.Println(err2) os.Exit(10) } fmt.Println(result) fmt.Println(\"end\") } func GetQueryResult(query *sql.Rows) ([]map[string]string, error) { column, _ := query.Columns() //读出查询出的列字段名 values := make([][]byte, len(column)) //values是每个列的值，这里获取到byte里 scans := make([]interface{}, len(column)) //因为每次查询出来的列是不定长的，用len(column)定住当次查询的长度 for i := range values { //让每一行数据都填充到[][]byte里面 scans[i] = \u0026values[i] } results := []map[string]string{} for query.Next() { //循环，让游标往下移动 if err := query.Scan(scans...); err != nil { //query.Scan查询出来的不定长值放到scans[i] = \u0026values[i],也就是每行都放在values里 fmt.Println(err) return nil, err } row := make(map[string]string) //每行数据 for k, v := range values { //每行数据是放在values里面，现在把它挪到row里 key := column[k] row[key] = string(v) } results = append(results, row) } query.Close() return results, nil } 用法说明 : _ \"github.com/godror/godror\" 这句是说明 sql 的 driver 是 oracle ，如果要操作 mysql ，换成 mysql 的 driver (_ \"github.com/go-sql-driver/mysql\") 即可。 crud 操作还是调用 database/sql 进行完成。 暴露出来给用户的还是 *sql.DB 。查询可以调用 *sql.DB 的 Query 方法，执行其他 sql 则调用 Exec 方法。 ","date":"2020-11-25","objectID":"/oracle-golang/:3:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/oracle-golang/"},{"categories":null,"content":"常见报错 如果报如下错误: (cx_Oracle.DatabaseError) DPI-1047: Cannot locate a 64-bit Oracle Client library: \"dlopen(libclntsh.dylib, 1): image not found\". See https://cx-oracle.readthedocs.io/en/latest/user_guide/installation.html for help 说明oracle的 client 没有正确安装 如果报错如下: (cx_Oracle.DatabaseError) ORA-01017: invalid username/password; logon denied 说明oracle 的用户密码不正确 如果报错如下: dpiStmt_execute: ORA-00911: invalid character 说明 sql 中包含无效字符，请注意如果 sql 中包含 ; 就会报错，需要把 sql 中的 ; trim 掉。我写了个标准化 sql 的方法，可以参考: // 去掉行首和行尾的空白字符 func TrimBlankSpace(s string) string { _s := regexp.MustCompile(\"^\\\\s+\").ReplaceAll([]byte(s), []byte(\"\")) _s = regexp.MustCompile(\"\\\\s+$\").ReplaceAll(_s, []byte(\"\")) return string(_s) } // 去掉 ; 并且全部转为大写字符 func FormatSql(sql string) string { sql = TrimBlankSpace(sql) sql = strings.TrimRight(sql, \";\") return strings.ToUpper(sql) } ","date":"2020-11-25","objectID":"/oracle-golang/:4:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/oracle-golang/"},{"categories":null,"content":"docker 中运行 我尝试过用 alpine 做基础镜像，然后进行安装 oracle client，把 oracle client 安装完成之后，运行编译完的 golang 程序， 出现了各种缺少动态库的问题，查了很多资料，和 apline 的官方源都彻底没有解决，然后就准备在 dockerhub 找一个现成的拿过来参考， 很遗憾没有找到一个可以直接用的，最后放弃了 alpine 这条路，选择 alpine 是因为 alpine 镜像比较小，这样做出来的镜像比较小。 看了 oracle client 官方下载和安装说明，也都是 centos 的版本，所以就基于 centos 做了一个包含 oracle client 的基础镜像。 已经上传到 dockerhub 了，参见: https://hub.docker.com/r/russellgao/oracle 如果你刚好需要，而我刚好有，那不妨试用一下（如果能帮到您可以给个 star 哟）。 dockerhub 可能访问比较慢，或者可能会出现无法访问的情况，这里贴一些关键信息。 ","date":"2020-11-25","objectID":"/oracle-golang/:5:0","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/oracle-golang/"},{"categories":null,"content":"镜像说明 镜像名称 russellgao/oracle:centos7-client12.2 操作系统 centos:centos7.9.2009 oracle client 版本 oracle-instantclient12.2-basic-12.2.0.1.0-1.x86_64 基于基础镜像优化的部分 调整时区为 CST 时区 （UTC +8） 镜像用法 这个一般用作基础镜像 或者: docker run -it --rm russellgao/oracle:centos7-client12.2 date or docker run -d russellgao/oracle:centos7-client12.2 tail -f /dev/null ","date":"2020-11-25","objectID":"/oracle-golang/:5:1","tags":["golang","oracle","数据库"],"title":"如何利用 golang 操纵 oracle","uri":"/oracle-golang/"},{"categories":null,"content":"openresty 配置文件 （二）","date":"2020-11-23","objectID":"/openresty-server/","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"导读 这篇是继上一篇 openresty 配置文件 （一） 介绍了 openresty 全局配置之后，介绍 openresty server 配置，server 的配置一般单独放在 conf.d 目录下。下面是我比较推荐的 conf.d 目录结构： [root@iZuf685opgs9oyozju9i2bZ conf.d]# tree . ├── 443.conf ├── 8080.conf ├── 80.conf └── upstream.conf 0 directories, 4 files upstream 放在单独的 配置文件，当然如果比较多，可以按照 service/product 的维度再进行拆分。不同的监听放在单独的配置文件，相对来说比较好维护一点，也更容易自动化程序处理。 这篇文章比较长，可以通过目录直接跳转到自己感兴趣的部分。 ","date":"2020-11-23","objectID":"/openresty-server/:1:0","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"server server 模块是位于 http 模块下面，进行端口监听，并把请求转发到 upstream 或者直接响应，先看它的配置是什么样子。 server { #配置监听端口 # listen 详细配置参考 listen 一节 listen 80; #配置访问域名，可以只有一个名称，也可以由多个名称并列，之间用空格隔开。每个名字就是一个域名，由两段或者三段组成，之间由点号“.”隔开 # 第一个名称作为此虚拟主机的主要名称 # server_name 更加详细的用法参考下面 server_name 一节 server_name russellgao.cn russellgao.com localhost 127.0.0.1; # log 在全局变量中已经配置，但是每个监听中也可以配置，这样做的好处，在分析日志时比较方便，通过日志就可以知道请求从哪个监听中进来的 # 也可以放在具体的 location 中。 access_log /usr/local/openresty/nginx/logs/access.log custom; error_log /usr/local/openresty/nginx/logs/error.log; # ssl 配置 ssl on; ssl_certificate /usr/local/openresty/nginx/ssl/4753767.pem; ssl_certificate_key /usr/local/openresty/nginx/ssl/4753767.key; ssl_session_timeout 5m; ssl_protocols SSLv2 SSLv3 TLSv1 TLSv1.2 TLSv1.1; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; # location 配置，location 介绍参考下面详细介绍 location / { root /usr/local/openresty/nginx/docs; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/local/openresty/nginx/html; } error_page 404 /404.html; location = /404.html { root /usr/local/openresty/nginx/docs; } } 一个 server 只能监听一个端口。 ","date":"2020-11-23","objectID":"/openresty-server/:2:0","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"listen listen 有三种配置语法。这个指令默认的配置值是：listen *:80 | *:8000；只能在server块种配置这个指令。 //第一种 listen address[:port] [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; //第二种 listen port [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; //第三种（可以不用重点关注） listen unix:path [default_server] [ssl] [http2 | spdy] [proxy_protocol] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; listen指令的配置非常灵活，可以单独制定ip，单独指定端口或者同时指定ip和端口。 关于上面的一些重要参数做如下说明： address：监听的IP地址（请求来源的IP地址），如果是IPv6的地址，需要使用中括号“[]”括起来，比如[fe80::1]等。 port：端口号，如果只定义了IP地址没有定义端口号，就使用80端口。这边需要做个说明：要是你压根没配置listen指令，那么那么如果nginx以超级用户权限运行，则使用*:80，否则使用*:8000。多个虚拟主机可以同时监听同一个端口,但是server_name需要设置成不一样； default_server：假如通过Host没匹配到对应的虚拟主机，则通过这台虚拟主机处理。 backlog=number：设置监听函数listen()最多允许多少网络连接同时处于挂起状态，在FreeBSD中默认为-1，其他平台默认为511。 accept_filter=filter，设置监听端口对请求的过滤，被过滤的内容不能被接收和处理。本指令只在FreeBSD和NetBSD 5.0+平台下有效。filter可以设置为dataready或httpready，感兴趣的读者可以参阅Nginx的官方文档。 bind：标识符，使用独立的bind()处理此address:port；一般情况下，对于端口相同而IP地址不同的多个连接，Nginx服务器将只使用一个监听命令，并使用bind()处理端口相同的所有连接。 ssl：标识符，设置会话连接使用SSL模式进行，此标识符和Nginx服务器提供的HTTPS服务有关。 ","date":"2020-11-23","objectID":"/openresty-server/:2:1","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"server_name 用于配置虚拟主机的名称。语法是： Syntax: server_name name ...; Default: server_name \"\"; Context: server 对于name 来说，可以只有一个名称，也可以由多个名称并列，之间用空格隔开。每个名字就是一个域名，由两段或者三段组成，之间由点号“.”隔开。比如 server_name myserver.com www.myserver.com 在该例中，此虚拟主机的名称设置为myserver.com或www. myserver.com。Nginx服务器规定，第一个名称作为此虚拟主机的主要名称。 在name 中可以使用通配符“*”，但通配符只能用在由三段字符串组成的名称的首段或尾段，或者由两段字符串组成的名称的尾段，如： server_name myserver.* *.myserver.com 另外name还支持正则表达式的形式 由于server_name指令支持使用通配符和正则表达式两种配置名称的方式，因此在包含有多个虚拟主机的配置文件中，可能会出现一个名称被多个虚拟主机的server_name匹配成功。那么，来自这个名称的请求到底要交给哪个虚拟主机处理呢？Nginx服务器做出如下规定： a. 对于匹配方式不同的，按照以下的优先级选择虚拟主机，排在前面的优先处理请求。 准确匹配server_name 通配符在开始时匹配server_name成功 通配符在结尾时匹配server_name成功 正则表达式匹配server_name成功 b. 在以上四种匹配方式中，如果server_name被处于同一优先级的匹配方式多次匹配成功，则首次匹配成功的虚拟主机处理请求。 ","date":"2020-11-23","objectID":"/openresty-server/:2:2","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"location ","date":"2020-11-23","objectID":"/openresty-server/:3:0","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"基本语法 location [=|~|~*|^~] /uri/ { ... } = : 表示精确匹配后面的url ~ : 表示正则匹配，但是区分大小写 ~* : 正则匹配，不区分大小写 ^~ : 如果把这个前缀用于一个常规字符串,那么告诉nginx 如果路径匹配那么不测试正则表达式 「=」 修饰符：要求路径完全匹配 server { server_name russellgao.cn; location = /abcd { […] } } https://russellgao.cn/abcd匹配 https://russellgao.cn/ABCD可能会匹配 ，也可以不匹配，取决于操作系统的文件系统是否大小写敏感（case-sensitive）。 https://russellgao.cn/abcd?param1\u0026param2匹配，忽略 querystring https://russellgao.cn/abcd/不匹配，带有结尾的/ https://russellgao.cn/abcde不匹配 「~」修饰符：区分大小写的正则匹配 server { server_name russellgao.cn; location ~ ^/abcd$ { […] } } ^/abcd$ 这个正则表达式表示字符串必须以/开始，以d结束，中间必须是abc，换言之只能匹配 /abcd https://russellgao.cn/abcd匹配（完全匹配） https://russellgao.cn/ABCD不匹配，大小写敏感 https://russellgao.cn/abcd?param1\u0026param2匹配 https://russellgao.cn/abcd/不匹配，不能匹配正则表达式 https://russellgao.cn/abcde不匹配，不能匹配正则表达式 「~*」不区分大小写的正则匹配 server { server_name russellgao.cn; location ~* ^/abcd$ { […] } } https://russellgao.cn/abcd匹配 (完全匹配) https://russellgao.cn/ABCD匹配 (大小写不敏感) https://russellgao.cn/abcd?param1\u0026param2匹配 https://russellgao.cn/abcd/ 不匹配，不能匹配正则表达式 https://russellgao.cn/abcde 不匹配，不能匹配正则表达式 「^~」修饰符 前缀匹配 如果该 location 是最佳的匹配，那么对于匹配这个 location 的字符串， 该修饰符不再进行正则表达式检测。注意，这不是一个正则表达式匹配，它的目的是优先于正则表达式的匹配。 ","date":"2020-11-23","objectID":"/openresty-server/:3:1","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"查找的顺序及优先级 当有多条 location 规则时，nginx 有一套比较复杂的规则，优先级如下： 精确匹配 = 前缀匹配 ^~（立刻停止后续的正则搜索） 按文件中顺序的正则匹配 ~或~* 匹配不带任何修饰的前缀匹配。 这个规则大体的思路是: 先精确匹配，没有则查找带有 ^~的前缀匹配，没有则进行正则匹配，最后才返回前缀匹配的结果（如果有的话） ","date":"2020-11-23","objectID":"/openresty-server/:3:2","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"alias 与 root 区别 root 实际访问文件路径会拼接URL中的路径 alias 实际访问文件路径不会拼接URL中的路径 看一个例子 location ^~ /sta/ { alias /usr/local/nginx/html/static/; } 请求：https://russellgao.cn/sta/index.html 实际访问：/usr/local/nginx/html/static/index.html 文件 location ^~ /static/ { root /usr/local/nginx/html/; } 请求：https://russellgao.cn/static/index.html 实际访问：/usr/local/nginx/html/static/index.html 文件 ","date":"2020-11-23","objectID":"/openresty-server/:3:3","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"rewrite rewrite 模块主要用于重定向。 指令语法：rewrite regex replacement[flag]; ，默认值为 none 。 看个简单例子 : location / { rewrite ^/(.*) https://russellgao.cn/$1 permanent; } 这是我 http 强转 https 的例子。 ","date":"2020-11-23","objectID":"/openresty-server/:3:4","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"常用正则表达式 字符 描述 \\ 将后面接着的字符标记为一个特殊字符或者一个原义字符或一个向后引用 ^ 匹配输入字符串的起始位置 $ 匹配输入字符串的结束位置 * 匹配前面的字符零次或者多次 + 匹配前面字符串一次或者多次 ? 匹配前面字符串的零次或者一次 . 匹配除“\\n”之外的所有单个字符 (pattern) 匹配括号内的pattern ","date":"2020-11-23","objectID":"/openresty-server/:3:5","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"flag参数 标记符号 说明 last 本条规则匹配完成后继续向下匹配新的location URI规则 break 本条规则匹配完成后终止，不在匹配任何规则 redirect 返回302临时重定向 permanent 返回301永久重定向 last 和 break关键字的区别 last 匹配到了还会继续向下匹配 break 匹配到了不会继续向下匹配，会终止掉 permanent 和 redirect关键字的区别 last 和 break 当出现在location 之外时，两者的作用是一致的没有任何差异 last 和 break 当出现在location 内部时： rewrite … permanent 永久性重定向，请求日志中的状态码为301 rewrite … redirect 临时重定向，请求日志中的状态码为302 ","date":"2020-11-23","objectID":"/openresty-server/:3:6","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"proxy_pass 在nginx中配置proxy_pass代理转发时，如果在proxy_pass后面的url加/，表示绝对根路径；如果没有/，表示相对路径，把匹配的路径部分也给代理走。 假设我们访问地址为 : https://russellgao.cn/proxypass/index.html 当配置为 location /proxypass/ { proxy_pass https://russellgao.cn/; } 代理到: https://russellgao.cn/index.html 当配置为 location /proxypass/ { proxy_pass https://russellgao.cn; } 代理到: https://russellgao.cn/proxypass/index.html 请注意：proxy_pass 最后没有 / 当配置为 location /proxypass/ { proxy_pass https://russellgao.cn/test/; } 代理到: https://russellgao.cn/test/index.html 当配置为 location /proxypass/ { proxy_pass https://russellgao.cn/test; } 代理到: https://russellgao.cn/testindex.html nginx 的 ngx_http_proxy_module 和 ngx_stream_proxy_module 模块都有 proxy_pass ，下面看看两者之间的关系与区别。 ngx_http_proxy_module 语法: proxy_pass URL 场景: location if in location limit_except 设置后端代理服务器的协议(protocol)和地址(address),以及location中可以匹配的一个可选的URI。协议可以是\"http\"或\"https”。地址可以是一个域名或ip地址和端口，或者一个 unix-domain socket 路径。 例: location ~* (/api/v1/blog-server) { proxy_pass_header Server; proxy_pass http://blog_server; } ngx_stream_proxy_module 语法: proxy_pass address; 场景: server 设置后端代理服务器的地址。这个地址(address)可以是一个域名或ip地址和端口，或者一个 unix-domain socket路径。 例: server { listen 127.0.0.1:12345; proxy_pass 127.0.0.1:8080; } 在两个模块中，两个proxy_pass都是用来做后端代理的指令。 ngx_stream_proxy_module模块的proxy_pass指令只能在server段使用使用, 只需要提供域名或ip地址和端口。可以理解为端口转发，可以是tcp端口，也可以是udp端口。 ngx_http_proxy_module模块的proxy_pass指令需要在location段，location中的if段，limit_except段中使用，处理需要提供域名或ip地址和端口外，还需要提供协议，如\"http\"或\"https”，还有一个可选的uri可以配置。 ","date":"2020-11-23","objectID":"/openresty-server/:3:7","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"常见 location 配置样例 静态网站 server { listen 80; server_name russellgao.cn; access_log /usr/local/openresty/nginx/logs/access.log custom; error_log /usr/local/openresty/nginx/logs/error.log; location / { rewrite ^/(.*) https://russellgao.cn/$1 permanent; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/local/openresty/nginx/html; } error_page 404 /404.html; location = /404.html { root /usr/local/openresty/nginx/blog; } } 反向代理 location ~* (/api/v1/blog-server) { access_log /var/nginx/logs/blog_access.log custom; error_log /var/nginx/logs/blog_error.log error; proxy_pass_header Server; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; # rewrite 只是举个例子，根据实际情况配置 # rewrite /api/v1/blog-server/(.*)$ /api/$1 break; proxy_pass http://blog_server; } 可以在 location 级别设置日志格式以及目录，方便精细化管理 通过proxy_pass 跳转到 upstream ","date":"2020-11-23","objectID":"/openresty-server/:3:8","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"upstream upstream 是后端服务器组，也称为虚拟服务器组，作用是负载均衡。配置样例参考 upstream blog_server { #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 server 172.19.208.76:80 weight=10; server 172.19.208.77:80 weight=50; server 172.19.208.78:80 weight=40; } nginx的upstream目前支持 5 种方式的分配: 轮询（默认）：每个请求按时间顺序逐一分配到不同的后端服务。如: upstream server { server 172.19.208.76:80; server 172.19.208.77:80; server 172.19.208.78:80; } 权重 ：指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 upstream server { server 172.19.208.76:80 weight=10; server 172.19.208.77:80 weight=50; server 172.19.208.78:80 weight=40; } ip_hash：每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 upstream server { ip_hash; server 172.19.208.76:80; server 172.19.208.77:80; server 172.19.208.78:80; } fair：按后端服务器的响应时间来分配请求，响应时间短的优先分配。 upstream server { fair; server 172.19.208.76:80; server 172.19.208.77:80; server 172.19.208.78:80; } url_hash：按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法。如: upstream server { hash $request_uri; hash_method crc32; server 172.19.208.76:80; server 172.19.208.77:80; server 172.19.208.78:80; } 在 upstream 中可以给 server 设置状态，如: upstream server { server 172.19.208.76:80 down; server 172.19.208.77:80 weight=10; server 172.19.208.78:80 backup; } 支持的状态有: down表示单前的server暂时不参与负载 weight为weight越大，负载的权重就越大。 max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误 fail_timeout:max_fails次失败后，暂停的时间。 backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。 ","date":"2020-11-23","objectID":"/openresty-server/:4:0","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"参考 https://www.cnblogs.com/54chensongxia/p/12938929.html https://juejin.cn/post/6844903849166110733 ","date":"2020-11-23","objectID":"/openresty-server/:5:0","tags":["nginx","openresty","server","location"],"title":"openresty 配置文件 （二）","uri":"/openresty-server/"},{"categories":null,"content":"openresty 配置文件 （一）","date":"2020-11-22","objectID":"/openresty-nginx.conf/","tags":["nginx","openresty","nginx.conf"],"title":"openresty 配置文件 （一）","uri":"/openresty-nginx.conf/"},{"categories":null,"content":"导读 openresty（nginx plus） 在日常工作中用的应该比较多，要想真正了解清楚其原理并不容易。我尝试着从配置的角度去分析 nginx 的基本原理。这篇主要介绍 nginx.conf 这个配置文件，后续再介绍其他的配置文件。 nginx.conf 中主要配置全局配置，配置好之后一般很少改动。 ","date":"2020-11-22","objectID":"/openresty-nginx.conf/:1:0","tags":["nginx","openresty","nginx.conf"],"title":"openresty 配置文件 （一）","uri":"/openresty-nginx.conf/"},{"categories":null,"content":"nginx.conf 配置项说明 #定义Nginx运行的用户和用户组 #user nobody; #nginx进程数，建议设置为等于CPU总核心数。 worker_processes 1; #全局错误日志定义类型，[ debug | info | notice | warn | error | crit ] #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #进程文件 #pid logs/nginx.pid; #指定进程可以打开的最大描述符 #工作模式与连接数上限 ##这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。 #这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。 worker_rlimit_nofile 65535; events { #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型 #是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。 #补充说明： #与apache相类，nginx针对不同的操作系统，有不同的事件模型 #A）标准事件模型 #Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll #B）高效事件模型 #Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。 #Epoll：使用于Linux内核2.6版本及以后的系统。 #/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。 #Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。 use epoll #单个进程最大连接数（最大连接数=连接数+进程数） worker_connections 65535; #keepalive 超时时间 keepalive_timeout 60; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。 #分页大小可以用命令getconf PAGESIZE 取得。 #[root@web001 ~]# getconf PAGESIZE #但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。 client_header_buffer_size 4k; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。 open_file_cache max=65535 inactive=60s; #这个是指多长时间检查一次缓存的有效信息。 #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息. open_file_cache_valid 80s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。 #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location 这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态. open_file_cache_min_uses 1; #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误. open_file_cache_errors on; #默认是on。设置为on后，多个worker按串行方式来处理连接，也就是一个连接只有一个worker被唤醒，其他的处于休眠状态。 #设置为off后，多个worker按并行方式来处理连接，也就是一个连接会唤醒所有的worker，知道连接分配完毕，没有取得连接的继续休眠。 #当你的服务器连接数不多时，开启这个参数会让负载有一定程度的降低。但是当服务器的吞吐量很大时，为了效率，请关闭这个参数。 multi_accept off; } #设定http服务器 http { #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; # 增加 header add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods \"GET, POST, OPTIONS\"; #默认编码 charset utf-8; #服务器名字的hash表大小 #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小. server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。 client_header_buffer_size 32k; #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。 large_client_header_buffers 4 64k; #设定通过nginx上传文件的大小 client_max_body_size 8m; #开启目录列表访问，合适下载服务器，默认关闭。 autoindex on; # 限流 limit_req_zone $server_name zone=xiaozhi_log:50m rate=40r/s; limit_req_zone $server_name zone=tico_log:50m rate=40r/s; #开启限制IP连接数的时候需要使用 #limit_zone crawler $binary_remote_addr 10m; # 日志格式定义，这里可以根据自己的日志规范进行自定义 #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; # 这里推荐一个日志格式 log_format custom '[$time_local] $remote_addr $remote_user $request ' '$status $upstream_response_time $request_time $body_bytes_sent $http_referer ' '$http_user_agent $http_x_forwarded_for ' ; #access_log logs/access.log main; #开启高效文件传输模式，sendfil","date":"2020-11-22","objectID":"/openresty-nginx.conf/:2:0","tags":["nginx","openresty","nginx.conf"],"title":"openresty 配置文件 （一）","uri":"/openresty-nginx.conf/"},{"categories":null,"content":"nginx.conf 样例 worker_processes 2; events { worker_connections 65535; } http { include mime.types; default_type application/octet-stream; log_format custom '[$time_local] $remote_addr $remote_user $request ' '$status $upstream_response_time $request_time $body_bytes_sent $http_referer ' '$http_user_agent $http_x_forwarded_for ' ; client_body_temp_path /var/run/openresty/nginx-client-body; proxy_temp_path /var/run/openresty/nginx-proxy; fastcgi_temp_path /var/run/openresty/nginx-fastcgi; uwsgi_temp_path /var/run/openresty/nginx-uwsgi; scgi_temp_path /var/run/openresty/nginx-scgi; sendfile on; keepalive_timeout 90; include /etc/nginx/conf.d/*.conf; } ","date":"2020-11-22","objectID":"/openresty-nginx.conf/:3:0","tags":["nginx","openresty","nginx.conf"],"title":"openresty 配置文件 （一）","uri":"/openresty-nginx.conf/"},{"categories":null,"content":"接下来 这是 openresty 配置文件系列篇，这篇介绍了 nginx.conf (全局配置) ，接下来还有 server 、 upstream、location 等介绍。 每天掌握一个知识点，积少成多，一周玩转 openresty 。 ","date":"2020-11-22","objectID":"/openresty-nginx.conf/:4:0","tags":["nginx","openresty","nginx.conf"],"title":"openresty 配置文件 （一）","uri":"/openresty-nginx.conf/"},{"categories":null,"content":"参考 https://juejin.cn/post/6844903741678698510 ","date":"2020-11-22","objectID":"/openresty-nginx.conf/:5:0","tags":["nginx","openresty","nginx.conf"],"title":"openresty 配置文件 （一）","uri":"/openresty-nginx.conf/"},{"categories":null,"content":"kubernetes 中patch与update比较","date":"2020-11-21","objectID":"/kubernetes/patch-update/","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"导读 不知道你有没有想过一个问题：对于一个 K8s 资源对象比如 Deployment，我们尝试在修改其中 image 镜像时，如果有其他人同时也在对这个 Deployment 做修改，会发生什么？ 当然，这里还可以引申出两个问题： 如果双方修改的是同一个字段，比如 image 字段，结果会怎样？ 如果双方修改的是不同字段，比如一个修改 image，另一个修改 replicas，又会怎么样？ 其实，对一个 Kubernetes 资源对象做“更新”操作，简单来说就是通知 kube-apiserver 组件我们希望如何修改这个对象。而 K8s 为这类需求定义了两种“通知”方式，分别是 update 和 patch。在 update 请求中，我们需要将整个修改后的对象提交给 K8s；而对于 patch 请求，我们只需要将对象中某些字段的修改提交给 K8s。 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:1:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"Update 机制 Kubernetes 中的所有资源对象，都有一个全局唯一的版本号（metadata.resourceVersion）。每个资源对象从创建开始就会有一个版本号，而后每次被修改（不管是 update 还是 patch 修改），版本号都会发生变化。 官方文档 告诉我们，这个版本号是一个 K8s 的内部机制，用户不应该假设它是一个数字或者通过比较两个版本号大小来确定资源对象的新旧，唯一能做的就是通过比较版本号相等来确定对象是否是同一个版本（即是否发生了变化）。而 resourceVersion 一个重要的用处，就是来做 update 请求的版本控制。 K8s 要求用户 update 请求中提交的对象必须带有 resourceVersion，也就是说我们提交 update 的数据必须先来源于 K8s 中已经存在的对象。因此，一次完整的 update 操作流程是： 首先，从 K8s 中拿到一个已经存在的对象（可以选择直接从 K8s 中查询；如果在客户端做了 list watch，推荐从本地 informer 中获取）； 然后，基于这个取出来的对象做一些修改，比如将 Deployment 中的 replicas 做增减，或是将 image 字段修改为一个新版本的镜像； 最后，将修改后的对象通过 update 请求提交给 K8s； 此时，kube-apiserver 会校验用户 update 请求提交对象中的 resourceVersion 一定要和当前 K8s 中这个对象最新的 resourceVersion 一致，才能接受本次 update。否则，K8s 会拒绝请求，并告诉用户发生了版本冲突（Conflict）。 上图展示了多个用户同时 update 某一个资源对象时会发生的事情。而如果如果发生了 Conflict 冲突，对于 User A 而言应该做的就是做一次重试，再次获取到最新版本的对象，修改后重新提交 update。 因此，我们上面的两个问题也都得到了解答： 用户修改 YAML 后提交 update 失败，是因为 YAML 文件中没有包含 resourceVersion 字段。对于 update 请求而言，应该取出当前 K8s 中的对象做修改后提交； 如果两个用户同时对一个资源对象做 update，不管操作的是对象中同一个字段还是不同字段，都存在版本控制的机制确保两个用户的 update 请求不会发生覆盖。 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:2:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"Patch 机制 相比于 update 的版本控制，K8s 的 patch 机制则显得更加简单。 当用户对某个资源对象提交一个 patch 请求时，kube-apiserver 不会考虑版本问题，而是“无脑”地接受用户的请求（只要请求发送的 patch 内容合法），也就是将 patch 打到对象上、同时更新版本号。 不过，patch 的复杂点在于，目前 K8s 提供了 4 种 patch 策略：json patch、merge patch、strategic merge patch、apply patch（从 K8s 1.14 支持 server-side apply 开始）。通过 kubectl patch -h 命令我们也可以看到这个策略选项（默认采用 strategic）： $ kubectl patch -h # ... --type='strategic': The type of patch being provided; one of [json merge strategic] 篇幅限制这里暂不对每个策略做详细的介绍了，我们就以一个简单的例子来看一下它们的差异性。如果针对一个已有的 Deployment 对象，假设 template 中已经有了一个名为 app 的容器： 如果要在其中新增一个 nginx 容器，如何 patch 更新？ 如果要修改 app 容器的镜像，如何 patch 更新？ ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:3:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"json patch 新增容器： kubectl patch deployment/foo --type='json' -p \\ '[{\"op\":\"add\",\"path\":\"/spec/template/spec/containers/1\",\"value\":{\"name\":\"nginx\",\"image\":\"nginx:alpine\"}}]' 修改已有容器 image： kubectl patch deployment/foo --type='json' -p \\ '[{\"op\":\"replace\",\"path\":\"/spec/template/spec/containers/0/image\",\"value\":\"app-image:v2\"}]' 这样一来，如果我们 patch 之前这个对象已经被其他人修改了，那么我们的 patch 有可能产生非预期的后果。比如在执行 app 容器镜像更新时，我们指定的序号是 0，但此时 containers 列表中第一个位置被插入了另一个容器，则更新的镜像就被错误地插入到这个非预期的容器中。 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:3:1","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"merge patch merge patch 无法单独更新一个列表中的某个元素，因此不管我们是要在 containers 里新增容器、还是修改已有容器的 image、env 等字段，都要用整个 containers 列表来提交 patch： kubectl patch deployment/foo --type='merge' -p \\ '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"app\",\"image\":\"app-image:v2\"},{\"name\":\"nginx\",\"image\":\"nginx:alpline\"}]}}}}' 显然，这个策略并不适合我们对一些列表深层的字段做更新，更适用于大片段的覆盖更新。 不过对于 labels/annotations 这些 map 类型的元素更新，merge patch 是可以单独指定 key-value 操作的，相比于 json patch 方便一些，写起来也更加直观： kubectl patch deployment/foo –type='merge’ -p ‘{“metadata”:{“labels”:{“test-key”:“foo”}}}’ ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:3:2","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"strategic merge patch 这种 patch 策略并没有一个通用的 RFC 标准，而是 K8s 独有的，不过相比前两种而言却更为强大的。 我们先从 K8s 源码看起，在 K8s 原生资源的数据结构定义中额外定义了一些的策略注解。比如以下这个截取了 podSpec 中针对 containers 列表的定义 // ... // +patchMergeKey=name // +patchStrategy=merge Containers []Container `json:\"containers\" patchStrategy:\"merge\" patchMergeKey:\"name\" protobuf:\"bytes,2,rep,name=containers\"` 可以看到其中有两个关键信息：patchStrategy:“merge” patchMergeKey:“name” 。这就代表了，containers 列表使用 strategic merge patch 策略更新时，会把下面每个元素中的 name 字段看作 key。 简单来说，在我们 patch 更新 containers 不再需要指定下标序号了，而是指定 name 来修改，K8s 会把 name 作为 key 来计算 merge。比如针对以下的 patch 操作： kubectl patch deployment/foo -p \\ '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"nginx\",\"image\":\"nginx:mainline\"}]}}}}' 如果 K8s 发现当前 containers 中已经有名字为 nginx 的容器，则只会把 image 更新上去；而如果当前 containers 中没有 nginx 容器，K8s 会把这个容器插入 containers 列表。 此外还要说明的是，目前 strategic 策略只能用于原生 K8s 资源以及 Aggregated API 方式的自定义资源，对于 CRD 定义的资源对象，是无法使用的。这很好理解，因为 kube-apiserver 无法得知 CRD 资源的结构和 merge 策略。如果用 kubectl patch 命令更新一个 CR，则默认会采用 merge patch 的策略来操作。 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:3:3","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"kubectl 封装 了解完了 K8s 的基础更新机制，我们再次回到最初的问题上。为什么用户修改 YAML 文件后无法直接调用 update 接口更新，却可以通过 kubectl apply 命令更新呢？ 其实 kubectl 为了给命令行用户提供良好的交互体感，设计了较为复杂的内部执行逻辑，诸如 apply、edit 这些常用操作其实背后并非对应一次简单的 update 请求。毕竟 update 是有版本控制的，如果发生了更新冲突对于普通用户并不友好。以下简略介绍下 kubectl 几种更新操作的逻辑，有兴趣可以看一下 link:https://github.com/kubernetes/kubectl[kubectl] 封装的源码。 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:3:4","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"apply 在使用默认参数执行 apply 时，触发的是 client-side apply。kubectl 逻辑如下： 首先解析用户提交的数据（YAML/JSON）为一个对象 A；然后调用 Get 接口从 K8s 中查询这个资源对象： 如果查询结果不存在，kubectl 将本次用户提交的数据记录到对象 A 的 annotation 中（key 为 kubectl.kubernetes.io/last-applied-configuration），最后将对象 A提交给 K8s 创建； 如果查询到 K8s 中已有这个资源，假设为对象 B：1. kubectl 尝试从对象 B 的 annotation 中取出 kubectl.kubernetes.io/last-applied-configuration 的值（对应了上一次 apply 提交的内容）；2. kubectl 根据前一次 apply 的内容和本次 apply 的内容计算出 diff（默认为 strategic merge patch 格式，如果非原生资源则采用 merge patch）；3. 将 diff 中添加本次的 kubectl.kubernetes.io/last-applied-configuration annotation，最后用 patch 请求提交给 K8s 做更新。 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:3:5","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"edit kubectl edit 逻辑上更简单一些。在用户执行命令之后，kubectl 从 K8s 中查到当前的资源对象，并打开一个命令行编辑器（默认用 vi）为用户提供编辑界面。 当用户修改完成、保存退出时，kubectl 并非直接把修改后的对象提交 update（避免 Conflict，如果用户修改的过程中资源对象又被更新），而是会把修改后的对象和初始拿到的对象计算 diff，最后将 diff 内容用 patch 请求提交给 K8s。 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:3:6","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"总结 看了上述的介绍，大家应该对 K8s 更新机制有了一个初步的了解了。接下来想一想，既然 K8s 提供了两种更新方式，我们在不同的场景下怎么选择 update 或 patch 来使用呢？这里我们的建议是： 如果要更新的字段只有我们自己会修改（比如我们有一些自定义标签，并写了 operator 来管理），则使用 patch 是最简单的方式； 如果要更新的字段可能会被其他方修改（比如我们修改的 replicas 字段，可能有一些其他组件比如 HPA 也会做修改），则建议使用 update 来更新，避免出现互相覆盖。 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:4:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"参考 https://aijishu.com/a/1060000000118183 ","date":"2020-11-21","objectID":"/kubernetes/patch-update/:5:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/kubernetes/patch-update/"},{"categories":null,"content":"kubernetes 中patch与update比较","date":"2020-11-21","objectID":"/patch-update/","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"导读 不知道你有没有想过一个问题：对于一个 K8s 资源对象比如 Deployment，我们尝试在修改其中 image 镜像时，如果有其他人同时也在对这个 Deployment 做修改，会发生什么？ 当然，这里还可以引申出两个问题： 如果双方修改的是同一个字段，比如 image 字段，结果会怎样？ 如果双方修改的是不同字段，比如一个修改 image，另一个修改 replicas，又会怎么样？ 其实，对一个 Kubernetes 资源对象做“更新”操作，简单来说就是通知 kube-apiserver 组件我们希望如何修改这个对象。而 K8s 为这类需求定义了两种“通知”方式，分别是 update 和 patch。在 update 请求中，我们需要将整个修改后的对象提交给 K8s；而对于 patch 请求，我们只需要将对象中某些字段的修改提交给 K8s。 ","date":"2020-11-21","objectID":"/patch-update/:1:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"Update 机制 Kubernetes 中的所有资源对象，都有一个全局唯一的版本号（metadata.resourceVersion）。每个资源对象从创建开始就会有一个版本号，而后每次被修改（不管是 update 还是 patch 修改），版本号都会发生变化。 官方文档 告诉我们，这个版本号是一个 K8s 的内部机制，用户不应该假设它是一个数字或者通过比较两个版本号大小来确定资源对象的新旧，唯一能做的就是通过比较版本号相等来确定对象是否是同一个版本（即是否发生了变化）。而 resourceVersion 一个重要的用处，就是来做 update 请求的版本控制。 K8s 要求用户 update 请求中提交的对象必须带有 resourceVersion，也就是说我们提交 update 的数据必须先来源于 K8s 中已经存在的对象。因此，一次完整的 update 操作流程是： 首先，从 K8s 中拿到一个已经存在的对象（可以选择直接从 K8s 中查询；如果在客户端做了 list watch，推荐从本地 informer 中获取）； 然后，基于这个取出来的对象做一些修改，比如将 Deployment 中的 replicas 做增减，或是将 image 字段修改为一个新版本的镜像； 最后，将修改后的对象通过 update 请求提交给 K8s； 此时，kube-apiserver 会校验用户 update 请求提交对象中的 resourceVersion 一定要和当前 K8s 中这个对象最新的 resourceVersion 一致，才能接受本次 update。否则，K8s 会拒绝请求，并告诉用户发生了版本冲突（Conflict）。 上图展示了多个用户同时 update 某一个资源对象时会发生的事情。而如果如果发生了 Conflict 冲突，对于 User A 而言应该做的就是做一次重试，再次获取到最新版本的对象，修改后重新提交 update。 因此，我们上面的两个问题也都得到了解答： 用户修改 YAML 后提交 update 失败，是因为 YAML 文件中没有包含 resourceVersion 字段。对于 update 请求而言，应该取出当前 K8s 中的对象做修改后提交； 如果两个用户同时对一个资源对象做 update，不管操作的是对象中同一个字段还是不同字段，都存在版本控制的机制确保两个用户的 update 请求不会发生覆盖。 ","date":"2020-11-21","objectID":"/patch-update/:2:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"Patch 机制 相比于 update 的版本控制，K8s 的 patch 机制则显得更加简单。 当用户对某个资源对象提交一个 patch 请求时，kube-apiserver 不会考虑版本问题，而是“无脑”地接受用户的请求（只要请求发送的 patch 内容合法），也就是将 patch 打到对象上、同时更新版本号。 不过，patch 的复杂点在于，目前 K8s 提供了 4 种 patch 策略：json patch、merge patch、strategic merge patch、apply patch（从 K8s 1.14 支持 server-side apply 开始）。通过 kubectl patch -h 命令我们也可以看到这个策略选项（默认采用 strategic）： $ kubectl patch -h # ... --type='strategic': The type of patch being provided; one of [json merge strategic] 篇幅限制这里暂不对每个策略做详细的介绍了，我们就以一个简单的例子来看一下它们的差异性。如果针对一个已有的 Deployment 对象，假设 template 中已经有了一个名为 app 的容器： 如果要在其中新增一个 nginx 容器，如何 patch 更新？ 如果要修改 app 容器的镜像，如何 patch 更新？ ","date":"2020-11-21","objectID":"/patch-update/:3:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"json patch 新增容器： kubectl patch deployment/foo --type='json' -p \\ '[{\"op\":\"add\",\"path\":\"/spec/template/spec/containers/1\",\"value\":{\"name\":\"nginx\",\"image\":\"nginx:alpine\"}}]' 修改已有容器 image： kubectl patch deployment/foo --type='json' -p \\ '[{\"op\":\"replace\",\"path\":\"/spec/template/spec/containers/0/image\",\"value\":\"app-image:v2\"}]' 这样一来，如果我们 patch 之前这个对象已经被其他人修改了，那么我们的 patch 有可能产生非预期的后果。比如在执行 app 容器镜像更新时，我们指定的序号是 0，但此时 containers 列表中第一个位置被插入了另一个容器，则更新的镜像就被错误地插入到这个非预期的容器中。 ","date":"2020-11-21","objectID":"/patch-update/:3:1","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"merge patch merge patch 无法单独更新一个列表中的某个元素，因此不管我们是要在 containers 里新增容器、还是修改已有容器的 image、env 等字段，都要用整个 containers 列表来提交 patch： kubectl patch deployment/foo --type='merge' -p \\ '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"app\",\"image\":\"app-image:v2\"},{\"name\":\"nginx\",\"image\":\"nginx:alpline\"}]}}}}' 显然，这个策略并不适合我们对一些列表深层的字段做更新，更适用于大片段的覆盖更新。 不过对于 labels/annotations 这些 map 类型的元素更新，merge patch 是可以单独指定 key-value 操作的，相比于 json patch 方便一些，写起来也更加直观： kubectl patch deployment/foo –type='merge’ -p ‘{“metadata”:{“labels”:{“test-key”:“foo”}}}’ ","date":"2020-11-21","objectID":"/patch-update/:3:2","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"strategic merge patch 这种 patch 策略并没有一个通用的 RFC 标准，而是 K8s 独有的，不过相比前两种而言却更为强大的。 我们先从 K8s 源码看起，在 K8s 原生资源的数据结构定义中额外定义了一些的策略注解。比如以下这个截取了 podSpec 中针对 containers 列表的定义 // ... // +patchMergeKey=name // +patchStrategy=merge Containers []Container `json:\"containers\" patchStrategy:\"merge\" patchMergeKey:\"name\" protobuf:\"bytes,2,rep,name=containers\"` 可以看到其中有两个关键信息：patchStrategy:“merge” patchMergeKey:“name” 。这就代表了，containers 列表使用 strategic merge patch 策略更新时，会把下面每个元素中的 name 字段看作 key。 简单来说，在我们 patch 更新 containers 不再需要指定下标序号了，而是指定 name 来修改，K8s 会把 name 作为 key 来计算 merge。比如针对以下的 patch 操作： kubectl patch deployment/foo -p \\ '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"nginx\",\"image\":\"nginx:mainline\"}]}}}}' 如果 K8s 发现当前 containers 中已经有名字为 nginx 的容器，则只会把 image 更新上去；而如果当前 containers 中没有 nginx 容器，K8s 会把这个容器插入 containers 列表。 此外还要说明的是，目前 strategic 策略只能用于原生 K8s 资源以及 Aggregated API 方式的自定义资源，对于 CRD 定义的资源对象，是无法使用的。这很好理解，因为 kube-apiserver 无法得知 CRD 资源的结构和 merge 策略。如果用 kubectl patch 命令更新一个 CR，则默认会采用 merge patch 的策略来操作。 ","date":"2020-11-21","objectID":"/patch-update/:3:3","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"kubectl 封装 了解完了 K8s 的基础更新机制，我们再次回到最初的问题上。为什么用户修改 YAML 文件后无法直接调用 update 接口更新，却可以通过 kubectl apply 命令更新呢？ 其实 kubectl 为了给命令行用户提供良好的交互体感，设计了较为复杂的内部执行逻辑，诸如 apply、edit 这些常用操作其实背后并非对应一次简单的 update 请求。毕竟 update 是有版本控制的，如果发生了更新冲突对于普通用户并不友好。以下简略介绍下 kubectl 几种更新操作的逻辑，有兴趣可以看一下 link:https://github.com/kubernetes/kubectl[kubectl] 封装的源码。 ","date":"2020-11-21","objectID":"/patch-update/:3:4","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"apply 在使用默认参数执行 apply 时，触发的是 client-side apply。kubectl 逻辑如下： 首先解析用户提交的数据（YAML/JSON）为一个对象 A；然后调用 Get 接口从 K8s 中查询这个资源对象： 如果查询结果不存在，kubectl 将本次用户提交的数据记录到对象 A 的 annotation 中（key 为 kubectl.kubernetes.io/last-applied-configuration），最后将对象 A提交给 K8s 创建； 如果查询到 K8s 中已有这个资源，假设为对象 B：1. kubectl 尝试从对象 B 的 annotation 中取出 kubectl.kubernetes.io/last-applied-configuration 的值（对应了上一次 apply 提交的内容）；2. kubectl 根据前一次 apply 的内容和本次 apply 的内容计算出 diff（默认为 strategic merge patch 格式，如果非原生资源则采用 merge patch）；3. 将 diff 中添加本次的 kubectl.kubernetes.io/last-applied-configuration annotation，最后用 patch 请求提交给 K8s 做更新。 ","date":"2020-11-21","objectID":"/patch-update/:3:5","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"edit kubectl edit 逻辑上更简单一些。在用户执行命令之后，kubectl 从 K8s 中查到当前的资源对象，并打开一个命令行编辑器（默认用 vi）为用户提供编辑界面。 当用户修改完成、保存退出时，kubectl 并非直接把修改后的对象提交 update（避免 Conflict，如果用户修改的过程中资源对象又被更新），而是会把修改后的对象和初始拿到的对象计算 diff，最后将 diff 内容用 patch 请求提交给 K8s。 ","date":"2020-11-21","objectID":"/patch-update/:3:6","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"总结 看了上述的介绍，大家应该对 K8s 更新机制有了一个初步的了解了。接下来想一想，既然 K8s 提供了两种更新方式，我们在不同的场景下怎么选择 update 或 patch 来使用呢？这里我们的建议是： 如果要更新的字段只有我们自己会修改（比如我们有一些自定义标签，并写了 operator 来管理），则使用 patch 是最简单的方式； 如果要更新的字段可能会被其他方修改（比如我们修改的 replicas 字段，可能有一些其他组件比如 HPA 也会做修改），则建议使用 update 来更新，避免出现互相覆盖。 ","date":"2020-11-21","objectID":"/patch-update/:4:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"参考 https://aijishu.com/a/1060000000118183 ","date":"2020-11-21","objectID":"/patch-update/:5:0","tags":["kubernetes","api","patch","update"],"title":"kubernetes 中patch与update比较","uri":"/patch-update/"},{"categories":null,"content":"kubectl 常用命令指南","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"导读 kubectl 应该是每个接触 kubernetes 的人都会接触的一个组件，它带给我们强大的命令行体验，本篇文章就是介绍 kubectl 中的一些常用命令，在结合一些具体的使用场景说说如何利用 kubectl 实现。好记性不如烂笔头，在这里尽可能全的罗列，方便后续 用的时候查找。如果能帮到您就收藏起来吧(😄)。 本次实验环境是 kubernetes-1.16.9，本篇文档的写作思路是按照平时 的使用场景进行写作，不会详细介绍 kubectl 的命令，kubectl 详细的帮助文档参考 kubectl --help or kubectl command --help 。 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:1:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"kubectl 支持的命令 kubectl --help kubectl controls the Kubernetes cluster manager. Find more information at: https://kubernetes.io/docs/reference/kubectl/overview/ Basic Commands (Beginner): create Create a resource from a file or from stdin. expose 使用 replication controller, service, deployment 或者 pod 并暴露它作为一个 新的 Kubernetes Service run 在集群中运行一个指定的镜像 set 为 objects 设置一个指定的特征 Basic Commands (Intermediate): explain 查看资源的文档 get 显示一个或更多 resources edit 在服务器上编辑一个资源 delete Delete resources by filenames, stdin, resources and names, or by resources and label selector Deploy Commands: rollout Manage the rollout of a resource scale 为 Deployment, ReplicaSet, Replication Controller 或者 Job 设置一个新的副本数量 autoscale 自动调整一个 Deployment, ReplicaSet, 或者 ReplicationController 的副本数量 Cluster Management Commands: certificate 修改 certificate 资源. cluster-info 显示集群信息 top Display Resource (CPU/Memory/Storage) usage. cordon 标记 node 为 unschedulable uncordon 标记 node 为 schedulable drain Drain node in preparation for maintenance taint 更新一个或者多个 node 上的 taints Troubleshooting and Debugging Commands: describe 显示一个指定 resource 或者 group 的 resources 详情 logs 输出容器在 pod 中的日志 attach Attach 到一个运行中的 container exec 在一个 container 中执行一个命令 port-forward Forward one or more local ports to a pod proxy 运行一个 proxy 到 Kubernetes API server cp 复制 files 和 directories 到 containers 和从容器中复制 files 和 directories. auth Inspect authorization Advanced Commands: diff Diff live version against would-be applied version apply 通过文件名或标准输入流(stdin)对资源进行配置 patch 使用 strategic merge patch 更新一个资源的 field(s) replace 通过 filename 或者 stdin替换一个资源 wait Experimental: Wait for a specific condition on one or many resources. convert 在不同的 API versions 转换配置文件 kustomize Build a kustomization target from a directory or a remote url. Settings Commands: label 更新在这个资源上的 labels annotate 更新一个资源的注解 completion Output shell completion code for the specified shell (bash or zsh) Other Commands: api-resources Print the supported API resources on the server api-versions Print the supported API versions on the server, in the form of \"group/version\" config 修改 kubeconfig 文件 plugin Provides utilities for interacting with plugins. version 输出 client 和 server 的版本信息 Usage: kubectl [flags] [options] Use \"kubectl \u003ccommand\u003e --help\" for more information about a given command. Use \"kubectl options\" for a list of global command-line options (applies to all commands). 从上面的帮助文档可以看出， kubectl 基本格式为 kubectl verb resource options , kubectl 后跟谓语动词， 再跟要操作的资源，可以加 options ，如： 要看 monitoring namespace 下面有哪些pod : kubectl -n monitoring get po ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:2:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"pod pod 场景下，可能会有如下需求: ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看某个 namespace 下，所有的pod # 先查看有哪些namespace kubectl get namespace # 查看 pod kubectl -n $namespace get po # 或者 kubectl get po -n $namespace 上面两种写法在达到的效果上是一样的，但是有一个细节可以注意一下，如果 kubectl 环境有命令自动补全的话，资源对象又比较多 的情况下，第一种写法将会有极大的优势，可以思考这么个场景，如：要查看 monitoring namespace 下的某个pod 详情, 就可以通过: kubectl -n monitoring get po 加 tab 键，列出这个namespace 下的所有 pod 供筛选。 centos 下命令自动补全需要安装 bash-completion ，方法为 yum install -y bash-completion 如果不加 -n $namespace ，则默认是 default namespace ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:1","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看所有namespace 的pod kubectl get po --all-namespaces # or kubectl get po -A ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:2","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看某个具体的 pod 信息 ，以 wide、json、yaml 的格式输出 kubectl -n $namespace get po xxx -o wide/json/yaml # 如 查看 monitoring 下的 prometheus-0 pod 信息，并以yaml 形式输出。 kubectl -n monitoring get po prometheus-0 -o yaml ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:3","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看某个 pod 的某个字段信息 如果我们只想知道 pod 的 hostIP 或者其他的 一些字段， 可以通过 -o jsonpath or -o template or -o go-template 其中template 语法遵循 golang template 需要对 pod 的对象模型有一定的了解，如果不了解，可以 -o yaml or -o json 直接查看。 查看 hostIP 的方法如下: # -o jsonpath kubectl -n monitoring get po prometheus-k8s-0 -o jsonpath=\"{.status.hostIP}\" # -o template kubectl -n monitoring get po prometheus-k8s-0 -o template --template=\"{{.status.hostIP}}\" # -o go-template kubectl -n monitoring get po prometheus-k8s-0 -o go-template=\"{{.status.hostIP}}\" 如果需要查看其他的字段照猫画虎即可。 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:4","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"通过标签选择查看 pod 通过 -l key1=value1,key2=value2 进行选择，如 kubectl -n monitoring get po -l app=prometheus kubectl -n monitoring get po -l app=prometheus,prometheus=k8s ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:5","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看某个node 上部署的所有 pod #先获取集群内所有的node kubectl get node -o wide # 假设其中一个 node 的名称为 node-0001 kubectl get po -A -o wide | grep node-0001 通过 kubectl get po -A -o wide | grep 可以做很多事情，具体可以根据情况而定，比如查看所有状态异常的 pod （非 Running） kubectl get po -A -o wide | grep -v Running ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:6","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看 pod 的详细信息 kubectl -n monitoring describe po prometheus-k8s-0 这个命令在查看 pod 的基本信息和问题定位时特别有用，当 pod 异常，可以查看 Events 或许就能发现问题所在。 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:7","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看 pod log kubectl -n $namespace logs -f $podName $containerName # 其中 $namespace，$podName，$containerName 替换成真实值即可，当 pod 中只有一个 容器时可省略 $containerName，如： kubectl -n monitoring logs -f prometheus-k8s-0 prometheus ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:8","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"进入容器 kubectl -n $namespace exec -it $podName -c $containerName sh # 其中 $namespace，$podName，$containerName 替换成真实值即可，当 pod 中只有一个 容器时可省略 -c $containerName，如： kubectl -n monitoring exec -it prometheus-k8s-0 -c prometheus sh ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:9","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看 pod 的资源使用情况 kubectl -n $namespace top pod # 其中 $namespace 替换成真实值即可，如： kubectl -n monitoring top pod ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:10","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"删除 pod kubectl -n $namespace delete po $podName kubectl -n monitoring delete po prometheus-k8s-0 # 在某些异常情况下删除 pod 会卡住，删不掉，需要强制才能删除 ，强制删除需要增加 --grace-period=0 --force ， kubectl -n monitoring delete po prometheus-k8s-0 --grace-period=0 --force 原理如下， 默认执行 delete po 时，kubectl 会增加–grace-period=30 参数，表示预留30秒的时间给 pod 处理当前的请求， 但同时也不接收新的请求了，以一种相对优雅的方式停止容器，注意这个参数在创建 pod 时可以指定，默认是30秒。强制删除时需要把–grace-period 设置为0，表示不等待马上删除，否则强制删除就会失效。 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:11","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"pod 标签管理 pod 的大多数的情况都会由 deployment or statefulset 来管理，所以标签也会通过它们管理，实际情况下很少会通过 kubectl 对 pod label 做增删改，如有需要可参考 下面 node 的用法，只需要把资源对象换成 pod 即可。 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:12","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"文件 copy 从 pod 中 copy 文件或者 copy 到 pod 中去。 容器中需要有 tar 命令，否则会失败 # 从本地 copy 到 pod kubectl cp /tmp/foo_dir \u003csome-pod\u003e:/tmp/bar_dir kubectl -n monitoring cp abc.txt prometheus-k8s-0:/tmp/abc.txt # 如果 pod 中有多个 container 可以用 -c 指定 container kubectl cp /tmp/foo \u003csome-pod\u003e:/tmp/bar -c \u003cspecific-container\u003e kubectl -n monitoring cp abc.txt prometheus-k8s-0:/tmp/abc.txt -c prometheus # 从 pod copy 到 本地 kubectl cp \u003csome-pod\u003e:/tmp/foo /tmp/bar kubectl -n monitoring cp prometheus-k8s-0:/tmp/abc.txt /tmp/abd.txt ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:3:13","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"node 在 pod 一节 已经了解了 kubectl get ,kubectl describe , 等相关的用法，node 的操作和 pod 类似，只是后面接的资源对象不同。 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看有哪些node以及其基本信息 kubectl get node -o wide ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:1","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看 node 上的详细情况 # 查看所有 node 的详细信息 kubectl describe node # 也可以查看某个 node 的信息 kubectl describe node node-0001 ... 这个命令在定位 node 的问题很有用，会输出如下信息: Labels Annotations Non-terminated Pods (正在运行的 pod) Allocated resources (已经分配的资源) … ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:2","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"查看 node 的资源使用情况 kubectl top node ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:3","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"node 的标签管理 增加标签 kubectl label node $nodename key1=value1 key2=value2 # 如 kubectl label node node-0001 a1=bbb a2=ccc 更新标签 # 在 增加标签的基础 加 --overwrite 参数 kubectl label node node-0001 a1=bbb --overwrite # 当标签不存在也可以 加 --overwrite 参数 kubectl label node node-0001 a10=bbb --overwrite 删除标签 kubectl label node $nodename key1- key2- kubectl label node node-0001 a10- a3- ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:4","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"将一个 node 标记为不可调度/可调度 在调试过程中或者当其中的某些 node 出现问题时，需要将 node 标记为不可调度，等恢复回来再标记回来。 # 将一个 node 可以 标记为不可调度(unschedulable) ，如果只是看看效果，而不是真正标记可加 --dry-run 参数 kubectl cordon $nodeName kubectl cordon node-0001 kubectl cordon node-0001 --dry-run # 将一个 node 可以 标记为可调度(schedulable) ，如果只是看看效果，而不是真正标记可加 --dry-run 参数 kubectl uncordon $nodeName kubectl uncordon node-0001 kubectl uncordon node-0001 --dry-run ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:5","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"排空 node 上的 pod # 排空node 上的所有 pod ，即使没有被 rc 管理，但是不会排空 被 daemonset 管理的 pod， 因为排空之后又会马上创建出来 kubectl drain foo --force ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:6","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"node 上的污点（taint）管理 污点需要配合 pod 的亲和性使用，否则污点没有什么意义 # 增加/更新 taint kubectl taint nodes node-0001 dedicated=special-user:NoSchedule --overwrite # 删除 taint kubectl taint nodes foo dedicated:NoSchedule- kubectl taint nodes foo dedicated- 整体用法和 label 类似 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:7","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"node 的 annotate 管理 和 label 是类似的，只是把 verb 换成 annotate 即可 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:4:8","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"其他场景 上面通过 pod 和 node 的例子，穿插的介绍了大部分的 verb（如 get 、describe、top … ），这个小节再介绍其他的一些常用场景 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:5:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"apply 在准备好一个资源对象的 yaml 文件时可以用 kubectl apply -f xxx.ymal 使之生效，kubernetes 的api 中并没有 apply，api 中有的是 create 、update、patch 等，apply 是kubectl 自己封装实现的，先执行 get ，再判断是 create 还是 patch，所以用kubectl 创建或者更新资源时 都可以用 apply 命令。 # 创建资源 kubectl apply -f xxx.ymal kubectl create -f xxx.ymal # 更新资源 kubectl apply -f xxx.ymal kubectl update -f xxx.ymal kubectl patch -f xxx.ymal ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:5:1","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"滚动更新 想象这么一个场景，如果使用 configmap 或者 secret 当作 pod 的环境变量，那么当 configmap 或者 secret 更新了应该如何更新 对应的pod 呢？ pod 应该都会通过 deployment 或者 statefulset 来环境， 换言之该如何更新 deployment 或者 statefulset 呢？默认情况下 configmap 或者 secret 的更新是不会触发 deployment 或者 statefulset 的更新，一种可行的方法为: 更新 annotations 中一个无关的字段: kubectl -n $namespace patch deployment $deploymentName -p \\ \"{\\\"spec\\\":{\\\"template\\\":{\\\"metadata\\\":{\\\"annotations\\\":{\\\"test_date\\\":\\\"`date +'%s'`\\\"}}}}}\" kubectl -n monitor patch deployment prometheus -p \\ \"{\\\"spec\\\":{\\\"template\\\":{\\\"metadata\\\":{\\\"annotations\\\":{\\\"test_date\\\":\\\"`date +'%s'`\\\"}}}}}\" ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:5:2","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"总结 这篇文章介绍了 kubectl 的基本用法，常见场景中的一些操作，如果有其他场景可以通过 kubectl --help 和 kubectl command --help 查看帮助文档。 如有不正确之处欢迎指正。 ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:6:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"参考 https://kubernetes.io/zh/docs/reference/kubectl/cheatsheet/ https://mp.weixin.qq.com/s/OxYbLmTKXn5jrgStIQ6ohQ ","date":"2020-11-20","objectID":"/kubernetes/kubectl-command/:7:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubernetes/kubectl-command/"},{"categories":null,"content":"kubectl 常用命令指南","date":"2020-11-20","objectID":"/kubectl-command/","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"导读 kubectl 应该是每个接触 kubernetes 的人都会接触的一个组件，它带给我们强大的命令行体验，本篇文章就是介绍 kubectl 中的一些常用命令，在结合一些具体的使用场景说说如何利用 kubectl 实现。好记性不如烂笔头，在这里尽可能全的罗列，方便后续 用的时候查找。如果能帮到您就收藏起来吧(😄)。 本次实验环境是 kubernetes-1.16.9，本篇文档的写作思路是按照平时 的使用场景进行写作，不会详细介绍 kubectl 的命令，kubectl 详细的帮助文档参考 kubectl --help or kubectl command --help 。 ","date":"2020-11-20","objectID":"/kubectl-command/:1:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"kubectl 支持的命令 kubectl --help kubectl controls the Kubernetes cluster manager. Find more information at: https://kubernetes.io/docs/reference/kubectl/overview/ Basic Commands (Beginner): create Create a resource from a file or from stdin. expose 使用 replication controller, service, deployment 或者 pod 并暴露它作为一个 新的 Kubernetes Service run 在集群中运行一个指定的镜像 set 为 objects 设置一个指定的特征 Basic Commands (Intermediate): explain 查看资源的文档 get 显示一个或更多 resources edit 在服务器上编辑一个资源 delete Delete resources by filenames, stdin, resources and names, or by resources and label selector Deploy Commands: rollout Manage the rollout of a resource scale 为 Deployment, ReplicaSet, Replication Controller 或者 Job 设置一个新的副本数量 autoscale 自动调整一个 Deployment, ReplicaSet, 或者 ReplicationController 的副本数量 Cluster Management Commands: certificate 修改 certificate 资源. cluster-info 显示集群信息 top Display Resource (CPU/Memory/Storage) usage. cordon 标记 node 为 unschedulable uncordon 标记 node 为 schedulable drain Drain node in preparation for maintenance taint 更新一个或者多个 node 上的 taints Troubleshooting and Debugging Commands: describe 显示一个指定 resource 或者 group 的 resources 详情 logs 输出容器在 pod 中的日志 attach Attach 到一个运行中的 container exec 在一个 container 中执行一个命令 port-forward Forward one or more local ports to a pod proxy 运行一个 proxy 到 Kubernetes API server cp 复制 files 和 directories 到 containers 和从容器中复制 files 和 directories. auth Inspect authorization Advanced Commands: diff Diff live version against would-be applied version apply 通过文件名或标准输入流(stdin)对资源进行配置 patch 使用 strategic merge patch 更新一个资源的 field(s) replace 通过 filename 或者 stdin替换一个资源 wait Experimental: Wait for a specific condition on one or many resources. convert 在不同的 API versions 转换配置文件 kustomize Build a kustomization target from a directory or a remote url. Settings Commands: label 更新在这个资源上的 labels annotate 更新一个资源的注解 completion Output shell completion code for the specified shell (bash or zsh) Other Commands: api-resources Print the supported API resources on the server api-versions Print the supported API versions on the server, in the form of \"group/version\" config 修改 kubeconfig 文件 plugin Provides utilities for interacting with plugins. version 输出 client 和 server 的版本信息 Usage: kubectl [flags] [options] Use \"kubectl \u003ccommand\u003e --help\" for more information about a given command. Use \"kubectl options\" for a list of global command-line options (applies to all commands). 从上面的帮助文档可以看出， kubectl 基本格式为 kubectl verb resource options , kubectl 后跟谓语动词， 再跟要操作的资源，可以加 options ，如： 要看 monitoring namespace 下面有哪些pod : kubectl -n monitoring get po ","date":"2020-11-20","objectID":"/kubectl-command/:2:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"pod pod 场景下，可能会有如下需求: ","date":"2020-11-20","objectID":"/kubectl-command/:3:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看某个 namespace 下，所有的pod # 先查看有哪些namespace kubectl get namespace # 查看 pod kubectl -n $namespace get po # 或者 kubectl get po -n $namespace 上面两种写法在达到的效果上是一样的，但是有一个细节可以注意一下，如果 kubectl 环境有命令自动补全的话，资源对象又比较多 的情况下，第一种写法将会有极大的优势，可以思考这么个场景，如：要查看 monitoring namespace 下的某个pod 详情, 就可以通过: kubectl -n monitoring get po 加 tab 键，列出这个namespace 下的所有 pod 供筛选。 centos 下命令自动补全需要安装 bash-completion ，方法为 yum install -y bash-completion 如果不加 -n $namespace ，则默认是 default namespace ","date":"2020-11-20","objectID":"/kubectl-command/:3:1","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看所有namespace 的pod kubectl get po --all-namespaces # or kubectl get po -A ","date":"2020-11-20","objectID":"/kubectl-command/:3:2","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看某个具体的 pod 信息 ，以 wide、json、yaml 的格式输出 kubectl -n $namespace get po xxx -o wide/json/yaml # 如 查看 monitoring 下的 prometheus-0 pod 信息，并以yaml 形式输出。 kubectl -n monitoring get po prometheus-0 -o yaml ","date":"2020-11-20","objectID":"/kubectl-command/:3:3","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看某个 pod 的某个字段信息 如果我们只想知道 pod 的 hostIP 或者其他的 一些字段， 可以通过 -o jsonpath or -o template or -o go-template 其中template 语法遵循 golang template 需要对 pod 的对象模型有一定的了解，如果不了解，可以 -o yaml or -o json 直接查看。 查看 hostIP 的方法如下: # -o jsonpath kubectl -n monitoring get po prometheus-k8s-0 -o jsonpath=\"{.status.hostIP}\" # -o template kubectl -n monitoring get po prometheus-k8s-0 -o template --template=\"{{.status.hostIP}}\" # -o go-template kubectl -n monitoring get po prometheus-k8s-0 -o go-template=\"{{.status.hostIP}}\" 如果需要查看其他的字段照猫画虎即可。 ","date":"2020-11-20","objectID":"/kubectl-command/:3:4","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"通过标签选择查看 pod 通过 -l key1=value1,key2=value2 进行选择，如 kubectl -n monitoring get po -l app=prometheus kubectl -n monitoring get po -l app=prometheus,prometheus=k8s ","date":"2020-11-20","objectID":"/kubectl-command/:3:5","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看某个node 上部署的所有 pod #先获取集群内所有的node kubectl get node -o wide # 假设其中一个 node 的名称为 node-0001 kubectl get po -A -o wide | grep node-0001 通过 kubectl get po -A -o wide | grep 可以做很多事情，具体可以根据情况而定，比如查看所有状态异常的 pod （非 Running） kubectl get po -A -o wide | grep -v Running ","date":"2020-11-20","objectID":"/kubectl-command/:3:6","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看 pod 的详细信息 kubectl -n monitoring describe po prometheus-k8s-0 这个命令在查看 pod 的基本信息和问题定位时特别有用，当 pod 异常，可以查看 Events 或许就能发现问题所在。 ","date":"2020-11-20","objectID":"/kubectl-command/:3:7","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看 pod log kubectl -n $namespace logs -f $podName $containerName # 其中 $namespace，$podName，$containerName 替换成真实值即可，当 pod 中只有一个 容器时可省略 $containerName，如： kubectl -n monitoring logs -f prometheus-k8s-0 prometheus ","date":"2020-11-20","objectID":"/kubectl-command/:3:8","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"进入容器 kubectl -n $namespace exec -it $podName -c $containerName sh # 其中 $namespace，$podName，$containerName 替换成真实值即可，当 pod 中只有一个 容器时可省略 -c $containerName，如： kubectl -n monitoring exec -it prometheus-k8s-0 -c prometheus sh ","date":"2020-11-20","objectID":"/kubectl-command/:3:9","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看 pod 的资源使用情况 kubectl -n $namespace top pod # 其中 $namespace 替换成真实值即可，如： kubectl -n monitoring top pod ","date":"2020-11-20","objectID":"/kubectl-command/:3:10","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"删除 pod kubectl -n $namespace delete po $podName kubectl -n monitoring delete po prometheus-k8s-0 # 在某些异常情况下删除 pod 会卡住，删不掉，需要强制才能删除 ，强制删除需要增加 --grace-period=0 --force ， kubectl -n monitoring delete po prometheus-k8s-0 --grace-period=0 --force 原理如下， 默认执行 delete po 时，kubectl 会增加–grace-period=30 参数，表示预留30秒的时间给 pod 处理当前的请求， 但同时也不接收新的请求了，以一种相对优雅的方式停止容器，注意这个参数在创建 pod 时可以指定，默认是30秒。强制删除时需要把–grace-period 设置为0，表示不等待马上删除，否则强制删除就会失效。 ","date":"2020-11-20","objectID":"/kubectl-command/:3:11","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"pod 标签管理 pod 的大多数的情况都会由 deployment or statefulset 来管理，所以标签也会通过它们管理，实际情况下很少会通过 kubectl 对 pod label 做增删改，如有需要可参考 下面 node 的用法，只需要把资源对象换成 pod 即可。 ","date":"2020-11-20","objectID":"/kubectl-command/:3:12","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"文件 copy 从 pod 中 copy 文件或者 copy 到 pod 中去。 容器中需要有 tar 命令，否则会失败 # 从本地 copy 到 pod kubectl cp /tmp/foo_dir \u003csome-pod\u003e:/tmp/bar_dir kubectl -n monitoring cp abc.txt prometheus-k8s-0:/tmp/abc.txt # 如果 pod 中有多个 container 可以用 -c 指定 container kubectl cp /tmp/foo \u003csome-pod\u003e:/tmp/bar -c \u003cspecific-container\u003e kubectl -n monitoring cp abc.txt prometheus-k8s-0:/tmp/abc.txt -c prometheus # 从 pod copy 到 本地 kubectl cp \u003csome-pod\u003e:/tmp/foo /tmp/bar kubectl -n monitoring cp prometheus-k8s-0:/tmp/abc.txt /tmp/abd.txt ","date":"2020-11-20","objectID":"/kubectl-command/:3:13","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"node 在 pod 一节 已经了解了 kubectl get ,kubectl describe , 等相关的用法，node 的操作和 pod 类似，只是后面接的资源对象不同。 ","date":"2020-11-20","objectID":"/kubectl-command/:4:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看有哪些node以及其基本信息 kubectl get node -o wide ","date":"2020-11-20","objectID":"/kubectl-command/:4:1","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看 node 上的详细情况 # 查看所有 node 的详细信息 kubectl describe node # 也可以查看某个 node 的信息 kubectl describe node node-0001 ... 这个命令在定位 node 的问题很有用，会输出如下信息: Labels Annotations Non-terminated Pods (正在运行的 pod) Allocated resources (已经分配的资源) … ","date":"2020-11-20","objectID":"/kubectl-command/:4:2","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"查看 node 的资源使用情况 kubectl top node ","date":"2020-11-20","objectID":"/kubectl-command/:4:3","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"node 的标签管理 增加标签 kubectl label node $nodename key1=value1 key2=value2 # 如 kubectl label node node-0001 a1=bbb a2=ccc 更新标签 # 在 增加标签的基础 加 --overwrite 参数 kubectl label node node-0001 a1=bbb --overwrite # 当标签不存在也可以 加 --overwrite 参数 kubectl label node node-0001 a10=bbb --overwrite 删除标签 kubectl label node $nodename key1- key2- kubectl label node node-0001 a10- a3- ","date":"2020-11-20","objectID":"/kubectl-command/:4:4","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"将一个 node 标记为不可调度/可调度 在调试过程中或者当其中的某些 node 出现问题时，需要将 node 标记为不可调度，等恢复回来再标记回来。 # 将一个 node 可以 标记为不可调度(unschedulable) ，如果只是看看效果，而不是真正标记可加 --dry-run 参数 kubectl cordon $nodeName kubectl cordon node-0001 kubectl cordon node-0001 --dry-run # 将一个 node 可以 标记为可调度(schedulable) ，如果只是看看效果，而不是真正标记可加 --dry-run 参数 kubectl uncordon $nodeName kubectl uncordon node-0001 kubectl uncordon node-0001 --dry-run ","date":"2020-11-20","objectID":"/kubectl-command/:4:5","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"排空 node 上的 pod # 排空node 上的所有 pod ，即使没有被 rc 管理，但是不会排空 被 daemonset 管理的 pod， 因为排空之后又会马上创建出来 kubectl drain foo --force ","date":"2020-11-20","objectID":"/kubectl-command/:4:6","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"node 上的污点（taint）管理 污点需要配合 pod 的亲和性使用，否则污点没有什么意义 # 增加/更新 taint kubectl taint nodes node-0001 dedicated=special-user:NoSchedule --overwrite # 删除 taint kubectl taint nodes foo dedicated:NoSchedule- kubectl taint nodes foo dedicated- 整体用法和 label 类似 ","date":"2020-11-20","objectID":"/kubectl-command/:4:7","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"node 的 annotate 管理 和 label 是类似的，只是把 verb 换成 annotate 即可 ","date":"2020-11-20","objectID":"/kubectl-command/:4:8","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"其他场景 上面通过 pod 和 node 的例子，穿插的介绍了大部分的 verb（如 get 、describe、top … ），这个小节再介绍其他的一些常用场景 ","date":"2020-11-20","objectID":"/kubectl-command/:5:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"apply 在准备好一个资源对象的 yaml 文件时可以用 kubectl apply -f xxx.ymal 使之生效，kubernetes 的api 中并没有 apply，api 中有的是 create 、update、patch 等，apply 是kubectl 自己封装实现的，先执行 get ，再判断是 create 还是 patch，所以用kubectl 创建或者更新资源时 都可以用 apply 命令。 # 创建资源 kubectl apply -f xxx.ymal kubectl create -f xxx.ymal # 更新资源 kubectl apply -f xxx.ymal kubectl update -f xxx.ymal kubectl patch -f xxx.ymal ","date":"2020-11-20","objectID":"/kubectl-command/:5:1","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"滚动更新 想象这么一个场景，如果使用 configmap 或者 secret 当作 pod 的环境变量，那么当 configmap 或者 secret 更新了应该如何更新 对应的pod 呢？ pod 应该都会通过 deployment 或者 statefulset 来环境， 换言之该如何更新 deployment 或者 statefulset 呢？默认情况下 configmap 或者 secret 的更新是不会触发 deployment 或者 statefulset 的更新，一种可行的方法为: 更新 annotations 中一个无关的字段: kubectl -n $namespace patch deployment $deploymentName -p \\ \"{\\\"spec\\\":{\\\"template\\\":{\\\"metadata\\\":{\\\"annotations\\\":{\\\"test_date\\\":\\\"`date +'%s'`\\\"}}}}}\" kubectl -n monitor patch deployment prometheus -p \\ \"{\\\"spec\\\":{\\\"template\\\":{\\\"metadata\\\":{\\\"annotations\\\":{\\\"test_date\\\":\\\"`date +'%s'`\\\"}}}}}\" ","date":"2020-11-20","objectID":"/kubectl-command/:5:2","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"总结 这篇文章介绍了 kubectl 的基本用法，常见场景中的一些操作，如果有其他场景可以通过 kubectl --help 和 kubectl command --help 查看帮助文档。 如有不正确之处欢迎指正。 ","date":"2020-11-20","objectID":"/kubectl-command/:6:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"参考 https://kubernetes.io/zh/docs/reference/kubectl/cheatsheet/ https://mp.weixin.qq.com/s/OxYbLmTKXn5jrgStIQ6ohQ ","date":"2020-11-20","objectID":"/kubectl-command/:7:0","tags":["kubernetes","kubectl"],"title":"kubectl 常用命令","uri":"/kubectl-command/"},{"categories":null,"content":"markdown中插入表情的方法","date":"2020-11-19","objectID":"/markdownemoji/","tags":["markdown","emoji"],"title":"markdown中插入表情的方法","uri":"/markdownemoji/"},{"categories":null,"content":"导读 markdown 中也是可以插入表情，但并不是所有的markdown 解析器都支持，我本地用的 Goland、MacDown 不支持，但是 hugo 是支持的， 写作的过程可以适当加入一些表情，可以表达当时写作的一个心情。 ","date":"2020-11-19","objectID":"/markdownemoji/:1:0","tags":["markdown","emoji"],"title":"markdown中插入表情的方法","uri":"/markdownemoji/"},{"categories":null,"content":"使用场景 markdown 中支持 emoji 的地方有 : Campfire GitHub Basecamp Redbooth Trac Flowdock Sprint.ly Kandan Textbox.io Kippt Redmine JabbR Trello Hall Qiita Zendesk Ruby China Grove Idobata NodeBB Forums Slack Streamup OrganisedMinds Hackpad Cryptbin Kato Reportedly Cheerful Ghost IRCCloud Dashcube MyVideoGameList Subrosa Sococo Quip And Bang Bonusly Discourse Ello Twemoji Awesome Got Chosen Flow ReadMe.io esa DBook Groups.io TeamworkChat Damn Bugs Let’s Chat Buildkite ChatGrape Dokuwiki Usersnap Discord Status Hero Morfy Bitbucket Gitter Yellow YouTube Habitica and Mattermost ","date":"2020-11-19","objectID":"/markdownemoji/:2:0","tags":["markdown","emoji"],"title":"markdown中插入表情的方法","uri":"/markdownemoji/"},{"categories":null,"content":"用法 emoji 的表情大全参考 : https://www.webfx.com/tools/emoji-cheat-sheet/ 如果想要在 markdown 中使用，只要在相应的地方插入 :xxx: 即可， 其中 xxx 就是表情的名字 ，例: ## 插入表情示例 - 笑： 😄 - 傻笑 😏 - 害羞 😊 ... :/play secret: ","date":"2020-11-19","objectID":"/markdownemoji/:3:0","tags":["markdown","emoji"],"title":"markdown中插入表情的方法","uri":"/markdownemoji/"},{"categories":null,"content":"参考 https://www.webfx.com/tools/emoji-cheat-sheet/ ","date":"2020-11-19","objectID":"/markdownemoji/:4:0","tags":["markdown","emoji"],"title":"markdown中插入表情的方法","uri":"/markdownemoji/"},{"categories":null,"content":"python中的多线程与多进程（二）","date":"2020-11-18","objectID":"/concurrent/","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/concurrent/"},{"categories":null,"content":"导读 在上一篇“python中的多线程与多进程(一)中介绍了进程、线程的概念、基本用法和在 python 中使用遇到的一些坑， 这在一篇中会介绍一些高级的用法，当然更多的是遇到的坑，换言之这是一片避坑指南。 ","date":"2020-11-18","objectID":"/concurrent/:1:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/concurrent/"},{"categories":null,"content":"concurrent.futures 我们都知道在 python 中，多线程的标准库是使用 threading , 如 ： # -*- coding: UTF-8 -*- import threading import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) for index,value in enumerate([\"python\", \"java\", \"golang\", \"php\"]) : thread = threading.Thread(target=runner,args=(index, value, )) thread.start() 多进程的库是 multiprocessing ,如： # -*- coding: UTF-8 -*- from multiprocessing import Process import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) for index,value in enumerate([\"python\", \"java\", \"golang\", \"php\"]) : process = Process(target=runner,args=(index, value, )) process.start() 以上两个库已经 python2 已经支持，可以很好的实现我们多进程与多线程的需求。 python3.2 提供了 concurrent.futures 库，并且已经回溯到python2，这个库在 threading 与 multiprocessing 的基础上提供了一层封装，使得多线程和多进程在使用行为上保持了一致，为什么这么说呢，且看下面分析，请先看两段代码： 多线程 # -*- coding: UTF-8 -*- from concurrent.futures._base import TimeoutError from concurrent.futures import ThreadPoolExecutor import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) max_workers = 4 print(\"执行升级任务的并发数为为： {}\".format(max_workers)) runners = [\"python\", \"java\", \"golang\", \"php\", \"rust\", \"shell\", \"c\"] with ThreadPoolExecutor(max_workers=max_workers) as executor: for index, value in enumerate(runners): result = executor.submit(runner, index, value) try: result.result(timeout=3 * 60 ) except TimeoutError as err: print(\"任务超时,\", err) 多进程 # -*- coding: UTF-8 -*- from concurrent.futures._base import TimeoutError from concurrent.futures import ProcessPoolExecutor import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) max_workers = 4 print(\"执行升级任务的并发数为为： {}\".format(max_workers)) runners = [\"python\", \"java\", \"golang\", \"php\", \"rust\", \"shell\", \"c\"] with ProcessPoolExecutor(max_workers=max_workers) as executor: for index, value in enumerate(runners): result = executor.submit(runner, index, value) try: result.result(timeout=3 * 60 ) except TimeoutError as err: print(\"任务超时,\", err) 可以看到多进程和多线程写法超级类似，一个使用的是 ProcessPoolExecutor ，一个使用的是 ThreadPoolExecutor，其他代码基本一直，查看源码可以发现 concurrent.futures 定义了一个 Executor 抽象基类，提供了 submit 、map 、shutdown 等方法 class Executor(object): \"\"\"This is an abstract base class for concrete asynchronous executors.\"\"\" def submit(self, fn, *args, **kwargs): \"\"\"Submits a callable to be executed with the given arguments. Schedules the callable to be executed as fn(*args, **kwargs) and returns a Future instance representing the execution of the callable. Returns: A Future representing the given call. \"\"\" raise NotImplementedError() def map(self, fn, *iterables, **kwargs): \"\"\"Returns a iterator equivalent to map(fn, iter). Args: fn: A callable that will take as many arguments as there are passed iterables. timeout: The maximum number of seconds to wait. If None, then there is no limit on the wait time. Returns: An iterator equivalent to: map(func, *iterables) but the calls may be evaluated out-of-order. Raises: TimeoutError: If the entire result iterator could not be generated before the given timeout. Exception: If fn(*args) raises for any values. \"\"\" timeout = kwargs.get('timeout') if timeout is not None: end_time = timeout + time.time() fs = [self.submit(fn, *args) for args in itertools.izip(*iterables)] # Yield must be hidden in closure so that the futures are submitted # before the first iterator value is required. def result_iterator(): try: for future in fs: if timeout is None: yield future.result() else: yield future.result(end_time - time.time()) finally: for future in fs: future.cancel() return result_iterator() def shutdown(self, wait=True): \"\"","date":"2020-11-18","objectID":"/concurrent/:2:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/concurrent/"},{"categories":null,"content":"concurrent 使用过程中遇到的坑 执行环境为 python-2.7.15 假设有这么一个脚本 multipy.py # -*- coding: UTF-8 -*- from concurrent.futures._base import TimeoutError from concurrent.futures import ProcessPoolExecutor import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) def main(max_workers=1) : print(\"执行升级任务的并发数为为： {}\".format(max_workers)) runners = [\"python\", \"java\", \"golang\", \"php\", \"rust\", \"shell\", \"c\"] with ProcessPoolExecutor(max_workers=max_workers) as executor: for index, value in enumerate(runners): result = executor.submit(runner, index, value) try: result.result(timeout=3 * 60) except TimeoutError as err: print(\"任务超时,\", err) if __name__ == \"__main__\" : main(3) 通过在命令行执行 python multipy.py ，大家可以在心里想象一下会输出什么。 第二个场景是：同样的脚本， 通过 setuptools 安装后执行，部分代码（setup.py）如下: #!/usr/bin/env python from setuptools import setup, find_packages setup( name=\"pyctl\", entry_points=''' [console_scripts] pyctl=pyctl.commands.shell:cli ''', classifiers=[ ... ], install_requires=[ ... 'click==7.0' ], ) 安装完成之后可以在命令行通过 pyctl xxx ... 执行，和执行系统命令是一样的，如果不熟悉 setuptools 可以先了解一下，文档参考https://pypi.org/project/setuptools/ 言归正传，通过 setuptools 打包之后再执行这个脚本，我们可以假设打包之后的执行方式为 pyctl multipy ，执行后会发生什么呢？大家也可以在心里先想象一下。 实际的结果就是直接通过 python multipy.py 的方式可以得到正确的结果，确实按照多进程的方式并发执行，但是到第二个场景时却无法运行，通过 ps -ef 查看进程，确实创建了多个进程，但这些进程都被阻塞，没有执行 runner 函数里面的内容，程序会被卡死。当时百思不解其中的原因，尝试过很多方法，包括使用原生的 multiprocessing 自己实现进程管理也是同样的效果，最后是同样的代码，换到python3.8，两种方法都可以得到正确结果。python2.7 为啥会卡死，多个进程创建出来没有执行 runner 任务至今还没有找到原因，后续有进展再更新， 欢迎知道原因的小伙伴留言告知！！！ ","date":"2020-11-18","objectID":"/concurrent/:3:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/concurrent/"},{"categories":null,"content":"总结 在python2.7的环境下面，如果通过 setuptools 打包安装，安装后多进程使用会有问题，现象是会创建多个子进程出来，但是主进程和子进程都会被阻塞而无法真正执行runner任务，一个行之有效的方法是切换到python3（python3.8亲测没有问题，其他的没测过）。 ","date":"2020-11-18","objectID":"/concurrent/:4:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/concurrent/"},{"categories":null,"content":"python中的多线程与多进程（二）","date":"2020-11-18","objectID":"/python/concurrent/","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/python/concurrent/"},{"categories":null,"content":"导读 在上一篇“python中的多线程与多进程(一)中介绍了进程、线程的概念、基本用法和在 python 中使用遇到的一些坑， 这在一篇中会介绍一些高级的用法，当然更多的是遇到的坑，换言之这是一片避坑指南。 ","date":"2020-11-18","objectID":"/python/concurrent/:1:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/python/concurrent/"},{"categories":null,"content":"concurrent.futures 我们都知道在 python 中，多线程的标准库是使用 threading , 如 ： # -*- coding: UTF-8 -*- import threading import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) for index,value in enumerate([\"python\", \"java\", \"golang\", \"php\"]) : thread = threading.Thread(target=runner,args=(index, value, )) thread.start() 多进程的库是 multiprocessing ,如： # -*- coding: UTF-8 -*- from multiprocessing import Process import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) for index,value in enumerate([\"python\", \"java\", \"golang\", \"php\"]) : process = Process(target=runner,args=(index, value, )) process.start() 以上两个库已经 python2 已经支持，可以很好的实现我们多进程与多线程的需求。 python3.2 提供了 concurrent.futures 库，并且已经回溯到python2，这个库在 threading 与 multiprocessing 的基础上提供了一层封装，使得多线程和多进程在使用行为上保持了一致，为什么这么说呢，且看下面分析，请先看两段代码： 多线程 # -*- coding: UTF-8 -*- from concurrent.futures._base import TimeoutError from concurrent.futures import ThreadPoolExecutor import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) max_workers = 4 print(\"执行升级任务的并发数为为： {}\".format(max_workers)) runners = [\"python\", \"java\", \"golang\", \"php\", \"rust\", \"shell\", \"c\"] with ThreadPoolExecutor(max_workers=max_workers) as executor: for index, value in enumerate(runners): result = executor.submit(runner, index, value) try: result.result(timeout=3 * 60 ) except TimeoutError as err: print(\"任务超时,\", err) 多进程 # -*- coding: UTF-8 -*- from concurrent.futures._base import TimeoutError from concurrent.futures import ProcessPoolExecutor import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) max_workers = 4 print(\"执行升级任务的并发数为为： {}\".format(max_workers)) runners = [\"python\", \"java\", \"golang\", \"php\", \"rust\", \"shell\", \"c\"] with ProcessPoolExecutor(max_workers=max_workers) as executor: for index, value in enumerate(runners): result = executor.submit(runner, index, value) try: result.result(timeout=3 * 60 ) except TimeoutError as err: print(\"任务超时,\", err) 可以看到多进程和多线程写法超级类似，一个使用的是 ProcessPoolExecutor ，一个使用的是 ThreadPoolExecutor，其他代码基本一直，查看源码可以发现 concurrent.futures 定义了一个 Executor 抽象基类，提供了 submit 、map 、shutdown 等方法 class Executor(object): \"\"\"This is an abstract base class for concrete asynchronous executors.\"\"\" def submit(self, fn, *args, **kwargs): \"\"\"Submits a callable to be executed with the given arguments. Schedules the callable to be executed as fn(*args, **kwargs) and returns a Future instance representing the execution of the callable. Returns: A Future representing the given call. \"\"\" raise NotImplementedError() def map(self, fn, *iterables, **kwargs): \"\"\"Returns a iterator equivalent to map(fn, iter). Args: fn: A callable that will take as many arguments as there are passed iterables. timeout: The maximum number of seconds to wait. If None, then there is no limit on the wait time. Returns: An iterator equivalent to: map(func, *iterables) but the calls may be evaluated out-of-order. Raises: TimeoutError: If the entire result iterator could not be generated before the given timeout. Exception: If fn(*args) raises for any values. \"\"\" timeout = kwargs.get('timeout') if timeout is not None: end_time = timeout + time.time() fs = [self.submit(fn, *args) for args in itertools.izip(*iterables)] # Yield must be hidden in closure so that the futures are submitted # before the first iterator value is required. def result_iterator(): try: for future in fs: if timeout is None: yield future.result() else: yield future.result(end_time - time.time()) finally: for future in fs: future.cancel() return result_iterator() def shutdown(self, wait=True): \"\"","date":"2020-11-18","objectID":"/python/concurrent/:2:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/python/concurrent/"},{"categories":null,"content":"concurrent 使用过程中遇到的坑 执行环境为 python-2.7.15 假设有这么一个脚本 multipy.py # -*- coding: UTF-8 -*- from concurrent.futures._base import TimeoutError from concurrent.futures import ProcessPoolExecutor import time def runner(index, param) : print(\"线程{} 开始运行: ------------\".format(index)) print(\"线程{} : {}\".format(index,param)) time.sleep(3) print(\"线程{} 运行结束: ------------\".format(index)) def main(max_workers=1) : print(\"执行升级任务的并发数为为： {}\".format(max_workers)) runners = [\"python\", \"java\", \"golang\", \"php\", \"rust\", \"shell\", \"c\"] with ProcessPoolExecutor(max_workers=max_workers) as executor: for index, value in enumerate(runners): result = executor.submit(runner, index, value) try: result.result(timeout=3 * 60) except TimeoutError as err: print(\"任务超时,\", err) if __name__ == \"__main__\" : main(3) 通过在命令行执行 python multipy.py ，大家可以在心里想象一下会输出什么。 第二个场景是：同样的脚本， 通过 setuptools 安装后执行，部分代码（setup.py）如下: #!/usr/bin/env python from setuptools import setup, find_packages setup( name=\"pyctl\", entry_points=''' [console_scripts] pyctl=pyctl.commands.shell:cli ''', classifiers=[ ... ], install_requires=[ ... 'click==7.0' ], ) 安装完成之后可以在命令行通过 pyctl xxx ... 执行，和执行系统命令是一样的，如果不熟悉 setuptools 可以先了解一下，文档参考https://pypi.org/project/setuptools/ 言归正传，通过 setuptools 打包之后再执行这个脚本，我们可以假设打包之后的执行方式为 pyctl multipy ，执行后会发生什么呢？大家也可以在心里先想象一下。 实际的结果就是直接通过 python multipy.py 的方式可以得到正确的结果，确实按照多进程的方式并发执行，但是到第二个场景时却无法运行，通过 ps -ef 查看进程，确实创建了多个进程，但这些进程都被阻塞，没有执行 runner 函数里面的内容，程序会被卡死。当时百思不解其中的原因，尝试过很多方法，包括使用原生的 multiprocessing 自己实现进程管理也是同样的效果，最后是同样的代码，换到python3.8，两种方法都可以得到正确结果。python2.7 为啥会卡死，多个进程创建出来没有执行 runner 任务至今还没有找到原因，后续有进展再更新， 欢迎知道原因的小伙伴留言告知！！！ ","date":"2020-11-18","objectID":"/python/concurrent/:3:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/python/concurrent/"},{"categories":null,"content":"总结 在python2.7的环境下面，如果通过 setuptools 打包安装，安装后多进程使用会有问题，现象是会创建多个子进程出来，但是主进程和子进程都会被阻塞而无法真正执行runner任务，一个行之有效的方法是切换到python3（python3.8亲测没有问题，其他的没测过）。 ","date":"2020-11-18","objectID":"/python/concurrent/:4:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（二）","uri":"/python/concurrent/"},{"categories":null,"content":"python中的多线程与多进程（一）","date":"2020-11-16","objectID":"/multithread/","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/multithread/"},{"categories":null,"content":"导读 在编码的过程，多线程、多进程、并发、并行这些概念肯定不止一次的出现在我们面前。概念理解是一回事，但是能真正用好又是另一回事。不同的编程语言，并发编程难易程度相差还是很大的，正好这几天梳理了他们之间的关系与区别，分享给大家。（基于自己的理解谈谈，如果不对欢迎指出） 灵魂拷问：什么是线程？什么是进程？ ","date":"2020-11-16","objectID":"/multithread/:1:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/multithread/"},{"categories":null,"content":"进程 进程是资源分配的最小单位。 ","date":"2020-11-16","objectID":"/multithread/:2:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/multithread/"},{"categories":null,"content":"线程 线程是 cpu 调度的最小调度。线程又分为内核线程，用户线程。 内核线程只运行在内核态，不受用户态的拖累。 用户线程是完全建立在用户空间的线程库，用户线程的创建、调度、同步和销毁在用户空间完成，不需要内核的帮助。用户线程又称为协程。 一个线程只能属于一个进程，但是一个进程可以有多个线程，多线程处理就是一个进程可以有多个线程在同一个时刻执行多个任务。 这些是比较官方的定义，简单理解就是运行一段程序，需要一定的资源，如cpu，系统内核会分配给进程，至于怎么分配这些资源可由线程去抢，如果某个线程占用资源(cpu)时间太长，内核为了平衡，会强行中断，切换给其他的线程执行，但是每次切换都是有代价的，需要把执行现场保留以确保后续恢复的时候可以正常执行，这就有了内核和用户态的切换（进程和线程都是受内核控制的）。那么问题来了，如果只在用户态切换，岂不是很好？还真是这样，go 语言就是这样实现。 ","date":"2020-11-16","objectID":"/multithread/:3:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/multithread/"},{"categories":null,"content":"python 多线程时遇到的坑 python 中如果要用多线程或者多进程时需要自己创建线程或者进程，这和go语言不一样，go语言只需要通过 go 关键字创建出协程，然后由runtime 进行调度（不需要自己处理进程与线程）。今天先看看python 中如何使用多线程与多进程。python 环境为 2.7.15 。 先看一段简单的代码 import threading import time ​ lock = threading.Lock() ​ def runner(i, p1, p2, p3=\"\", p4=\"\", **kwargs): \"\"\" :return: \"\"\" count = 0 print(\"线程{} param1:====\".format(i), p1) print(\"线程{} param2:====\".format(i), p2) print(\"线程{} param3:====\".format(i), p3) print(\"线程{} param3:====\".format(i), p4) while True: with lock: count += 1 print(\"线程{} 第 {} 秒 后: ......\".format(i, count)) time.sleep(1) if count == 5: break def main_thread(): \"\"\" 主线程的运行代码 :return: \"\"\" print(\"主线程开始执行\") time.sleep(1) print(\"主线程执行结束\") ​ def main(): \"\"\" :return: \"\"\" for i in range(5): thread = threading.Thread(target=runner, args=(i, \"a1\", \"a2\"), kwargs={\"p3\": \"p2\", \"p4\": \"p4\"}) thread.setName(\"线程{}\".format(i)) thread.start() ​ main_thread() ​ if __name__ == \"__main__\": main() ​ 这个应该能想的出来不同的线程的输出是交叉打印出来的，说明这是多个线程并发执行的。 现在假设有这么一个场景，有10台机器，每个机器上有10个容器需要重启，如果要并发的执行应该怎么做呢? 看看下面的代码有没有问题? import os ​ import threading ​ def runnner(hostip) : appIds = [ \"app-{}\".format(i) for i in range(10)] cmd = \"docker restart {}\".format(\" \".join(appIds)) print(cmd) os.system(\"ssh {hostip} {cmd}\".format(hostip=hostip,cmd=cmd)) ​ hosts = [\"10.0.0.1\", \"10.0.0.2\", \"10.0.0.3\" , \"10.0.0.4\", \"10.0.0.5\",\"10.0.0.6\", \"10.0.0.7\", \"10.0.0.8\" , \"10.0.0.9\", \"10.0.0.10\"] ​ for hostip in hosts : thread = threading.Thread(target=runnner, args=(hostip,)) thread.start() 看起来应该是没有问题的，然而真正执行的还是串行，没有到达并发执行的目的。问题出在哪里呢？ 在python 中线程执行需要先获取GIL锁（全局解释器锁），看起来是创建了多个线程，但是同一个时间点每个进程只能有一个线程获取这个锁并且执行，是一种伪多线程，如果在密集计算的场景，就会频繁的发生线程切换，这个是很耗时间的，还没有单线程效果好。那么问题又来了，什么会发生线程切换呢? 如果遇到io等待或者sleep 时肯定会发生切换，还有就是每100条指令切换一次线程。可以通过如下指令设置: sys.setcheckinterval 上面这里例子就没有触发线程的切换，当前面的线程执行完退出之后释放GIL锁，后续的线程才能执行，所以才有看起来是多线程的写法，但是确实单线程的效果。 改进的方法当然使用多进程，每个进程都有自己的GIL锁，可以真正的实现并发。进程并不是越多越好，创建进程开销比线程要大很多，如果进程之间有数据交换也比线程复杂，并且真正执行还是要落到cpu上去执行，进程多了也会造成排队，理论上和创建和cpu相同个数的进程性能最好。下面看看多进程的写法。 import os from multiprocessing import Process ​ def runnner(hostip) : appIds = [ \"app-{}\".format(i) for i in range(10)] cmd = \"docker restart {}\".format(\" \".join(appIds)) print(cmd) os.system(\"ssh {hostip} {cmd}\".format(hostip=hostip,cmd=cmd)) ​ ​ hosts = [\"10.0.0.{}\".format(i) for i in range(10)] ​ ​ for hostip in hosts : process = Process(target=runnner, args=(hostip,)) process.start() 当然可以用进程池控制进程的个数，如: import os ​ from multiprocessing import Pool ​ def runnner(hostip) : appIds = [ \"app-{}\".format(i) for i in range(10)] cmd = \"docker restart {}\".format(\" \".join(appIds)) print(cmd) os.system(\"ssh {hostip} {cmd}\".format(hostip=hostip,cmd=cmd)) ​ ​ hosts = [\"10.0.0.{}\".format(i) for i in range(10)] ​ p = Pool(4) ​ for hostip in hosts : p.apply_async(runnner, args=(hostip,)) # 异步执行 p.close() p.join() ","date":"2020-11-16","objectID":"/multithread/:4:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/multithread/"},{"categories":null,"content":"参考 https://docs.python.org/2/library/sys.html#sys.setcheckinterval ","date":"2020-11-16","objectID":"/multithread/:5:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/multithread/"},{"categories":null,"content":"python中的多线程与多进程（一）","date":"2020-11-16","objectID":"/python/multithread/","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/python/multithread/"},{"categories":null,"content":"导读 在编码的过程，多线程、多进程、并发、并行这些概念肯定不止一次的出现在我们面前。概念理解是一回事，但是能真正用好又是另一回事。不同的编程语言，并发编程难易程度相差还是很大的，正好这几天梳理了他们之间的关系与区别，分享给大家。（基于自己的理解谈谈，如果不对欢迎指出） 灵魂拷问：什么是线程？什么是进程？ ","date":"2020-11-16","objectID":"/python/multithread/:1:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/python/multithread/"},{"categories":null,"content":"进程 进程是资源分配的最小单位。 ","date":"2020-11-16","objectID":"/python/multithread/:2:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/python/multithread/"},{"categories":null,"content":"线程 线程是 cpu 调度的最小调度。线程又分为内核线程，用户线程。 内核线程只运行在内核态，不受用户态的拖累。 用户线程是完全建立在用户空间的线程库，用户线程的创建、调度、同步和销毁在用户空间完成，不需要内核的帮助。用户线程又称为协程。 一个线程只能属于一个进程，但是一个进程可以有多个线程，多线程处理就是一个进程可以有多个线程在同一个时刻执行多个任务。 这些是比较官方的定义，简单理解就是运行一段程序，需要一定的资源，如cpu，系统内核会分配给进程，至于怎么分配这些资源可由线程去抢，如果某个线程占用资源(cpu)时间太长，内核为了平衡，会强行中断，切换给其他的线程执行，但是每次切换都是有代价的，需要把执行现场保留以确保后续恢复的时候可以正常执行，这就有了内核和用户态的切换（进程和线程都是受内核控制的）。那么问题来了，如果只在用户态切换，岂不是很好？还真是这样，go 语言就是这样实现。 ","date":"2020-11-16","objectID":"/python/multithread/:3:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/python/multithread/"},{"categories":null,"content":"python 多线程时遇到的坑 python 中如果要用多线程或者多进程时需要自己创建线程或者进程，这和go语言不一样，go语言只需要通过 go 关键字创建出协程，然后由runtime 进行调度（不需要自己处理进程与线程）。今天先看看python 中如何使用多线程与多进程。python 环境为 2.7.15 。 先看一段简单的代码 import threading import time ​ lock = threading.Lock() ​ def runner(i, p1, p2, p3=\"\", p4=\"\", **kwargs): \"\"\" :return: \"\"\" count = 0 print(\"线程{} param1:====\".format(i), p1) print(\"线程{} param2:====\".format(i), p2) print(\"线程{} param3:====\".format(i), p3) print(\"线程{} param3:====\".format(i), p4) while True: with lock: count += 1 print(\"线程{} 第 {} 秒 后: ......\".format(i, count)) time.sleep(1) if count == 5: break def main_thread(): \"\"\" 主线程的运行代码 :return: \"\"\" print(\"主线程开始执行\") time.sleep(1) print(\"主线程执行结束\") ​ def main(): \"\"\" :return: \"\"\" for i in range(5): thread = threading.Thread(target=runner, args=(i, \"a1\", \"a2\"), kwargs={\"p3\": \"p2\", \"p4\": \"p4\"}) thread.setName(\"线程{}\".format(i)) thread.start() ​ main_thread() ​ if __name__ == \"__main__\": main() ​ 这个应该能想的出来不同的线程的输出是交叉打印出来的，说明这是多个线程并发执行的。 现在假设有这么一个场景，有10台机器，每个机器上有10个容器需要重启，如果要并发的执行应该怎么做呢? 看看下面的代码有没有问题? import os ​ import threading ​ def runnner(hostip) : appIds = [ \"app-{}\".format(i) for i in range(10)] cmd = \"docker restart {}\".format(\" \".join(appIds)) print(cmd) os.system(\"ssh {hostip} {cmd}\".format(hostip=hostip,cmd=cmd)) ​ hosts = [\"10.0.0.1\", \"10.0.0.2\", \"10.0.0.3\" , \"10.0.0.4\", \"10.0.0.5\",\"10.0.0.6\", \"10.0.0.7\", \"10.0.0.8\" , \"10.0.0.9\", \"10.0.0.10\"] ​ for hostip in hosts : thread = threading.Thread(target=runnner, args=(hostip,)) thread.start() 看起来应该是没有问题的，然而真正执行的还是串行，没有到达并发执行的目的。问题出在哪里呢？ 在python 中线程执行需要先获取GIL锁（全局解释器锁），看起来是创建了多个线程，但是同一个时间点每个进程只能有一个线程获取这个锁并且执行，是一种伪多线程，如果在密集计算的场景，就会频繁的发生线程切换，这个是很耗时间的，还没有单线程效果好。那么问题又来了，什么会发生线程切换呢? 如果遇到io等待或者sleep 时肯定会发生切换，还有就是每100条指令切换一次线程。可以通过如下指令设置: sys.setcheckinterval 上面这里例子就没有触发线程的切换，当前面的线程执行完退出之后释放GIL锁，后续的线程才能执行，所以才有看起来是多线程的写法，但是确实单线程的效果。 改进的方法当然使用多进程，每个进程都有自己的GIL锁，可以真正的实现并发。进程并不是越多越好，创建进程开销比线程要大很多，如果进程之间有数据交换也比线程复杂，并且真正执行还是要落到cpu上去执行，进程多了也会造成排队，理论上和创建和cpu相同个数的进程性能最好。下面看看多进程的写法。 import os from multiprocessing import Process ​ def runnner(hostip) : appIds = [ \"app-{}\".format(i) for i in range(10)] cmd = \"docker restart {}\".format(\" \".join(appIds)) print(cmd) os.system(\"ssh {hostip} {cmd}\".format(hostip=hostip,cmd=cmd)) ​ ​ hosts = [\"10.0.0.{}\".format(i) for i in range(10)] ​ ​ for hostip in hosts : process = Process(target=runnner, args=(hostip,)) process.start() 当然可以用进程池控制进程的个数，如: import os ​ from multiprocessing import Pool ​ def runnner(hostip) : appIds = [ \"app-{}\".format(i) for i in range(10)] cmd = \"docker restart {}\".format(\" \".join(appIds)) print(cmd) os.system(\"ssh {hostip} {cmd}\".format(hostip=hostip,cmd=cmd)) ​ ​ hosts = [\"10.0.0.{}\".format(i) for i in range(10)] ​ p = Pool(4) ​ for hostip in hosts : p.apply_async(runnner, args=(hostip,)) # 异步执行 p.close() p.join() ","date":"2020-11-16","objectID":"/python/multithread/:4:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/python/multithread/"},{"categories":null,"content":"参考 https://docs.python.org/2/library/sys.html#sys.setcheckinterval https://mp.weixin.qq.com/s/nrT8iIe73POFTBpCdfXupA ","date":"2020-11-16","objectID":"/python/multithread/:5:0","tags":["python","多线程","多进程"],"title":"python中的多线程与多进程（一）","uri":"/python/multithread/"},{"categories":null,"content":"投稿到 servicemesh 社区的文章","date":"2020-11-10","objectID":"/elk/","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"ELK 这篇文档是由我投稿的云原生社区的文章，节选自 istio-handbook，如果有兴趣可以参考这本书。 ELK 指的是由 Elasticsearch + Logstash + Kibana 组成的日志采集、存储、展示为一体的日志解决方案，简称 “ELK Stack”。ELK Stack 还包含 Beats（如Filebeat、Metricbeat、Heartbeat等）、Kafka等成员，是目前主流的一种日志解决方案。 Elasticsearch 是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。 Logstash 是免费且开放的服务器端数据处理管道，能够从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的“存储库”中。Logstash 比较耗资源，在实践中我们一般用作实时解析和转换数据。Logstash 采用可插拔框架，拥有 200 多个插件。您可以将不同的输入选择、过滤器和输出选择混合搭配、精心安排，让它们在管道中和谐地运行。 Kibana 是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。 Kafka 是由 Apache 软件基金会开发的一个开源流处理平台，由 Scala 和 Java 编写。用来做缓冲，当日志量比较大的时候可以缓解后端 Elasticsearch 的压力。 Beats 是数据采集的得力工具。Beats家族成员包括如下： Filebeat：用于日志文件采集，内置了多种模块（Apache、Cisco ASA、Microsoft Azure、NGINX、MySQL 等等）。 Metricbeat： 用于指标采集。 Packetbeat：用于网络数据采集。 Winlogbeat：用于Windows 事件采集。 Auditbeat：用于审计日志采集。 Heartbeat：用于运行时间采集。 其中 Filebeat 被经常用来收集 Node 或者 Pod 中的日志。 Beats 用于收集客户端的日志，发送给缓存队列如Kafka，目的是为了解耦数据收集与解析入库的过程，同时提高了可扩展性，使日志系统有峰值处理能力，不会因为突发的访问压力造成日志系统奔溃。缓存队列可选的还有 Redis，由于 Redis 是内存型，很容易写满，生产环境建议用 kafka。Logstash 从 缓存队列中消费日志解析处理之后写到 Elasticsearch，通过 Kibana 展示给最终用户。 ","date":"2020-11-10","objectID":"/elk/:0:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"采集方案 Filebeat 有两种部署模式，一是通过 DaemonSet 方式部署，二是通过 Sidecar 方式部署，Filebeat 采集后发送到 Kafka ，再由 Logstash 从 Kafka 中消费写到 Elasticsearch。 ","date":"2020-11-10","objectID":"/elk/:1:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"DaemonSet 方式部署 开启 Envoy 的访问日志输出到 stdout ，以 DaemonSet 的方式在每一台集群节点部署 Filebeat ，并将日志目录挂载至 Filebeat Pod，实现对 Envoy 访问日志的采集。 ","date":"2020-11-10","objectID":"/elk/:1:1","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"Sidecar 方式部署 Filebeat 和 Envoy 部署在同一个 Pod 内，共享日志数据卷， Envoy 写，Filebeat 读，实现对 Envoy 访问日志的采集。 ","date":"2020-11-10","objectID":"/elk/:1:2","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"部署 ELK 有了以上的基础，我们开始部署 ELK Stack ","date":"2020-11-10","objectID":"/elk/:2:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"部署 Kafka 首先，创建一个新的 namespace 用于部署 ELK Stack： # Logging Namespace. All below are a part of this namespace. apiVersion: v1 kind: Namespace metadata: name: logging 接下来，部署 Kafka 服务。 Kafka 通过 Zookeeper 管理集群配置，所以在部署 Kafka 需要先部署 Zookeeper。 Zookeeper 是一个分布式的，开放源码的分布式应用程序协调服务。 Kafka 与 Zookeeper 都是有状态服务，部署时需要选择 StatefulSet 。 部署 Zookeeper Service apiVersion:v1kind:Servicemetadata:name:zookeeper-clusternamespace:loggingspec:selector:app:zookeeper-clusterports:- name:httpport:2181targetPort:2181type:ClusterIP Zookeeper 在集群内使用，供 Kafka 使用，创建类型为 ClusterIP 的 Service 。 Zookeeper 的默认端口是2181。 部署 Zookeeper ConfigMap apiVersion:v1kind:ConfigMapmetadata:name:zookeeper-confignamespace:loggingdata:ZOO_CONF_DIR:/confZOO_PORT:\"2181\" Zookeeper 配置文件中的 key 都可以 以 ZOO_ 加大写的方式设置到环境变量中，使之生效。 这里仅列举部分配置。 部署 Zookeeper StatefulSet apiVersion:apps/v1kind:StatefulSetmetadata:name:zookeepernamespace:loggingspec:serviceName:zookeeper-clusterreplicas:1updateStrategy:type:RollingUpdateselector:matchLabels:app:zookeeper-clustertemplate:metadata:labels:app:zookeeper-clusterannotations:sidecar.istio.io/inject:\"false\"spec:containers:- name:zookeeperresources:requests:cpu:10mmemory:100Milimits:memory:200Miimage:zookeeperimagePullPolicy:IfNotPresentenvFrom:- configMapRef:name:zookeeper-configreadinessProbe:tcpSocket:port:2181initialDelaySeconds:5periodSeconds:10livenessProbe:tcpSocket:port:2181initialDelaySeconds:15periodSeconds:20ports:- containerPort:2181name:zk-client sidecar.istio.io/inject=false 标识此服务无需 sidecar 注入。 部署 Kafka Service apiVersion:v1kind:Servicemetadata:name:bootstrap-kafkanamespace:loggingspec:clusterIP:Noneports:- port:9092selector:app:kafka---apiVersion:v1kind:Servicemetadata:name:kafka-clusternamespace:loggingspec:ports:- name:httptargetPort:9092port:9092selector:app:kafkatype:ClusterIP 部署两个 Service 。 bootstrap-kafka 为后续部署 Kafka Statefulset 使用。 kafka-cluster 为 Kafka 的访问入口，在生产中使用可以用其他的 Service 类型。 kafka 的默认端口是9092 部署 Kafka ConfigMap apiVersion:v1kind:ConfigMapmetadata:name:kafka-confignamespace:loggingdata:KAFKA_ADVERTISED_LISTENERS:\"PLAINTEXT://kafka-cluster:9092\"KAFKA_LISTENERS:\"PLAINTEXT://0.0.0.0:9092\"KAFKA_ZOOKEEPER_CONNECT:\"zookeeper-cluster:2181\"KAFKA_LOG_RETENTION_HOURS:\"48\"KAFKA_NUM_PARTITIONS:\"30\" Kafka 配置文件（server.properties）中的 key 都可以 以 KAFKA_ 加大写的方式设置到环境变量中，使之生效。 KAFKA_ADVERTISED_LISTENERS 为 Kafka 监听的服务地址。 KAFKA_ZOOKEEPER_CONNECT 为前面部署的 Zookeeper 的服务地址。 KAFKA_LOG_RETENTION_HOURS 为 Kafka 数据保留的时间，超过这个时间将会被清理，可以根据实际情况进行调整。 KAFKA_NUM_PARTITIONS 为创建 Kafka topic 时的默认分片数，设置大一些可以增加 Kafka 的吞吐量。 这里仅列举部分配置。 部署 Kafka StatefulSet apiVersion:apps/v1kind:StatefulSetmetadata:name:kafkanamespace:loggingspec:selector:matchLabels:app:kafkaserviceName:bootstrap-kafkareplicas:1template:metadata:labels:app:kafkaannotations:sidecar.istio.io/inject:\"false\"spec:containers:- name:kafka-brokerimage:russellgao/kafka:2.12-2.0.1ports:- name:insidecontainerPort:9092resources:requests:cpu:0.1memory:1024Milimits:memory:3069MireadinessProbe:tcpSocket:port:9092timeoutSeconds:1initialDelaySeconds:5periodSeconds:10livenessProbe:tcpSocket:port:9092timeoutSeconds:1initialDelaySeconds:15periodSeconds:20envFrom:- configMapRef:name:kafka-config kafka 对磁盘的 IO 要求较高，可以选择固态硬盘或者经过IO优化的磁盘，否则可能会成为日志系统的瓶颈。 请注意，本次实践没有把数据卷映射出来，在生产实践中使用 volumeClaimTemplates 来为 Pod 提供持久化存储。resources 可以根据实际情况调整。 ","date":"2020-11-10","objectID":"/elk/:2:1","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"部署 Logstash Logstash 是一个无状态服务，通过 Deployment 进行部署。 部署 Logstash ConfigMap apiVersion:v1kind:ConfigMapmetadata:name:logstash-confnamespace:loggingdata:logstash.conf:| input {http{host=\u003e\"0.0.0.0\"# default: 0.0.0.0port =\u003e 8080 # default:8080user=\u003e\"logstash\"password=\u003e\"aoDJ0JVgkfNPjarn\"response_headers=\u003e{\"Content-Type\"=\u003e\"text/plain\"\"Access-Control-Allow-Origin\"=\u003e\"*\"\"Access-Control-Allow-Methods\"=\u003e\"GET, POST, DELETE, PUT\"\"Access-Control-Allow-Headers\"=\u003e\"authorization, content-type\"\"Access-Control-Allow-Credentials\"=\u003etrue}}kafka{topics=\u003e\"istio\"bootstrap_servers=\u003e\"kafka-cluster:9092\"auto_offset_reset=\u003e\"earliest\"group_id=\u003e\"istio_kafka_gr\"consumer_threads=\u003e3codec=\u003e\"json\"}}filter{grok{match=\u003e{\"message\"=\u003e\"(?m)\\[%{TIMESTAMP_ISO8601:timestamp}\\] \"%{NOTSPACE:method}%{NOTSPACE:path}%{NOTSPACE:protocol}\" %{NUMBER:response_code:int} %{NOTSPACE:response_flags} \"%{NOTSPACE:istio_policy_status}\" \"%{NOTSPACE:upstream_transport_failure_reason}\" %{NUMBER:bytes_received:int} %{NUMBER:bytes_sent:int} %{NUMBER:duration:int} %{NUMBER:upstream_service_time:int} \"%{NOTSPACE:x_forwarded_for}\" \"%{NOTSPACE:user_agent}\" \"%{NOTSPACE:request_id}\" \"%{NOTSPACE:authority}\" \"%{NOTSPACE:upstream_host}\" %{NOTSPACE:upstream_cluster} %{NOTSPACE:upstream_local_address} %{NOTSPACE:downstream_local_address} %{NOTSPACE:downstream_remote_address} %{NOTSPACE:requested_server_name} %{NOTSPACE:route_name}\"}remove_field=\u003e[\"message\"]}date{match=\u003e[\"timestamp\",\"yyyy-MM-ddTHH:mm:ss.SSSZ\"]timezone=\u003e\"Asia/Shanghai\"}ruby{code=\u003e\"event.set('[@metadata][index_day]',(event.get('@timestamp').time.localtime + 8*60*60 ).strftime('%Y.%m.%d'))\"}}output{if\"_grokparsefailure\"notin[tags]{elasticsearch{user=\u003e\"elastic\"password=\u003e\"elastic\"hosts=\u003e[\"elasticsearch.com:9200\"]index=\u003e\"istio-%{[@metadata][index_day]}\"}}} Logstash 配置由3部分组成： input Logstash input 支持非常多的数据源，如 File、Elasticsearch、Beats、Redis、Kafka、Http等。 Http input 用于Logstash 的健康检查，也可通过 http 接口将日志直接发送到 Logstash，主要用于移动端的场景。 Kafka input 用于收集日志，一个input只能从一个 Topic 中读取数据，需要和后续的 Filebeat output 对应。 filter Logstash filter 支持非常多的插件，可以对数据进行解析、加工、转换，如 grok、date、ruby、json、drop等。 grok 用于对日志进行解析。 date 用于把 timestamp 转化成 elasticsearch 中的 @timestamp 字段，可以指定时区。 ruby 插件支持执行 ruby 代码，可以进行复杂逻辑的处理，此处的用法是 @timestamp 字段的时间加8小时，解决自动生成的索引时差问题。 output Logstash output 支持非常多的数据源，如 elasticsearch、cvs、jdbc 等。 此处是把 grok 解析成功的日志写到 elasticsearch 。 部署 Logstash Deployment apiVersion:apps/v1beta2kind:Deploymentmetadata:name:logstashnamespace:loggingspec:replicas:2selector:matchLabels:app:logstashtemplate:metadata:labels:app:logstashannotations:sidecar.istio.io/inject:\"false\"spec:volumes:- name:configconfigMap:name:logstash-confhostname:logstashcontainers:- name:logstashimage:logstash:7.2.0args:[\"-f\",\"/usr/share/logstash/pipeline/logstash.conf\",]imagePullPolicy:IfNotPresentvolumeMounts:- name:configmountPath:\"/usr/share/logstash/pipeline/logstash.conf\"readOnly:truesubPath:logstash.confresources:requests:cpu:0.5memory:1024Milimits:cpu:1.5memory:3072MireadinessProbe:tcpSocket:port:8080initialDelaySeconds:5periodSeconds:10livenessProbe:tcpSocket:port:8080initialDelaySeconds:15periodSeconds:20 Logstash 不需要对外发布服务，即不需要创建 Service，从 Kafka 中消费日志，处理完成之后写到 Elasticsearch 。 Logstash 只需要把配置文件挂载进去，无需挂载其他目录，排查错误时可通过 Logstash Console Log 进行查看。 部署 Logstash HorizontalPodAutoscaler apiVersion:autoscaling/v2beta1kind:HorizontalPodAutoscalermetadata:name:logstashnamespace:loggingspec:scaleTargetRef:apiVersion:apps/v1beta2kind:Deploymentname:logstashminReplicas:2maxReplicas:10metrics:- type:Resourceresource:name:cputargetAverageUtilization:80 Logstash 比较消费 CPU ，可以部署 HPA，可以根据日志量动态的扩所容。 Logstash 的压力对 CPU 比较敏感，可以只根据 CPU 这一个指标进行 HPA。 Logstash 的配置文件支持if/else条件判断，通过这种方式，一个 Logstash 集群可以支持比较多的日志格式。另外 Logstash 的 grok 语法相对复杂，可以使用 Kibana Dev Tools 工具进行调试，如下图： ","date":"2020-11-10","objectID":"/elk/:2:2","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"部署 Filebeat 这里仅给出 Filebeat DaemonSet 的部署过程。 部署 Filebeat ConfigMap apiVersion:v1kind:ConfigMapmetadata:name:filebeat-confnamespace:loggingdata:filebeat.yml:| filebeat:inputs:- paths:- /var/log- /var/lib/docker/containersignore_older:1hforce_close_files:true#强制filebeat在文件名改变时，关闭文件，会有丢失日志的风险close_older:1mfields_under_root:trueoutput:kafka:enabled:truehosts:[\"kafka-cluster:9092\"]topic:\"istio\"version:\"2.0.0\"partition.round_robin:reachable_only:falseworker:2max_retries:3bulk_max_size:2048timeout:30sbroker_timeout:10schannel_buffer_size:256keep_alive:60compression:gzipmax_message_bytes:1000000required_acks:1 input.paths 代表 Filebeat 监听的日志路径。 input.ignore_older 代表日志文件的修改时间超过这个之间，将会忽略，这个在 Filebeat 重启时很有效果，解决重复读取日志的问题。 out.kafka.hosts 和之前部署的 Kafka Service 对应。 out.kafka.topic 和之前部署的 Logstash ConfigMap 中的 input 对应。 部署 Filebeat DaemonSet apiVersion:apps/v1kind:DaemonSetmetadata:name:filebeatnamespace:logginglabels:app:filebeatspec:selector:matchLabels:app:filebeattemplate:metadata:labels:app:filebeatannotations:sidecar.istio.io/inject:\"false\"spec:containers:- name:filebeatimage:elastic/filebeat:7.2.0imagePullPolicy:IfNotPresentvolumeMounts:- name:configmountPath:\"/usr/share/filebeat/filebeat.yml\"readOnly:truesubPath:filebeat.yml- name:varlogmountPath:/var/log- name:varlibdockercontainersmountPath:/var/lib/docker/containersresources:requests:cpu:0.1memory:200Milimits:cpu:0.3memory:600Mivolumes:- name:varloghostPath:path:/var/log- name:varlibdockercontainershostPath:path:/var/lib/docker/containers- name:configconfigMap:name:filebeat-conf 这里声明了两个 hostPath 类型的数据卷，路径为日志存储的路径。 将宿主机的 /var/log 和 /var/lib/docker/containers 挂载到了 Filebeat Pod 内便于 Filebeat 收集日志。 Filebeat 不需要部署 Service 。 Filebeat 对资源消耗比较少，可忽略对 Node 的资源消耗。 ","date":"2020-11-10","objectID":"/elk/:2:3","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"小结 本节为大家介绍了 ELK 的原理和安装部署，以及如何收集日志。 ","date":"2020-11-10","objectID":"/elk/:3:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"参考 Beats Logstash Zookeeper ","date":"2020-11-10","objectID":"/elk/:4:0","tags":["kubernetes","istio"],"title":"istio中的ELK实践","uri":"/elk/"},{"categories":null,"content":"Hugo, the world's fastest framework for building websites","date":"2020-11-08","objectID":"/about/","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"简介 高维宗（russellgao），现就职于上海海鼎信息工程股份有限公司，担任运维开发经理。 ","date":"2020-11-08","objectID":"/about/:1:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"关注领域 专注于devops，aiops，golong，python，kubernetes，servicemesh，云原生，算法等领域，热衷于参与开源软件和开源社区。 ","date":"2020-11-08","objectID":"/about/:2:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"个人公众号 ","date":"2020-11-08","objectID":"/about/:3:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"投稿 如果有好的文章需要分享也可以投稿给作者哟！ ","date":"2020-11-08","objectID":"/about/:4:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"投稿指南 文章须为原创的技术文章 须包含作者的姓名，公司头衔和简要介绍 须通过在 github 提交 PR 的方式提供 ","date":"2020-11-08","objectID":"/about/:4:1","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"原创申明 本博客上的所有文档均为原创，在写入过程中不免参考其他人优秀的文章，一般都会在文末申明参考的文章，如有侵犯到您的权益请联系作者第一时间修改。 ","date":"2020-11-08","objectID":"/about/:5:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"转载说明 如需转载，请加注原文出处。 ","date":"2020-11-08","objectID":"/about/:6:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"Hugo, the world's fastest framework for building websites","date":"2020-11-08","objectID":"/golang/defer/","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"背景 在学习和使用 Go 的过程中发现，Go 在语言层面的设计有很多有趣的地方，所以准备用一个系列来细数这些有趣的地方。写这个系列一是为了加深自己的理解，二是愿意分享，分享 Go 中有趣的设计细节。每篇都会通过一个例子讲述一个细节，感兴趣的话可以关注一下哟！ ","date":"2020-11-08","objectID":"/golang/defer/:1:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"Go 介绍 Go（又称 Golang）是 Google 的 Robert Griesemer，Rob Pike 及 Ken Thompson 开发的一种静态强类型、编译型语言。Go 语言语法与 C 相近，但功能上有：内存安全，GC（垃圾回收），结构形态及 CSP-style 并发计算。 Go 是由这3位大佬从2007年9月开始设计Go，2009年正式推出，到目前为止已经发了15个大版本，最新版为1.15.4。Go 现在广泛应用于云原生、中间件、还有各个业务平台，如 docker、kubernetes、etcd等都是Go语言编写。所以还是很有必要了解一下哟！ 下面简单说说Go的优缺点，俗话说：一万个人眼中有一万个哈姆雷特，所以优缺点都是相对而言，就谈谈自己使用过程中的感受，具体的优缺点会在后面的系列文章中一一提到，这里是抛砖引玉。 ","date":"2020-11-08","objectID":"/golang/defer/:2:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"Go 优点 语言层面支持并发：一个 go 关键字即可实现并发，其他编程语言依赖于库实现并发，这是有本质的区别 高性能 编译完之后生成二进制文件，可免去环境依赖 defer 机制 内置runtime 内嵌C支持，Go里面也可以直接包含C代码，利用现有的丰富的C库 跨平台编译 。。。 ","date":"2020-11-08","objectID":"/golang/defer/:3:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"Go 缺点 包管理 。。。 ","date":"2020-11-08","objectID":"/golang/defer/:4:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"defer 说起 Go 语言的最强大的地方，不得不说 Go 的并发机制和调度原理，但是今天不讲这些高深的理论，先从简单的开始。先思考这么几个问题（可以用自己熟悉的语言思考如何解决）: 对于文件的打开关闭，网络连接的建立断开场景，当打开时候应该何时关闭? 当调用一个函数，希望在函数返回时修改它的值，该如何解决? 先看看defer 的官方定义 ： A “defer” statement invokes a function whose execution is deferred to the moment the surrounding function returns, either because the surrounding function executed a return statement, reached the end of its function body, or because the corresponding goroutine is panicking. 意思是说，当包裹defer 的函数返回时或者包裹defer的函数执行到末尾时或者所在的goroutine发生panic时才会执行。 换句话说就是当函数执行完之后或者发生异常时再执行defer语句，就是说在被调函数返回之后，赋值给调用函数之前，还有机会执行其他指令，是不是很神奇。先看一段python 代码 : def f(x,y) : z = x / y z += 1 return z ​ if __name__ == \"__main__\" : result = f(4 /2) 当调用函数f，f返回给z并且赋值给result，在这时间，是没有任何机会执行其他的函数代码的。再看一段go代码: package main func main() { result := f(4, 2) fmt.Println(result) } ​ func f(x, y int) (r int) { r = x / y r += 1 defer func() { r += 2 }() return } 当调用函数f，f返回之后，在赋值之前执行了r +=2 。现在回想一下之前的两个问题，如果有defer 机制，是不是可以很好的解决。如对于第一个问题，在defer 语句中处理文件的关闭，连接的释放等，而不用考虑一些异常情况。 那defer的实现原理是怎样的呢? defer 其实是调用runtime.deferproc 进行实现，在defer 出现的地方，插入了call runtime.deferproc，然后在函数返回之前的地方，插入指令call runtime.deferreturn。 普通函数返回时，汇编代码类似于: add xx SP return 如果包含了defer 语句，汇编代码类似于: call runtime.deferreturn， add xx SP return goroutine的控制结构中，有一张表记录defer，调用runtime.deferproc时会将需要defer的表达式记录在表中，而在调用runtime.deferreturn的时候，则会依次从defer表中出栈并执行。 defer 在使用过程中也存在一些坑，看几个例子: 例1: func f() (result int) { defer func() { result++ }() return 10 } 例2: func f() (result int) { t := 10 defer func() { t = t + 1 }() return t } 例3: func f() (result int) { defer func(result int) { result = result + 1 }(result) return 10 } 大家可以先心里默默算一下他们的结果 第一个是11，第二个是10，第三个是10。 defer表达式可能会在设置函数返回值之后，在返回到调用函数之前，修改返回值，使最终的函数返回值与你想象的不一致。其实使用defer时，用一个简单的转换规则改写一下，就不会迷糊了。改写规则是将return语句拆成两句写，return xxx会被改写成: 返回值 = xxx 调用defer函数 空的return 例1 会被改写成: func f() (result int) { result = 10 // return语句不是一条原子调用，return xxx其实是赋值＋ret指令 defer func() { result++ }() return // 空的return指令 } 所以返回值是11 例2 会被改写成: func f() (result int) { t := 10 result = t // 赋值指令 defer func() { t = t + 1 //defer被插入到赋值与返回之间执行，这个例子中返回值 result没被修改过 }() return // 空的return指令 } 所以返回值是10 例3 就留给大家自己改写一下啦，有兴趣可以私我沟通哟！ ","date":"2020-11-08","objectID":"/golang/defer/:5:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"总结 这篇主要做了对Go语言的介绍和优缺点，分析了defer 的用法以及实现原理，最后用例子展示了使用过程中可能会存在的坑。下篇预告: Go 的调度模型，欢迎关注!!! 如果有理解不正确的地方，欢迎指出。 ","date":"2020-11-08","objectID":"/golang/defer/:6:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/golang/defer/"},{"categories":null,"content":"Hugo, the world's fastest framework for building websites","date":"2020-11-08","objectID":"/defer/","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"背景 在学习和使用 Go 的过程中发现，Go 在语言层面的设计有很多有趣的地方，所以准备用一个系列来细数这些有趣的地方。写这个系列一是为了加深自己的理解，二是愿意分享，分享 Go 中有趣的设计细节。每篇都会通过一个例子讲述一个细节，感兴趣的话可以关注一下哟！ ","date":"2020-11-08","objectID":"/defer/:1:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"Go 介绍 Go（又称 Golang）是 Google 的 Robert Griesemer，Rob Pike 及 Ken Thompson 开发的一种静态强类型、编译型语言。Go 语言语法与 C 相近，但功能上有：内存安全，GC（垃圾回收），结构形态及 CSP-style 并发计算。 Go 是由这3位大佬从2007年9月开始设计Go，2009年正式推出，到目前为止已经发了15个大版本，最新版为1.15.4。Go 现在广泛应用于云原生、中间件、还有各个业务平台，如 docker、kubernetes、etcd等都是Go语言编写。所以还是很有必要了解一下哟！ 下面简单说说Go的优缺点，俗话说：一万个人眼中有一万个哈姆雷特，所以优缺点都是相对而言，就谈谈自己使用过程中的感受，具体的优缺点会在后面的系列文章中一一提到，这里是抛砖引玉。 ","date":"2020-11-08","objectID":"/defer/:2:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"Go 优点 语言层面支持并发：一个 go 关键字即可实现并发，其他编程语言依赖于库实现并发，这是有本质的区别 高性能 编译完之后生成二进制文件，可免去环境依赖 defer 机制 内置runtime 内嵌C支持，Go里面也可以直接包含C代码，利用现有的丰富的C库 跨平台编译 。。。 ","date":"2020-11-08","objectID":"/defer/:3:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"Go 缺点 包管理 。。。 ","date":"2020-11-08","objectID":"/defer/:4:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"defer 说起 Go 语言的最强大的地方，不得不说 Go 的并发机制和调度原理，但是今天不讲这些高深的理论，先从简单的开始。先思考这么几个问题（可以用自己熟悉的语言思考如何解决）: 对于文件的打开关闭，网络连接的建立断开场景，当打开时候应该何时关闭? 当调用一个函数，希望在函数返回时修改它的值，该如何解决? 先看看defer 的官方定义 ： A “defer” statement invokes a function whose execution is deferred to the moment the surrounding function returns, either because the surrounding function executed a return statement, reached the end of its function body, or because the corresponding goroutine is panicking. 意思是说，当包裹defer 的函数返回时或者包裹defer的函数执行到末尾时或者所在的goroutine发生panic时才会执行。 换句话说就是当函数执行完之后或者发生异常时再执行defer语句，就是说在被调函数返回之后，赋值给调用函数之前，还有机会执行其他指令，是不是很神奇。先看一段python 代码 : def f(x,y) : z = x / y z += 1 return z ​ if __name__ == \"__main__\" : result = f(4 /2) 当调用函数f，f返回给z并且赋值给result，在这时间，是没有任何机会执行其他的函数代码的。再看一段go代码: package main func main() { result := f(4, 2) fmt.Println(result) } ​ func f(x, y int) (r int) { r = x / y r += 1 defer func() { r += 2 }() return } 当调用函数f，f返回之后，在赋值之前执行了r +=2 。现在回想一下之前的两个问题，如果有defer 机制，是不是可以很好的解决。如对于第一个问题，在defer 语句中处理文件的关闭，连接的释放等，而不用考虑一些异常情况。 那defer的实现原理是怎样的呢? defer 其实是调用runtime.deferproc 进行实现，在defer 出现的地方，插入了call runtime.deferproc，然后在函数返回之前的地方，插入指令call runtime.deferreturn。 普通函数返回时，汇编代码类似于: add xx SP return 如果包含了defer 语句，汇编代码类似于: call runtime.deferreturn， add xx SP return goroutine的控制结构中，有一张表记录defer，调用runtime.deferproc时会将需要defer的表达式记录在表中，而在调用runtime.deferreturn的时候，则会依次从defer表中出栈并执行。 defer 在使用过程中也存在一些坑，看几个例子: 例1: func f() (result int) { defer func() { result++ }() return 10 } 例2: func f() (result int) { t := 10 defer func() { t = t + 1 }() return t } 例3: func f() (result int) { defer func(result int) { result = result + 1 }(result) return 10 } 大家可以先心里默默算一下他们的结果 第一个是11，第二个是10，第三个是10。 defer表达式可能会在设置函数返回值之后，在返回到调用函数之前，修改返回值，使最终的函数返回值与你想象的不一致。其实使用defer时，用一个简单的转换规则改写一下，就不会迷糊了。改写规则是将return语句拆成两句写，return xxx会被改写成: 返回值 = xxx 调用defer函数 空的return 例1 会被改写成: func f() (result int) { result = 10 // return语句不是一条原子调用，return xxx其实是赋值＋ret指令 defer func() { result++ }() return // 空的return指令 } 所以返回值是11 例2 会被改写成: func f() (result int) { t := 10 result = t // 赋值指令 defer func() { t = t + 1 //defer被插入到赋值与返回之间执行，这个例子中返回值 result没被修改过 }() return // 空的return指令 } 所以返回值是10 例3 就留给大家自己改写一下啦，有兴趣可以私我沟通哟！ ","date":"2020-11-08","objectID":"/defer/:5:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"总结 这篇主要做了对Go语言的介绍和优缺点，分析了defer 的用法以及实现原理，最后用例子展示了使用过程中可能会存在的坑。下篇预告: Go 的调度模型，欢迎关注!!! 如果有理解不正确的地方，欢迎指出。 ","date":"2020-11-08","objectID":"/defer/:6:0","tags":["golang","defer"],"title":"细谈 Golang 中那些设计优美的细节-defer","uri":"/defer/"},{"categories":null,"content":"自己开源的项目","date":"2020-11-08","objectID":"/opensrouce/toolkit/","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"toolkit ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:0:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"作用 用于提供工作效率的工具箱，里面有各种工具，就比如真实工具箱中里面有扳手，各种大小的起子，钳子等 某些场景下确实可以达到事半功倍的效果 ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:1:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"安装 ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:2:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"源码安装 有 go 语言环境的可以直接用源码进行编译运行 git clone https://github.com/russellgao/toolkit.git cd toolkit make ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:2:1","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"二进制 可以直接在release 页面进行下载对应的操作系统的二进制文件 https://github.com/russellgao/toolkit/releases/ ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:2:2","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"用法 ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:3:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"本机运行 可以通过如下命令进行 gwz:toolkit gaoweizong$ tkctl --help tkctl is a toolkit entrypoint,run `tkctl --help` get more information. Usage: tkctl [flags] tkctl [command] Available Commands: help Help about any command replace 文本替换，支持正则替换和非正则替换，类似与linux下的sed，但比sed更好用，而且可以跨平台使用 secret 生成随机密码，支持1～100位长度，可以指定是否包含特殊字符 version tkctl version Flags: -h, --help help for tkctl -v, --version show the version and exit Use \"tkctl [command] --help\" for more information about a command. tkctl 中的子命令会不断更新，某个具体的功能请查看Available Commands:下的帮助文档，如文本替换 tkctl replace --help 文本替换，支持正则替换和非正则替换，类似与linux下的sed，但比sed更好用，而且可以跨平台使用 Usage: tkctl replace [flags] Flags: -d, --dirs string 需要替换的目录, 默认为当前路径 (default \".\") -h, --help help for replace -m, --mode string 替换的模式，支持正则（regexp）和非正则（text）两种模式，默认非正则， (default \"text\") -p, --pattern string 需要替换的pattern [required] -r, --repl string 目标字符串 [required] ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:3:1","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"docker 如果本地有docker环境，也可以不用下载二进制的制品，可以通过docker 环境直接运行 docker run -it --rm russellgao/toolkit:latest tkctl --help # 如果有需要可以把目录挂载进去 docker run -it -v /data:/data --rm russellgao/toolkit:latest tkctl --help ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:3:2","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"适用范围 可以跨平台使用 mac windows linux ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:4:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"开发环境 go 1.14.2 ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:5:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"支持的功能 ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:6:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"1.0.0 文本正则替换 生成随机密码 ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:6:1","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"未来展望 期望可以成为一个完整的工具箱，可以解决日常工作中的繁杂事情。 ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:7:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"项目地址 https://github.com/russellgao/toolkit ","date":"2020-11-08","objectID":"/opensrouce/toolkit/:8:0","tags":["golang","toolkit"],"title":"自己开源的项目 - toolkit","uri":"/opensrouce/toolkit/"},{"categories":null,"content":"如何利用 python 操纵 oracle","date":"2020-07-09","objectID":"/oracle/","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"安装库 pip3 install sqlalchemy pip3 install cx_Oracle ","date":"2020-07-09","objectID":"/oracle/:1:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"安装客户端 oracle 客户端下载页面: https://www.oracle.com/database/technologies/instant-client/downloads.html ","date":"2020-07-09","objectID":"/oracle/:2:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"mac https://www.oracle.com/database/technologies/instant-client/macos-intel-x86-downloads.html 在上面的页面下载之后执行: # 解压 cd ~ unzip instantclient-basic-macos.x64-19.3.0.0.0dbru.zip # 创建link mkdir ~/lib ln -s ~/instantclient_19_3/libclntsh.dylib ~/lib/ ","date":"2020-07-09","objectID":"/oracle/:2:1","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"linux https://www.oracle.com/database/technologies/instant-client/linux-x86-64-downloads.html ","date":"2020-07-09","objectID":"/oracle/:2:2","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"windows https://www.oracle.com/database/technologies/instant-client/winx64-64-downloads.html ","date":"2020-07-09","objectID":"/oracle/:2:3","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"使用 在上面装好库和oracle client 就可以用python 操作 oracle 了 简单用法参见 : from sqlalchemy import * # 连接oracle engine = create_engine('oracle://username:passwoed@xxxxx', encoding=\"utf8\",echo=True) connection = engine.connect() # table, 会根据表名自动生成Table 对象 meta = MetaData() t = Table(\"abcd\",meta,autoload=True,autoload_with=engine) # 获取列 columns = t.c print(columns) # 查询 # s = select([t]) # s = select([t]).where(t.c.name == \"xxxx\") s = select([t]).where(t.c.code == \"xxxx\") result = connection.execute(s) for row in result : print(row[t.c.gid],row[t.c.code],row[t.c.name],row[t.c.note]) result.close() print(\"end\") ","date":"2020-07-09","objectID":"/oracle/:3:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"报错 如果报如下错误: sqlalchemy.exc.DatabaseError: (cx_Oracle.DatabaseError) DPI-1047: Cannot locate a 64-bit Oracle Client library: \"dlopen(libclntsh.dylib, 1): image not found\". See https://cx-oracle.readthedocs.io/en/latest/user_guide/installation.html for help (Background on this error at: http://sqlalche.me/e/13/4xp6) 说明oracle的 client 没有正确安装 如果报错如下: sqlalchemy.exc.DatabaseError: (cx_Oracle.DatabaseError) ORA-01017: invalid username/password; logon denied (Background on this error at: http://sqlalche.me/e/13/4xp6) 说明oracle 的用户密码不正确 ","date":"2020-07-09","objectID":"/oracle/:4:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"参考 https://docs.sqlalchemy.org/en/13/dialects/oracle.html https://www.cnblogs.com/iupoint/p/10932069.html ","date":"2020-07-09","objectID":"/oracle/:5:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/oracle/"},{"categories":null,"content":"如何利用 python 操纵 oracle","date":"2020-07-09","objectID":"/python/oracle/","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"安装库 pip3 install sqlalchemy pip3 install cx_Oracle ","date":"2020-07-09","objectID":"/python/oracle/:1:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"安装客户端 oracle 客户端下载页面: https://www.oracle.com/database/technologies/instant-client/downloads.html ","date":"2020-07-09","objectID":"/python/oracle/:2:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"mac https://www.oracle.com/database/technologies/instant-client/macos-intel-x86-downloads.html 在上面的页面下载之后执行: # 解压 cd ~ unzip instantclient-basic-macos.x64-19.3.0.0.0dbru.zip # 创建link mkdir ~/lib ln -s ~/instantclient_19_3/libclntsh.dylib ~/lib/ ","date":"2020-07-09","objectID":"/python/oracle/:2:1","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"linux https://www.oracle.com/database/technologies/instant-client/linux-x86-64-downloads.html ","date":"2020-07-09","objectID":"/python/oracle/:2:2","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"windows https://www.oracle.com/database/technologies/instant-client/winx64-64-downloads.html ","date":"2020-07-09","objectID":"/python/oracle/:2:3","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"使用 在上面装好库和oracle client 就可以用python 操作 oracle 了 简单用法参见 : from sqlalchemy import * # 连接oracle engine = create_engine('oracle://username:passwoed@xxxxx', encoding=\"utf8\",echo=True) connection = engine.connect() # table, 会根据表名自动生成Table 对象 meta = MetaData() t = Table(\"abcd\",meta,autoload=True,autoload_with=engine) # 获取列 columns = t.c print(columns) # 查询 # s = select([t]) # s = select([t]).where(t.c.name == \"xxxx\") s = select([t]).where(t.c.code == \"xxxx\") result = connection.execute(s) for row in result : print(row[t.c.gid],row[t.c.code],row[t.c.name],row[t.c.note]) result.close() print(\"end\") ","date":"2020-07-09","objectID":"/python/oracle/:3:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"报错 如果报如下错误: sqlalchemy.exc.DatabaseError: (cx_Oracle.DatabaseError) DPI-1047: Cannot locate a 64-bit Oracle Client library: \"dlopen(libclntsh.dylib, 1): image not found\". See https://cx-oracle.readthedocs.io/en/latest/user_guide/installation.html for help (Background on this error at: http://sqlalche.me/e/13/4xp6) 说明oracle的 client 没有正确安装 如果报错如下: sqlalchemy.exc.DatabaseError: (cx_Oracle.DatabaseError) ORA-01017: invalid username/password; logon denied (Background on this error at: http://sqlalche.me/e/13/4xp6) 说明oracle 的用户密码不正确 ","date":"2020-07-09","objectID":"/python/oracle/:4:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"参考 https://docs.sqlalchemy.org/en/13/dialects/oracle.html https://www.cnblogs.com/iupoint/p/10932069.html ","date":"2020-07-09","objectID":"/python/oracle/:5:0","tags":["python","oracle","数据库"],"title":"如何利用 python 操纵 oracle","uri":"/python/oracle/"},{"categories":null,"content":"pod 配置文件说明","date":"2020-06-18","objectID":"/kubernetes/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/","tags":["kubernetes","pod"],"title":"pod 配置文件说明","uri":"/kubernetes/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/"},{"categories":null,"content":"Pod的定义文件 apiVersion:v1kind:Podmetadata:name:stringnamaspace:stringlabels:- name:stringannotations:- name:stringspec:containers:- name:string# 使用的镜像image:stringimagePullPolicy:[Always|Never|IfNotPresent]command:[string]args:[string]# 工作目录workingDir:stringvolumeMounts:- name:stringmountPath:stringreadOnly:booleanports:- name:stringcontainerPort:inthostPort:intprotocol:stringenv:- name:stringvalue:stringresources:limits:cpu:stringmemory:stringrequests:cpu:stringmemory:stringlivenessProbe:exec:command:[string]httpGet:path:stringport:inthost:stringscheme:stringhttpHeaders:- name:stringvalue:stringtcpSocket:port:int# 多久之后去检查initialDelaySeconds:number# 健康检查超时时间timeoutSeconds:number# 多长时间检查一次periodSeconds:number# 成功的阀值，检查几次成功才算成功successThreshold:0# 失败的阀值，检查几次失败才算失败failureThreshold:0securityContext:# 详细参见 pod_SecurityContext 章节# securityContext 可以配置pod 或者container 级别runAsUser:1000# 运行的用户runAsGroup:3000# 运行的用户组fsGroup:2000privileged:bool# 是否以privileged 权限运行，即这是这个进程拥有特权allowPrivilegeEscalation:bool# 控制一个进程是否能比其父进程获取更多的权限，如果一个容器以privileged权限运行或具有CAP_SYS_ADMIN权限，则AllowPrivilegeEscalation的值将总是truecapabilities:add:[\"NET_ADMIN\",\"SYS_TIME\",\"...\"]# 给某个特定的进程privileged权限，而不用给root用户所有的privileged权限terminationMessagePath:/dev/termination-log# 容器终止的日志文件terminationMessagePolicy:[File|FallbackToLogsOnError]# 默认为File, 容器终止消息输出到文件restartPolicy:[Always|Never|OnFailure]# 重启策略，默认为 AlwaysnodeSelector:object# 通过label 选取nodednsPolicy:ClusterFirst# pod 的 dns 策略 ,可以配置如下值# Default : 和宿主机的DNS完全一致# ClusterFirst: 把集群的DNS写入到Pod的DNS配置，但是如果设置了HostNetwork=true，就会强制设置为Default# ClusterFirstWithHostNet: 把集群的DNS写入到Pod的DNS配置，不管是否设置HostNetwork# None: 忽略所有的DNS配置，一般来说，设置了None之后会自己手动再设置dnsConfigenableServiceLinks:true# Kubernetes支持两种查找服务的主要模式: 环境变量和DNS, 如果不需要服务环境变量, 将 `enableServiceLinks` 标志设置为 `false` 来禁用此模式terminationGracePeriodSeconds:10# 发出删除pod指令后多久之后真正的删除podserviceAccountName:jenkins# pod 绑定的serviceAccountpriorityClassName:# 给pod 设置优先级，参考 : https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/schedulerName:default-scheduler# 如果不配置则使用kubernetes 默认的default-scheduler，如果这个不满足要求则可以自定义一个scheduler# https://kubernetes.io/zh/docs/tasks/administer-cluster/configure-multiple-schedulers/affinity:# 亲和性设置tolerations:- effect:NoExecutekey:node.kubernetes.io/not-readyoperator:ExiststolerationSeconds:300- effect:NoExecutekey:node.kubernetes.io/unreachableoperator:ExiststolerationSeconds:300# 容忍设置imagePullSecrets:- name:string# 镜像拉取策略hostNetwork:false# 是否使用主机网络，默认为false，如果为true，pod直接用主机网络，在pod中可以看到主机的网络接口volumes:- name:stringemptyDir:{}hostPath:path:stringsecret:secretName:stringitems:- key:stringpath:stringconfigMap:name:stringitems:- key:stringpath:string# 目录挂载 ","date":"2020-06-18","objectID":"/kubernetes/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/:1:0","tags":["kubernetes","pod"],"title":"pod 配置文件说明","uri":"/kubernetes/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/"},{"categories":null,"content":"pod 具体的样例 apiVersion:v1kind:Podmetadata:labels:app:elastic-clustername:enode-0spec:containers:- env:- name:ES_JAVA_OPTSvalueFrom:configMapKeyRef:key:ES_JAVA_OPTSname:es-configimage:elasticsearch:6.7.2imagePullPolicy:IfNotPresentlivenessProbe:failureThreshold:3httpGet:path:/_cluster/health?local=trueport:9200scheme:HTTPperiodSeconds:600successThreshold:1timeoutSeconds:1name:elasticsearchports:- containerPort:9200name:es-httpprotocol:TCP- containerPort:9300name:es-transportprotocol:TCPreadinessProbe:failureThreshold:3httpGet:path:/_cluster/health?local=trueport:9200scheme:HTTPinitialDelaySeconds:30periodSeconds:20successThreshold:1timeoutSeconds:1resources:limits:cpu:\"2\"memory:10Girequests:cpu:\"1\"memory:8GisecurityContext:capabilities:add:- IPC_LOCK- SYS_RESOURCEprivileged:truerunAsUser:1000terminationMessagePath:/dev/termination-logterminationMessagePolicy:FilevolumeMounts:- mountPath:/usr/share/elasticsearch/dataname:es-data- mountPath:/usr/share/elasticsearch/logsname:es-logs- mountPath:/usr/share/elasticsearch/config/elasticsearch.ymlname:elasticsearch-configsubPath:elasticsearch.yml- mountPath:/var/run/secrets/kubernetes.io/serviceaccountname:default-token-k4r6freadOnly:truednsPolicy:ClusterFirstenableServiceLinks:truehostname:enode-0initContainers:- command:- sysctl- -w- vm.max_map_count=262144image:busyboximagePullPolicy:IfNotPresentname:init-sysctlresources:{}securityContext:privileged:trueterminationMessagePath:/dev/termination-logterminationMessagePolicy:FilevolumeMounts:- mountPath:/var/run/secrets/kubernetes.io/serviceaccountname:default-token-k4r6freadOnly:truepriority:0restartPolicy:AlwaysschedulerName:default-schedulersecurityContext:fsGroup:1000serviceAccount:defaultserviceAccountName:defaultsubdomain:elasticsearch-clusterterminationGracePeriodSeconds:30tolerations:- effect:NoExecutekey:node.kubernetes.io/not-readyoperator:ExiststolerationSeconds:300- effect:NoExecutekey:node.kubernetes.io/unreachableoperator:ExiststolerationSeconds:300volumes:- name:es-datapersistentVolumeClaim:claimName:es-data-enode-0- name:es-logspersistentVolumeClaim:claimName:es-logs-enode-0- configMap:defaultMode:420items:- key:elasticsearch.ymlpath:elasticsearch.ymlname:es-configname:elasticsearch-config- name:default-token-k4r6fsecret:defaultMode:420secretName:default-token-k4r6f ","date":"2020-06-18","objectID":"/kubernetes/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/:2:0","tags":["kubernetes","pod"],"title":"pod 配置文件说明","uri":"/kubernetes/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/"},{"categories":null,"content":"pod 配置文件说明","date":"2020-06-18","objectID":"/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/","tags":["kubernetes","pod"],"title":"pod 配置文件说明","uri":"/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/"},{"categories":null,"content":"Pod的定义文件 apiVersion:v1kind:Podmetadata:name:stringnamaspace:stringlabels:- name:stringannotations:- name:stringspec:containers:- name:string# 使用的镜像image:stringimagePullPolicy:[Always|Never|IfNotPresent]command:[string]args:[string]# 工作目录workingDir:stringvolumeMounts:- name:stringmountPath:stringreadOnly:booleanports:- name:stringcontainerPort:inthostPort:intprotocol:stringenv:- name:stringvalue:stringresources:limits:cpu:stringmemory:stringrequests:cpu:stringmemory:stringlivenessProbe:exec:command:[string]httpGet:path:stringport:inthost:stringscheme:stringhttpHeaders:- name:stringvalue:stringtcpSocket:port:int# 多久之后去检查initialDelaySeconds:number# 健康检查超时时间timeoutSeconds:number# 多长时间检查一次periodSeconds:number# 成功的阀值，检查几次成功才算成功successThreshold:0# 失败的阀值，检查几次失败才算失败failureThreshold:0securityContext:# 详细参见 pod_SecurityContext 章节# securityContext 可以配置pod 或者container 级别runAsUser:1000# 运行的用户runAsGroup:3000# 运行的用户组fsGroup:2000privileged:bool# 是否以privileged 权限运行，即这是这个进程拥有特权allowPrivilegeEscalation:bool# 控制一个进程是否能比其父进程获取更多的权限，如果一个容器以privileged权限运行或具有CAP_SYS_ADMIN权限，则AllowPrivilegeEscalation的值将总是truecapabilities:add:[\"NET_ADMIN\",\"SYS_TIME\",\"...\"]# 给某个特定的进程privileged权限，而不用给root用户所有的privileged权限terminationMessagePath:/dev/termination-log# 容器终止的日志文件terminationMessagePolicy:[File|FallbackToLogsOnError]# 默认为File, 容器终止消息输出到文件restartPolicy:[Always|Never|OnFailure]# 重启策略，默认为 AlwaysnodeSelector:object# 通过label 选取nodednsPolicy:ClusterFirst# pod 的 dns 策略 ,可以配置如下值# Default : 和宿主机的DNS完全一致# ClusterFirst: 把集群的DNS写入到Pod的DNS配置，但是如果设置了HostNetwork=true，就会强制设置为Default# ClusterFirstWithHostNet: 把集群的DNS写入到Pod的DNS配置，不管是否设置HostNetwork# None: 忽略所有的DNS配置，一般来说，设置了None之后会自己手动再设置dnsConfigenableServiceLinks:true# Kubernetes支持两种查找服务的主要模式: 环境变量和DNS, 如果不需要服务环境变量, 将 `enableServiceLinks` 标志设置为 `false` 来禁用此模式terminationGracePeriodSeconds:10# 发出删除pod指令后多久之后真正的删除podserviceAccountName:jenkins# pod 绑定的serviceAccountpriorityClassName:# 给pod 设置优先级，参考 : https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/schedulerName:default-scheduler# 如果不配置则使用kubernetes 默认的default-scheduler，如果这个不满足要求则可以自定义一个scheduler# https://kubernetes.io/zh/docs/tasks/administer-cluster/configure-multiple-schedulers/affinity:# 亲和性设置tolerations:- effect:NoExecutekey:node.kubernetes.io/not-readyoperator:ExiststolerationSeconds:300- effect:NoExecutekey:node.kubernetes.io/unreachableoperator:ExiststolerationSeconds:300# 容忍设置imagePullSecrets:- name:string# 镜像拉取策略hostNetwork:false# 是否使用主机网络，默认为false，如果为true，pod直接用主机网络，在pod中可以看到主机的网络接口volumes:- name:stringemptyDir:{}hostPath:path:stringsecret:secretName:stringitems:- key:stringpath:stringconfigMap:name:stringitems:- key:stringpath:string# 目录挂载 ","date":"2020-06-18","objectID":"/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/:1:0","tags":["kubernetes","pod"],"title":"pod 配置文件说明","uri":"/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/"},{"categories":null,"content":"pod 具体的样例 apiVersion:v1kind:Podmetadata:labels:app:elastic-clustername:enode-0spec:containers:- env:- name:ES_JAVA_OPTSvalueFrom:configMapKeyRef:key:ES_JAVA_OPTSname:es-configimage:elasticsearch:6.7.2imagePullPolicy:IfNotPresentlivenessProbe:failureThreshold:3httpGet:path:/_cluster/health?local=trueport:9200scheme:HTTPperiodSeconds:600successThreshold:1timeoutSeconds:1name:elasticsearchports:- containerPort:9200name:es-httpprotocol:TCP- containerPort:9300name:es-transportprotocol:TCPreadinessProbe:failureThreshold:3httpGet:path:/_cluster/health?local=trueport:9200scheme:HTTPinitialDelaySeconds:30periodSeconds:20successThreshold:1timeoutSeconds:1resources:limits:cpu:\"2\"memory:10Girequests:cpu:\"1\"memory:8GisecurityContext:capabilities:add:- IPC_LOCK- SYS_RESOURCEprivileged:truerunAsUser:1000terminationMessagePath:/dev/termination-logterminationMessagePolicy:FilevolumeMounts:- mountPath:/usr/share/elasticsearch/dataname:es-data- mountPath:/usr/share/elasticsearch/logsname:es-logs- mountPath:/usr/share/elasticsearch/config/elasticsearch.ymlname:elasticsearch-configsubPath:elasticsearch.yml- mountPath:/var/run/secrets/kubernetes.io/serviceaccountname:default-token-k4r6freadOnly:truednsPolicy:ClusterFirstenableServiceLinks:truehostname:enode-0initContainers:- command:- sysctl- -w- vm.max_map_count=262144image:busyboximagePullPolicy:IfNotPresentname:init-sysctlresources:{}securityContext:privileged:trueterminationMessagePath:/dev/termination-logterminationMessagePolicy:FilevolumeMounts:- mountPath:/var/run/secrets/kubernetes.io/serviceaccountname:default-token-k4r6freadOnly:truepriority:0restartPolicy:AlwaysschedulerName:default-schedulersecurityContext:fsGroup:1000serviceAccount:defaultserviceAccountName:defaultsubdomain:elasticsearch-clusterterminationGracePeriodSeconds:30tolerations:- effect:NoExecutekey:node.kubernetes.io/not-readyoperator:ExiststolerationSeconds:300- effect:NoExecutekey:node.kubernetes.io/unreachableoperator:ExiststolerationSeconds:300volumes:- name:es-datapersistentVolumeClaim:claimName:es-data-enode-0- name:es-logspersistentVolumeClaim:claimName:es-logs-enode-0- configMap:defaultMode:420items:- key:elasticsearch.ymlpath:elasticsearch.ymlname:es-configname:elasticsearch-config- name:default-token-k4r6fsecret:defaultMode:420secretName:default-token-k4r6f ","date":"2020-06-18","objectID":"/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/:2:0","tags":["kubernetes","pod"],"title":"pod 配置文件说明","uri":"/pod%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E/"},{"categories":null,"content":"位运算合集","date":"2020-05-30","objectID":"/argorithm/bit/","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位运算 计算机中的数在内存中都是以二进制形式进行存储的，用位运算就是直接对整数在内存中的二进制位进行操作，因此其执行效率非常高，在程序中尽量使用位运算进行操作，这会大大提高程序的性能。 ","date":"2020-05-30","objectID":"/argorithm/bit/:0:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位操作符 ","date":"2020-05-30","objectID":"/argorithm/bit/:1:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"\u0026 与运算 \u0026 与运算 两个位都是 1 时，结果才为 1，否则为 0，如 1 0 0 1 1 \u0026 1 1 0 0 1 ------------------------------ 1 0 0 0 1 ","date":"2020-05-30","objectID":"/argorithm/bit/:1:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"| 或运算 两个位都是 0 时，结果才为 0，否则为 1，如 1 0 0 1 1 | 1 1 0 0 1 ------------------------------ 1 1 0 1 1 ","date":"2020-05-30","objectID":"/argorithm/bit/:1:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"^ 异或运算 两个位相同则为 0，不同则为 1，如 1 0 0 1 1 ^ 1 1 0 0 1 ----------------------------- 0 1 0 1 0 ","date":"2020-05-30","objectID":"/argorithm/bit/:1:3","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"~ 取反运算 0 则变为 1，1 则变为 0，如 ~ 1 0 0 1 1 ----------------------------- 0 1 1 0 0 ","date":"2020-05-30","objectID":"/argorithm/bit/:1:4","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"« 左移运算 向左进行移位操作，高位丢弃，低位补 0,如 int a = 8; a \u003c\u003c 3; 移位前：0000 0000 0000 0000 0000 0000 0000 1000 移位后：0000 0000 0000 0000 0000 0000 0100 0000 左移n为的值即为当前值*2^n, 如: a = 8 b = a\u003c\u003c3 # 64 c = a * (2 ** 3) # 64 ","date":"2020-05-30","objectID":"/argorithm/bit/:1:5","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"»右移运算 向右进行移位操作，对无符号数，高位补 0，对于有符号数，高位补符号位，如 unsigned int a = 8; a \u003e\u003e 3; 移位前：0000 0000 0000 0000 0000 0000 0000 1000 移位后：0000 0000 0000 0000 0000 0000 0000 0001 ​ int a = -8; a \u003e\u003e 3; 移位前：1111 1111 1111 1111 1111 1111 1111 1000 移位前：1111 1111 1111 1111 1111 1111 1111 1111 ","date":"2020-05-30","objectID":"/argorithm/bit/:1:6","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"有符号数和无符号数 ","date":"2020-05-30","objectID":"/argorithm/bit/:2:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"有符号数 有符号数的定义是：字节的最高位作为符号位，其余的是数值位。例如一个字节中存储的二进制数为1100 1000，最高位1作为符号位，其余的7为 100 1000 作为数值为。 那么，符号位占据1位，就有0和1这样的两种数值，就有： 如果符号位为0，那么字节中存储的数值是正数 如果符号位为1，那么字节中存储的数值是负数 对于1100 1000这样的二进制数据，符号位是1，就表示负数。 在有符号数中，表示负数的算法是： 把数值位中存储的二进制数据，每个位都取反，就是原来为0的值变为1，原来为1的值变为0； 给对取反后的二进制数据加1，得到的数值就得到负数值； ","date":"2020-05-30","objectID":"/argorithm/bit/:2:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"无符号数 无符号数的定义是：没有符号位，所有的位数都是数值位。所以表示的都是正数。 ","date":"2020-05-30","objectID":"/argorithm/bit/:2:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"例子 例一 1100 1000这个数值，如果作为有符号数看待，那么符号位是1，数值位是100 1000。所以，符号位是1，所以，这个数据是负数。然后，表示成十进制时，对数值位的操作是： 数值位取反，得到011 0111； 对取反后的数值 011 0111加1得到011 1000，数值位的值为56； 那么，1100 1000这个二进制数据表示为“有符号数”时，就是-56这个数值。 如果作为无符号数看待，那么，就没有符号位，所有的位数都是数值位，所以11001000都作为数值位，表示的十进制数值是200 例二 例如，0111 0011这个数值，如果当做“有符号数”看待，那么，其符号位是0，所以，表示整数，数值位是115，所以，表示正115这个数值。如果当做无符号数看待，所有位都是数值位，计算得到115这个数值，所以，表示正115。所以我们可以总结 ","date":"2020-05-30","objectID":"/argorithm/bit/:2:3","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"总结 无符号数，总是表示正数。所有位数都表示数值位。 有符号数，可以表示正数和负数，最高位是符号位，其余位都是数值位。如果符号位是0，则表示正数；如果符号位是1，则表示负数。对于负数的表示方法是：数值位全部取反，再加1，得到的数值就是负数值。 ","date":"2020-05-30","objectID":"/argorithm/bit/:2:4","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"原码、反码、补码 ","date":"2020-05-30","objectID":"/argorithm/bit/:3:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"原码 原码的表示范围-127~-0, +0~+127, 共256个数字 正0的原码是0000 0000, 负0的原码是1000 0000, 有正0负0之分, 不符合人的习惯, 待解决. 原码有几个缺点，零分两种 +0 和 -0 。还有，在进行不同符号的加法运算或者同符号的减法运算的时候，不能直接判断出结果的正负。你需要将两个值的绝对值进行比较，然后进行加减操作 ，最后符号位由绝对值大的决定。于是反码就产生了。 ","date":"2020-05-30","objectID":"/argorithm/bit/:3:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"反码 除符号位, 原码其余位取反而得 +0：0000 0000，-0：1111 1111 仍然有正0负0之分。 正数的反码就是原码，负数的反码等于原码除符号位以外所有的位取反 举例说明： int类型的 3 的反码是 00000000 00000000 00000000 00000011 和原码一样没什么可说的 int类型的 -3 的反码是 11111111 11111111 11111111 11111100 除开符号位 所有位 取反 解决了加减运算的问题，但还是有正负零之分，然后就到补码了 ","date":"2020-05-30","objectID":"/argorithm/bit/:3:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"补码 在反码的基础上加1而得 对原码的两种0同时末位加1 +0：0000 0000，-0：0000 0000(因为溢出导致8位全0) 消除了正0负0之别, 如此一来, 便节省出一个数值表示方式1000 0000, 不能浪费, 用来表示-128, -128特殊之处在于没有相应的反码原码。也可以这样考虑: -1： 1111 1111 -2： 1111 1110（在-1的基础上减1，直接将补码减1即可） -3： 1111 1101（在-2补码基础上减1，以下类似） -4： 1111 1100 …… -127：1000 0001 -128：1000 0000 如此以来：8位补码表示范围是-128~+127因为0只有一种形式所以，仍然是256个数 若8位代表无符号数, 则表示范围是 : 0~255, 这就是为什么高级语言讲到数据类型， 正数的补码与原码相同，负数的补码为 其原码除符号位外所有位取反（得到反码了），然后最低位加1 ","date":"2020-05-30","objectID":"/argorithm/bit/:3:3","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"原码，反码，补码总结 正数的反码和补码都与原码相同。 负数的反码为对该数的原码除符号位外各位取反。 负数的补码为对该数的原码除符号位外各位取反，然后在最后一位加1　 优缺点: 原码最好理解了，但是加减法不够方便，还有两个零。。 反码稍微困难一些，解决了加减法的问题，但还是有有个零 补码理解困难，其他就没什么缺点了 ","date":"2020-05-30","objectID":"/argorithm/bit/:3:4","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"存储 计算机中的整数是用补码存储的，最高位为符号位 如果最高位为0则为正数，求值的时候，直接转为10进制即可。 最高位如果为1代表为负数，求值的时候，需要先把二进制的值按位取反，然后加1得到负数绝对值(相反数)的二进制码，然后转为10进制，加上负号即可。 ","date":"2020-05-30","objectID":"/argorithm/bit/:3:5","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"原码，反码，补码的应用 ","date":"2020-05-30","objectID":"/argorithm/bit/:3:6","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"负数的十进制和二进制转换 ","date":"2020-05-30","objectID":"/argorithm/bit/:4:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"十进制转二进制 方法为: 先转换为二进制 对二进制数求反 再将该二进制数加一 总而言之: 十进制数转换为二进制数求补码即为结果 例子 -32 转换为二进制 第一步：32（10）=00100000（2） 第二步：求反：11011111 第三步：加1:11100000 所以-32（10）=11100000（2） ","date":"2020-05-30","objectID":"/argorithm/bit/:4:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"二进制转十进制 方法为: 数值为取反 对该二进制加一 转换为10进制 例子 11001000 转换为十进制 第一步（数值位取反）： 10110111 第二步（加一）：10111000 第三步（十进制）：-56 所以11001000（2）=-56（10） ","date":"2020-05-30","objectID":"/argorithm/bit/:4:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"十进制数求反的规律 下面都是以10进制表示: ","date":"2020-05-30","objectID":"/argorithm/bit/:5:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"负数求反 负数求反等于其绝对值 -1 如: num = -5 num1 = ~num # 4 ","date":"2020-05-30","objectID":"/argorithm/bit/:5:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"正数求反 正数求反等于其值 +1 的负数 如: num = 4 num1 = ~num # -5 ","date":"2020-05-30","objectID":"/argorithm/bit/:5:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"二进制的应用场景 ","date":"2020-05-30","objectID":"/argorithm/bit/:6:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位操作实现乘除法 数 a 向右移一位，相当于将 a 除以 2；数 a 向左移一位，相当于将 a 乘以 2 a = 2 a \u003e\u003e 1 # ---\u003e 1 a \u003c\u003c 1 # ---\u003e 4 ","date":"2020-05-30","objectID":"/argorithm/bit/:6:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位操作交换两数 位操作交换两数可以不需要第三个临时变量，虽然普通操作也可以做到，但是没有其效率高 # 普通操作 def swap(a: int, b: int) -\u003e(int,int): a = a + b b = a - b a = a - b return a,b # 位与操作 def swap(a: int, b: int) -\u003e (int, int): \"\"\" 交换两个数 :param a: :param b: :return: \"\"\" a ^= b # a = (a^b) b ^= a # b = b ^ a = b ^ a ^ b a ^= b # a = a ^ b = a ^ a ^ b return a, b ","date":"2020-05-30","objectID":"/argorithm/bit/:6:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位操作判断奇偶数 只要根据数的最后一位是 0 还是 1 来决定即可，为 0 就是偶数，为 1 就是奇数 if(0 == (a \u0026 1)) { //偶数 } ","date":"2020-05-30","objectID":"/argorithm/bit/:6:3","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位操作交换符号 交换符号将正数变成负数，负数变成正数 func reversal(a int) int { return ^a + 1 } def reversal(a: int) -\u003e int: \"\"\" 求相反数 :param a: :return: \"\"\" return ~a + 1 正数取反加1，正好变成其对应的负数(补码表示)；负数取反加一，则变为其原码，即正数 ","date":"2020-05-30","objectID":"/argorithm/bit/:6:4","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位操作求绝对值 正数的绝对值是其本身，负数的绝对值正好可以对其进行取反加一求得，即我们首先判断其符号位（整数右移 31 位得到 0，负数右移 31 位得到 -1,即 0xffffffff），然后根据符号进行相应的操作 def abs(a: int) -\u003e int: i = a \u003e\u003e 31 result = a if i == 0 else ~a + 1 return result 上面的操作可以进行优化，可以将 i == 0 的条件判断语句去掉。我们都知道符号位 i 只有两种情况，即 i = 0 为正，i = -1 为负。对于任何数与 0 异或都会保持不变，与 -1 即 0xffffffff 进行异或就相当于对此数进行取反,因此可以将上面三目元算符转换为((a^i)-i)，即整数时 a 与 0 异或得到本身，再减去 0，负数时与 0xffffffff 异或将 a 进行取反，然后在加上 1，即减去 i(i =-1) def abs(a: int) -\u003e int: \"\"\" 求绝对值 :param a: :return: \"\"\" i = a \u003e\u003e 31 result = (a ^ i) - i return result or func abs(a int) int { i := a \u003e\u003e 31 return (a ^ i) - i } ","date":"2020-05-30","objectID":"/argorithm/bit/:6:5","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位操作进行高低位交换 给定一个 16 位的无符号整数，将其高 8 位与低 8 位进行交换，求出交换后的值，如 从上面移位操作我们可以知道，只要将无符号数 a»8 即可得到其高 8 位移到低 8 位，高位补 0；将 a « 8 即可将 低 8 位移到高 8 位，低 8 位补 0，然后将 a » 8 和 a«8 进行或操作既可求得交换后的结果 。 unsigned short a = 34520; a = (a \u003e\u003e 8) | (a \u003c\u003c 8); ","date":"2020-05-30","objectID":"/argorithm/bit/:6:6","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位操作统计二进制中 1 的个数 统计二进制1的个数可以分别获取每个二进制位数，然后再统计其1的个数，此方法效率比较低。 这里介绍另外一种高效的方法，同样以 34520 为例， 我们计算其 a \u0026= (a-1)的结果： 第一次：计算前：1000 0110 1101 1000 计算后：1000 0110 1101 0000 第二次：计算前：1000 0110 1101 0000 计算后：1000 0110 1100 0000 第三次：计算前：1000 0110 1100 0000 计算后：1000 0110 1000 0000 我们发现，每计算一次二进制中就少了一个 1，则我们可以通过下面方法去统计：count = 0 def count_1(a: int) -\u003e int: \"\"\" 计算数值的二进制表示的1的数量 :param a: :return: \"\"\" count = 0 while (a): a = a \u0026 a - 1 count += 1 return count ","date":"2020-05-30","objectID":"/argorithm/bit/:6:7","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"求和 两数求和 func add(a int, b int) int { for b != 0 { sum := a ^ b carry := (a \u0026 b) \u003c\u003c 1 a = sum b = carry } return a } ","date":"2020-05-30","objectID":"/argorithm/bit/:6:8","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"比特位计数 给定一个非负整数 num。对于 0 ≤ i ≤ num 范围中的每个数字 i ，计算其二进制数中的 1 的数目并将它们作为数组返回。 示例 1: 输入: 2 输出: [0,1,1] 示例 2: 输入: 5 输出: [0,1,1,2,1,2] def countBits(num: int) -\u003e [int]: result = [0] * (num + 1) for i in range(1, num + 1): result[i] = result[i \u0026 i - 1] + 1 return result func countBits(num int) []int { result := make([]int, num+1) for i := 1; i \u003c num+1 ; i ++ { result[i] = result[i \u0026 (i-1)] + 1 } return result } ","date":"2020-05-30","objectID":"/argorithm/bit/:6:9","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"常用的特殊的数 0xaaaaaaaa = 10101010101010101010101010101010 (偶数位为1，奇数位为0） 0x55555555 = 1010101010101010101010101010101 (偶数位为0，奇数位为1） 0x33333333 = 110011001100110011001100110011 (1和0每隔两位交替出现) 0xcccccccc = 11001100110011001100110011001100 (0和1每隔两位交替出现) 0x0f0f0f0f = 00001111000011110000111100001111 (1和0每隔四位交替出现) 0xf0f0f0f0 = 11110000111100001111000011110000 (0和1每隔四位交替出现) 0xffffffff = 11111111111111111111111111111111 ","date":"2020-05-30","objectID":"/argorithm/bit/:7:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/argorithm/bit/"},{"categories":null,"content":"位运算合集","date":"2020-05-30","objectID":"/bit/","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位运算 计算机中的数在内存中都是以二进制形式进行存储的，用位运算就是直接对整数在内存中的二进制位进行操作，因此其执行效率非常高，在程序中尽量使用位运算进行操作，这会大大提高程序的性能。 ","date":"2020-05-30","objectID":"/bit/:0:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位操作符 ","date":"2020-05-30","objectID":"/bit/:1:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"\u0026 与运算 \u0026 与运算 两个位都是 1 时，结果才为 1，否则为 0，如 1 0 0 1 1 \u0026 1 1 0 0 1 ------------------------------ 1 0 0 0 1 ","date":"2020-05-30","objectID":"/bit/:1:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"| 或运算 两个位都是 0 时，结果才为 0，否则为 1，如 1 0 0 1 1 | 1 1 0 0 1 ------------------------------ 1 1 0 1 1 ","date":"2020-05-30","objectID":"/bit/:1:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"^ 异或运算 两个位相同则为 0，不同则为 1，如 1 0 0 1 1 ^ 1 1 0 0 1 ----------------------------- 0 1 0 1 0 ","date":"2020-05-30","objectID":"/bit/:1:3","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"~ 取反运算 0 则变为 1，1 则变为 0，如 ~ 1 0 0 1 1 ----------------------------- 0 1 1 0 0 ","date":"2020-05-30","objectID":"/bit/:1:4","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"« 左移运算 向左进行移位操作，高位丢弃，低位补 0,如 int a = 8; a \u003c\u003c 3; 移位前：0000 0000 0000 0000 0000 0000 0000 1000 移位后：0000 0000 0000 0000 0000 0000 0100 0000 左移n为的值即为当前值*2^n, 如: a = 8 b = a\u003c\u003c3 # 64 c = a * (2 ** 3) # 64 ","date":"2020-05-30","objectID":"/bit/:1:5","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"»右移运算 向右进行移位操作，对无符号数，高位补 0，对于有符号数，高位补符号位，如 unsigned int a = 8; a \u003e\u003e 3; 移位前：0000 0000 0000 0000 0000 0000 0000 1000 移位后：0000 0000 0000 0000 0000 0000 0000 0001 ​ int a = -8; a \u003e\u003e 3; 移位前：1111 1111 1111 1111 1111 1111 1111 1000 移位前：1111 1111 1111 1111 1111 1111 1111 1111 ","date":"2020-05-30","objectID":"/bit/:1:6","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"有符号数和无符号数 ","date":"2020-05-30","objectID":"/bit/:2:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"有符号数 有符号数的定义是：字节的最高位作为符号位，其余的是数值位。例如一个字节中存储的二进制数为1100 1000，最高位1作为符号位，其余的7为 100 1000 作为数值为。 那么，符号位占据1位，就有0和1这样的两种数值，就有： 如果符号位为0，那么字节中存储的数值是正数 如果符号位为1，那么字节中存储的数值是负数 对于1100 1000这样的二进制数据，符号位是1，就表示负数。 在有符号数中，表示负数的算法是： 把数值位中存储的二进制数据，每个位都取反，就是原来为0的值变为1，原来为1的值变为0； 给对取反后的二进制数据加1，得到的数值就得到负数值； ","date":"2020-05-30","objectID":"/bit/:2:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"无符号数 无符号数的定义是：没有符号位，所有的位数都是数值位。所以表示的都是正数。 ","date":"2020-05-30","objectID":"/bit/:2:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"例子 例一 1100 1000这个数值，如果作为有符号数看待，那么符号位是1，数值位是100 1000。所以，符号位是1，所以，这个数据是负数。然后，表示成十进制时，对数值位的操作是： 数值位取反，得到011 0111； 对取反后的数值 011 0111加1得到011 1000，数值位的值为56； 那么，1100 1000这个二进制数据表示为“有符号数”时，就是-56这个数值。 如果作为无符号数看待，那么，就没有符号位，所有的位数都是数值位，所以11001000都作为数值位，表示的十进制数值是200 例二 例如，0111 0011这个数值，如果当做“有符号数”看待，那么，其符号位是0，所以，表示整数，数值位是115，所以，表示正115这个数值。如果当做无符号数看待，所有位都是数值位，计算得到115这个数值，所以，表示正115。所以我们可以总结 ","date":"2020-05-30","objectID":"/bit/:2:3","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"总结 无符号数，总是表示正数。所有位数都表示数值位。 有符号数，可以表示正数和负数，最高位是符号位，其余位都是数值位。如果符号位是0，则表示正数；如果符号位是1，则表示负数。对于负数的表示方法是：数值位全部取反，再加1，得到的数值就是负数值。 ","date":"2020-05-30","objectID":"/bit/:2:4","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"原码、反码、补码 ","date":"2020-05-30","objectID":"/bit/:3:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"原码 原码的表示范围-127~-0, +0~+127, 共256个数字 正0的原码是0000 0000, 负0的原码是1000 0000, 有正0负0之分, 不符合人的习惯, 待解决. 原码有几个缺点，零分两种 +0 和 -0 。还有，在进行不同符号的加法运算或者同符号的减法运算的时候，不能直接判断出结果的正负。你需要将两个值的绝对值进行比较，然后进行加减操作 ，最后符号位由绝对值大的决定。于是反码就产生了。 ","date":"2020-05-30","objectID":"/bit/:3:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"反码 除符号位, 原码其余位取反而得 +0：0000 0000，-0：1111 1111 仍然有正0负0之分。 正数的反码就是原码，负数的反码等于原码除符号位以外所有的位取反 举例说明： int类型的 3 的反码是 00000000 00000000 00000000 00000011 和原码一样没什么可说的 int类型的 -3 的反码是 11111111 11111111 11111111 11111100 除开符号位 所有位 取反 解决了加减运算的问题，但还是有正负零之分，然后就到补码了 ","date":"2020-05-30","objectID":"/bit/:3:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"补码 在反码的基础上加1而得 对原码的两种0同时末位加1 +0：0000 0000，-0：0000 0000(因为溢出导致8位全0) 消除了正0负0之别, 如此一来, 便节省出一个数值表示方式1000 0000, 不能浪费, 用来表示-128, -128特殊之处在于没有相应的反码原码。也可以这样考虑: -1： 1111 1111 -2： 1111 1110（在-1的基础上减1，直接将补码减1即可） -3： 1111 1101（在-2补码基础上减1，以下类似） -4： 1111 1100 …… -127：1000 0001 -128：1000 0000 如此以来：8位补码表示范围是-128~+127因为0只有一种形式所以，仍然是256个数 若8位代表无符号数, 则表示范围是 : 0~255, 这就是为什么高级语言讲到数据类型， 正数的补码与原码相同，负数的补码为 其原码除符号位外所有位取反（得到反码了），然后最低位加1 ","date":"2020-05-30","objectID":"/bit/:3:3","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"原码，反码，补码总结 正数的反码和补码都与原码相同。 负数的反码为对该数的原码除符号位外各位取反。 负数的补码为对该数的原码除符号位外各位取反，然后在最后一位加1　 优缺点: 原码最好理解了，但是加减法不够方便，还有两个零。。 反码稍微困难一些，解决了加减法的问题，但还是有有个零 补码理解困难，其他就没什么缺点了 ","date":"2020-05-30","objectID":"/bit/:3:4","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"存储 计算机中的整数是用补码存储的，最高位为符号位 如果最高位为0则为正数，求值的时候，直接转为10进制即可。 最高位如果为1代表为负数，求值的时候，需要先把二进制的值按位取反，然后加1得到负数绝对值(相反数)的二进制码，然后转为10进制，加上负号即可。 ","date":"2020-05-30","objectID":"/bit/:3:5","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"原码，反码，补码的应用 ","date":"2020-05-30","objectID":"/bit/:3:6","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"负数的十进制和二进制转换 ","date":"2020-05-30","objectID":"/bit/:4:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"十进制转二进制 方法为: 先转换为二进制 对二进制数求反 再将该二进制数加一 总而言之: 十进制数转换为二进制数求补码即为结果 例子 -32 转换为二进制 第一步：32（10）=00100000（2） 第二步：求反：11011111 第三步：加1:11100000 所以-32（10）=11100000（2） ","date":"2020-05-30","objectID":"/bit/:4:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"二进制转十进制 方法为: 数值为取反 对该二进制加一 转换为10进制 例子 11001000 转换为十进制 第一步（数值位取反）： 10110111 第二步（加一）：10111000 第三步（十进制）：-56 所以11001000（2）=-56（10） ","date":"2020-05-30","objectID":"/bit/:4:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"十进制数求反的规律 下面都是以10进制表示: ","date":"2020-05-30","objectID":"/bit/:5:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"负数求反 负数求反等于其绝对值 -1 如: num = -5 num1 = ~num # 4 ","date":"2020-05-30","objectID":"/bit/:5:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"正数求反 正数求反等于其值 +1 的负数 如: num = 4 num1 = ~num # -5 ","date":"2020-05-30","objectID":"/bit/:5:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"二进制的应用场景 ","date":"2020-05-30","objectID":"/bit/:6:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位操作实现乘除法 数 a 向右移一位，相当于将 a 除以 2；数 a 向左移一位，相当于将 a 乘以 2 a = 2 a \u003e\u003e 1 # ---\u003e 1 a \u003c\u003c 1 # ---\u003e 4 ","date":"2020-05-30","objectID":"/bit/:6:1","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位操作交换两数 位操作交换两数可以不需要第三个临时变量，虽然普通操作也可以做到，但是没有其效率高 # 普通操作 def swap(a: int, b: int) -\u003e(int,int): a = a + b b = a - b a = a - b return a,b # 位与操作 def swap(a: int, b: int) -\u003e (int, int): \"\"\" 交换两个数 :param a: :param b: :return: \"\"\" a ^= b # a = (a^b) b ^= a # b = b ^ a = b ^ a ^ b a ^= b # a = a ^ b = a ^ a ^ b return a, b ","date":"2020-05-30","objectID":"/bit/:6:2","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位操作判断奇偶数 只要根据数的最后一位是 0 还是 1 来决定即可，为 0 就是偶数，为 1 就是奇数 if(0 == (a \u0026 1)) { //偶数 } ","date":"2020-05-30","objectID":"/bit/:6:3","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位操作交换符号 交换符号将正数变成负数，负数变成正数 func reversal(a int) int { return ^a + 1 } def reversal(a: int) -\u003e int: \"\"\" 求相反数 :param a: :return: \"\"\" return ~a + 1 正数取反加1，正好变成其对应的负数(补码表示)；负数取反加一，则变为其原码，即正数 ","date":"2020-05-30","objectID":"/bit/:6:4","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位操作求绝对值 正数的绝对值是其本身，负数的绝对值正好可以对其进行取反加一求得，即我们首先判断其符号位（整数右移 31 位得到 0，负数右移 31 位得到 -1,即 0xffffffff），然后根据符号进行相应的操作 def abs(a: int) -\u003e int: i = a \u003e\u003e 31 result = a if i == 0 else ~a + 1 return result 上面的操作可以进行优化，可以将 i == 0 的条件判断语句去掉。我们都知道符号位 i 只有两种情况，即 i = 0 为正，i = -1 为负。对于任何数与 0 异或都会保持不变，与 -1 即 0xffffffff 进行异或就相当于对此数进行取反,因此可以将上面三目元算符转换为((a^i)-i)，即整数时 a 与 0 异或得到本身，再减去 0，负数时与 0xffffffff 异或将 a 进行取反，然后在加上 1，即减去 i(i =-1) def abs(a: int) -\u003e int: \"\"\" 求绝对值 :param a: :return: \"\"\" i = a \u003e\u003e 31 result = (a ^ i) - i return result or func abs(a int) int { i := a \u003e\u003e 31 return (a ^ i) - i } ","date":"2020-05-30","objectID":"/bit/:6:5","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位操作进行高低位交换 给定一个 16 位的无符号整数，将其高 8 位与低 8 位进行交换，求出交换后的值，如 从上面移位操作我们可以知道，只要将无符号数 a»8 即可得到其高 8 位移到低 8 位，高位补 0；将 a « 8 即可将 低 8 位移到高 8 位，低 8 位补 0，然后将 a » 8 和 a«8 进行或操作既可求得交换后的结果 。 unsigned short a = 34520; a = (a \u003e\u003e 8) | (a \u003c\u003c 8); ","date":"2020-05-30","objectID":"/bit/:6:6","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"位操作统计二进制中 1 的个数 统计二进制1的个数可以分别获取每个二进制位数，然后再统计其1的个数，此方法效率比较低。 这里介绍另外一种高效的方法，同样以 34520 为例， 我们计算其 a \u0026= (a-1)的结果： 第一次：计算前：1000 0110 1101 1000 计算后：1000 0110 1101 0000 第二次：计算前：1000 0110 1101 0000 计算后：1000 0110 1100 0000 第三次：计算前：1000 0110 1100 0000 计算后：1000 0110 1000 0000 我们发现，每计算一次二进制中就少了一个 1，则我们可以通过下面方法去统计：count = 0 def count_1(a: int) -\u003e int: \"\"\" 计算数值的二进制表示的1的数量 :param a: :return: \"\"\" count = 0 while (a): a = a \u0026 a - 1 count += 1 return count ","date":"2020-05-30","objectID":"/bit/:6:7","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"求和 两数求和 func add(a int, b int) int { for b != 0 { sum := a ^ b carry := (a \u0026 b) \u003c\u003c 1 a = sum b = carry } return a } ","date":"2020-05-30","objectID":"/bit/:6:8","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"比特位计数 给定一个非负整数 num。对于 0 ≤ i ≤ num 范围中的每个数字 i ，计算其二进制数中的 1 的数目并将它们作为数组返回。 示例 1: 输入: 2 输出: [0,1,1] 示例 2: 输入: 5 输出: [0,1,1,2,1,2] def countBits(num: int) -\u003e [int]: result = [0] * (num + 1) for i in range(1, num + 1): result[i] = result[i \u0026 i - 1] + 1 return result func countBits(num int) []int { result := make([]int, num+1) for i := 1; i \u003c num+1 ; i ++ { result[i] = result[i \u0026 (i-1)] + 1 } return result } ","date":"2020-05-30","objectID":"/bit/:6:9","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"常用的特殊的数 0xaaaaaaaa = 10101010101010101010101010101010 (偶数位为1，奇数位为0） 0x55555555 = 1010101010101010101010101010101 (偶数位为0，奇数位为1） 0x33333333 = 110011001100110011001100110011 (1和0每隔两位交替出现) 0xcccccccc = 11001100110011001100110011001100 (0和1每隔两位交替出现) 0x0f0f0f0f = 00001111000011110000111100001111 (1和0每隔四位交替出现) 0xf0f0f0f0 = 11110000111100001111000011110000 (0和1每隔四位交替出现) 0xffffffff = 11111111111111111111111111111111 ","date":"2020-05-30","objectID":"/bit/:7:0","tags":["算法","位运算","bit"],"title":"位运算","uri":"/bit/"},{"categories":null,"content":"二叉搜索树","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"定义及特点 二叉查找树（英语：Binary Search Tree），也称为 二叉搜索树、有序二叉树（Ordered Binary Tree）或排序二叉树（Sorted Binary Tree），是指一棵空树或者具有下列性质的二叉树： 若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 二叉查找树相比于其他数据结构的优势在于查找、插入的时间复杂度较低。为 O(logn)。二叉查找树是基础性数据结构，用于构建更为抽象的数据结构，如集合、多重集、关联数组等。 二叉查找树的查找过程和次优二叉树类似，通常采取二叉链表作为二叉查找树的存储结构。中序遍历二叉查找树可得到一个关键字的有序序列，一个无序序列可以通过构造一棵二叉查找树变成一个有序序列，构造树的过程即为对无序序列进行查找的过程。每次插入的新的结点都是二叉查找树上新的叶子结点，在进行插入操作时，不必移动其它结点，只需改动某个结点的指针，由空变为非空即可。搜索、插入、删除的复杂度等于树高，期望 O(\\log n)O(logn)，最坏 O(n)O(n)（数列有序，树退化成线性表）。 虽然二叉查找树的最坏效率是 O(n)O(n)，但它支持动态查询，且有很多改进版的二叉查找树可以使树高为 O(\\log n)O(logn)，从而将最坏效率降至 O(\\log n)O(logn)，如 AVL 树、红黑树等。 ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:1:0","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"常用操作 ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:2:0","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"树节点定义: class TreeNode: def __init__(self, val): self.val = val self.left = None self.right = None or type TreeNode struct { Val int Left *TreeNode Right *TreeNode } ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:2:1","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"查找 在二叉搜索树b中查找x的过程为： 若b是空树，则搜索失败，否则： 若x等于b的根节点的数据域之值，则查找成功；否则： 若x小于b的根节点的数据域之值，则递归搜索左子树；否则: 递归查找右子树 ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:2:2","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"插入 向一个二叉搜索树b中插入一个节点s的算法，过程为： 若b是空树，则将s所指结点作为根节点插入，否则： 若s.val等于b的根节点的数据域之值，则返回，否则： 若s.val小于b的根节点的数据域之值，则把s所指节点插入到左子树中，否则： 把s所指节点插入到右子树中（新插入节点总是叶子节点） ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:2:3","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"删除 二叉搜索树的删除操作分三种情况讨论: 如果待删除的节点是叶子节点，那么可以立即被删除，如下图所示： 例：删除数据为16的节点，是叶子节点，可以直接删除 如果有一个子节点，要将下一个子节点上移到当前节点，即替换之 例：删除数据为25的节点，它下面有唯一一个子节点35, 上移到替换之 如果有两个子节点，则将其右子树的最小数据代替此节点的数据，并将其右子树的最小数据删除，如下图所示 例：删除节点数据为5的节点，找到被删除节点右子树的最小节点。需要一个临时变量successor，将11节点下面的子节点进行查询，找到右子树最小节点7，并把右子树最小节点7替换被删除节点，维持二叉树结构。如下图 ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:2:4","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"遍历 可以采用前序，中序，后序来遍历该二叉搜索树，或者使用广度优先搜索的方式。这里用中序遍历来实现，可以保证按从小到大的顺序打印。 ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:2:5","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"构造一颗二叉查找树 用一组数值建造一棵二叉查找树的同时，也把这组数值进行了排序。其最差时间复杂度为 O(n2)。例如，若该组数值经是有序的（从小到大），则建造出来的二叉查找树的所有节点，都没有左子树 ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:2:6","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"常用操作的实现 python版 # 节点定义 class TreeNode: def __init__(self, x): self.val = x self.left = None self.right = None # 查找 def search(root: TreeNode, val: int) -\u003e (bool, TreeNode): if root == None: return False, None elif val \u003e root.val: return search(root.right, val) elif val \u003c root.val: return search(root.left, val) else: return True, root # 插入 def insert(root: TreeNode, node: TreeNode) -\u003e TreeNode: \"\"\"insert inplace\"\"\" if root == None: root = node return root elif node.val \u003e root.val: root.right = insert(root.right, node) else: root.left = insert(root.left, node) return root # 删除 def deleteNode(root: TreeNode, key: int) -\u003e TreeNode: \"\"\" :type root: TreeNode :type key: int :rtype: TreeNode \"\"\" if root == None: return None if key \u003c root.val: root.left = deleteNode(root.left, key) elif key \u003e root.val: root.right = deleteNode(root.right, key) else: if root.left == None: return root.right elif root.right == None: return root.left else: min_node = findMinNode(root.right) root.val = min_node.val root.right = deleteNode(root.right, root.val) return root def findMinNode(node: TreeNode) -\u003e TreeNode: while node.left: node = node.left return node # 中序遍历 def traverse_binary_tree(root: TreeNode): if root is None: return traverse_binary_tree(root.left) print(root.val) traverse_binary_tree(root.right) # 构建二叉树 def build_binary_tree(values: [int]): tree = None for v in values: tree = insert(tree, TreeNode(v)) return tree if __name__ == \"__main__\": values = [17, 5, 35, 2, 11, 29, 38, 9, 16, 7] # 构造二叉树 node = build_binary_tree(values) # 查找 node_7 = search(node, 35) # 遍历 traverse_binary_tree(node) # 删除 a = deleteNode(node, 5) print() golang版: package main import \"fmt\" type TreeNode struct { Val int Left *TreeNode Right *TreeNode } func main() { values := []int{17, 5, 35, 2, 11, 29, 38, 9, 16, 7} // 测试构造二叉树 node := buildBinarySearchTree(values) // 遍历 traverseBinarySearchTree(node) // 搜索 ok, child := search(node, 11) // 删除 new_node := deleteTreenode(node, 35) fmt.Println(new_node) fmt.Println(ok, child) } // 查找 func search(root *TreeNode, val int) (bool, *TreeNode) { if root == nil { return false, nil } if root.Val == val { return true, root } else if root.Val \u003c val { return search(root.Right, val) } else { return search(root.Left, val) } } // 插入 func insert(root, node *TreeNode) *TreeNode { if root == nil { root = node return root } if root.Val \u003e node.Val { root.Left = insert(root.Left, node) } else { root.Right = insert(root.Right, node) } return root } // 删除 func deleteTreenode(root *TreeNode, val int) *TreeNode { if root == nil { return nil } if root.Val \u003e val { root.Left = deleteTreenode(root.Left, val) } else if root.Val \u003c val { root.Right = deleteTreenode(root.Right, val) } else { if root.Left == nil { return root.Right } else if root.Right == nil { return root.Left } else { min_node := findMinNode(root.Right) root.Val = min_node.Val root.Right = deleteTreenode(root.Right, min_node.Val) } } return root } func findMinNode(root *TreeNode) *TreeNode { for root.Left != nil { root = root.Left } return root } // 中序遍历 func traverseBinarySearchTree(root *TreeNode) { if root == nil { return } traverseBinarySearchTree(root.Left) fmt.Println(root.Val) traverseBinarySearchTree(root.Right) } // 构建二叉搜索树 func buildBinarySearchTree(values []int) *TreeNode { var node *TreeNode = nil for _, value := range values { node = insert(node, \u0026TreeNode{Val: value}) } return node } ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:3:0","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"性能分析 查找：最佳情况Olog(n), 最坏情况O(n) 插入：最佳情况Olog(n), 最坏情况O(n) 删除：最佳情况Olog(n), 最坏情况O(n) ","date":"2020-05-05","objectID":"/argorithm/binarysearchtree/:4:0","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/argorithm/binarysearchtree/"},{"categories":null,"content":"二叉搜索树","date":"2020-05-05","objectID":"/binarysearchtree/","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"定义及特点 二叉查找树（英语：Binary Search Tree），也称为 二叉搜索树、有序二叉树（Ordered Binary Tree）或排序二叉树（Sorted Binary Tree），是指一棵空树或者具有下列性质的二叉树： 若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 二叉查找树相比于其他数据结构的优势在于查找、插入的时间复杂度较低。为 O(logn)。二叉查找树是基础性数据结构，用于构建更为抽象的数据结构，如集合、多重集、关联数组等。 二叉查找树的查找过程和次优二叉树类似，通常采取二叉链表作为二叉查找树的存储结构。中序遍历二叉查找树可得到一个关键字的有序序列，一个无序序列可以通过构造一棵二叉查找树变成一个有序序列，构造树的过程即为对无序序列进行查找的过程。每次插入的新的结点都是二叉查找树上新的叶子结点，在进行插入操作时，不必移动其它结点，只需改动某个结点的指针，由空变为非空即可。搜索、插入、删除的复杂度等于树高，期望 O(\\log n)O(logn)，最坏 O(n)O(n)（数列有序，树退化成线性表）。 虽然二叉查找树的最坏效率是 O(n)O(n)，但它支持动态查询，且有很多改进版的二叉查找树可以使树高为 O(\\log n)O(logn)，从而将最坏效率降至 O(\\log n)O(logn)，如 AVL 树、红黑树等。 ","date":"2020-05-05","objectID":"/binarysearchtree/:1:0","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"常用操作 ","date":"2020-05-05","objectID":"/binarysearchtree/:2:0","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"树节点定义: class TreeNode: def __init__(self, val): self.val = val self.left = None self.right = None or type TreeNode struct { Val int Left *TreeNode Right *TreeNode } ","date":"2020-05-05","objectID":"/binarysearchtree/:2:1","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"查找 在二叉搜索树b中查找x的过程为： 若b是空树，则搜索失败，否则： 若x等于b的根节点的数据域之值，则查找成功；否则： 若x小于b的根节点的数据域之值，则递归搜索左子树；否则: 递归查找右子树 ","date":"2020-05-05","objectID":"/binarysearchtree/:2:2","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"插入 向一个二叉搜索树b中插入一个节点s的算法，过程为： 若b是空树，则将s所指结点作为根节点插入，否则： 若s.val等于b的根节点的数据域之值，则返回，否则： 若s.val小于b的根节点的数据域之值，则把s所指节点插入到左子树中，否则： 把s所指节点插入到右子树中（新插入节点总是叶子节点） ","date":"2020-05-05","objectID":"/binarysearchtree/:2:3","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"删除 二叉搜索树的删除操作分三种情况讨论: 如果待删除的节点是叶子节点，那么可以立即被删除，如下图所示： 例：删除数据为16的节点，是叶子节点，可以直接删除 如果有一个子节点，要将下一个子节点上移到当前节点，即替换之 例：删除数据为25的节点，它下面有唯一一个子节点35, 上移到替换之 如果有两个子节点，则将其右子树的最小数据代替此节点的数据，并将其右子树的最小数据删除，如下图所示 例：删除节点数据为5的节点，找到被删除节点右子树的最小节点。需要一个临时变量successor，将11节点下面的子节点进行查询，找到右子树最小节点7，并把右子树最小节点7替换被删除节点，维持二叉树结构。如下图 ","date":"2020-05-05","objectID":"/binarysearchtree/:2:4","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"遍历 可以采用前序，中序，后序来遍历该二叉搜索树，或者使用广度优先搜索的方式。这里用中序遍历来实现，可以保证按从小到大的顺序打印。 ","date":"2020-05-05","objectID":"/binarysearchtree/:2:5","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"构造一颗二叉查找树 用一组数值建造一棵二叉查找树的同时，也把这组数值进行了排序。其最差时间复杂度为 O(n2)。例如，若该组数值经是有序的（从小到大），则建造出来的二叉查找树的所有节点，都没有左子树 ","date":"2020-05-05","objectID":"/binarysearchtree/:2:6","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"常用操作的实现 python版 # 节点定义 class TreeNode: def __init__(self, x): self.val = x self.left = None self.right = None # 查找 def search(root: TreeNode, val: int) -\u003e (bool, TreeNode): if root == None: return False, None elif val \u003e root.val: return search(root.right, val) elif val \u003c root.val: return search(root.left, val) else: return True, root # 插入 def insert(root: TreeNode, node: TreeNode) -\u003e TreeNode: \"\"\"insert inplace\"\"\" if root == None: root = node return root elif node.val \u003e root.val: root.right = insert(root.right, node) else: root.left = insert(root.left, node) return root # 删除 def deleteNode(root: TreeNode, key: int) -\u003e TreeNode: \"\"\" :type root: TreeNode :type key: int :rtype: TreeNode \"\"\" if root == None: return None if key \u003c root.val: root.left = deleteNode(root.left, key) elif key \u003e root.val: root.right = deleteNode(root.right, key) else: if root.left == None: return root.right elif root.right == None: return root.left else: min_node = findMinNode(root.right) root.val = min_node.val root.right = deleteNode(root.right, root.val) return root def findMinNode(node: TreeNode) -\u003e TreeNode: while node.left: node = node.left return node # 中序遍历 def traverse_binary_tree(root: TreeNode): if root is None: return traverse_binary_tree(root.left) print(root.val) traverse_binary_tree(root.right) # 构建二叉树 def build_binary_tree(values: [int]): tree = None for v in values: tree = insert(tree, TreeNode(v)) return tree if __name__ == \"__main__\": values = [17, 5, 35, 2, 11, 29, 38, 9, 16, 7] # 构造二叉树 node = build_binary_tree(values) # 查找 node_7 = search(node, 35) # 遍历 traverse_binary_tree(node) # 删除 a = deleteNode(node, 5) print() golang版: package main import \"fmt\" type TreeNode struct { Val int Left *TreeNode Right *TreeNode } func main() { values := []int{17, 5, 35, 2, 11, 29, 38, 9, 16, 7} // 测试构造二叉树 node := buildBinarySearchTree(values) // 遍历 traverseBinarySearchTree(node) // 搜索 ok, child := search(node, 11) // 删除 new_node := deleteTreenode(node, 35) fmt.Println(new_node) fmt.Println(ok, child) } // 查找 func search(root *TreeNode, val int) (bool, *TreeNode) { if root == nil { return false, nil } if root.Val == val { return true, root } else if root.Val \u003c val { return search(root.Right, val) } else { return search(root.Left, val) } } // 插入 func insert(root, node *TreeNode) *TreeNode { if root == nil { root = node return root } if root.Val \u003e node.Val { root.Left = insert(root.Left, node) } else { root.Right = insert(root.Right, node) } return root } // 删除 func deleteTreenode(root *TreeNode, val int) *TreeNode { if root == nil { return nil } if root.Val \u003e val { root.Left = deleteTreenode(root.Left, val) } else if root.Val \u003c val { root.Right = deleteTreenode(root.Right, val) } else { if root.Left == nil { return root.Right } else if root.Right == nil { return root.Left } else { min_node := findMinNode(root.Right) root.Val = min_node.Val root.Right = deleteTreenode(root.Right, min_node.Val) } } return root } func findMinNode(root *TreeNode) *TreeNode { for root.Left != nil { root = root.Left } return root } // 中序遍历 func traverseBinarySearchTree(root *TreeNode) { if root == nil { return } traverseBinarySearchTree(root.Left) fmt.Println(root.Val) traverseBinarySearchTree(root.Right) } // 构建二叉搜索树 func buildBinarySearchTree(values []int) *TreeNode { var node *TreeNode = nil for _, value := range values { node = insert(node, \u0026TreeNode{Val: value}) } return node } ","date":"2020-05-05","objectID":"/binarysearchtree/:3:0","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"性能分析 查找：最佳情况Olog(n), 最坏情况O(n) 插入：最佳情况Olog(n), 最坏情况O(n) 删除：最佳情况Olog(n), 最坏情况O(n) ","date":"2020-05-05","objectID":"/binarysearchtree/:4:0","tags":["算法","binarySearchTree","二叉搜索树"],"title":"二叉搜索树","uri":"/binarysearchtree/"},{"categories":null,"content":"How to run jenkins on kubernetes","date":"2020-02-08","objectID":"/opensrouce/k8s_jenkins/","tags":["kubernetes","jenkins"],"title":"How to run jenkins on kubernetes","uri":"/opensrouce/k8s_jenkins/"},{"categories":null,"content":"作用 如何在Kubernetes环境中运行jenkins ","date":"2020-02-08","objectID":"/opensrouce/k8s_jenkins/:1:0","tags":["kubernetes","jenkins"],"title":"How to run jenkins on kubernetes","uri":"/opensrouce/k8s_jenkins/"},{"categories":null,"content":"项目地址 https://github.com/russellgao/k8s_jenkins ","date":"2020-02-08","objectID":"/opensrouce/k8s_jenkins/:2:0","tags":["kubernetes","jenkins"],"title":"How to run jenkins on kubernetes","uri":"/opensrouce/k8s_jenkins/"},{"categories":null,"content":"参考 https://mp.weixin.qq.com/s/7YFlmcUH5iOB2XOBIZ2_rA ","date":"2020-02-08","objectID":"/opensrouce/k8s_jenkins/:3:0","tags":["kubernetes","jenkins"],"title":"How to run jenkins on kubernetes","uri":"/opensrouce/k8s_jenkins/"},{"categories":null,"content":"在k8s 中运行EKL","date":"2020-01-04","objectID":"/opensrouce/k8s_elk/","tags":["kubernetes","ELK"],"title":"ELK stack on kubernetes","uri":"/opensrouce/k8s_elk/"},{"categories":null,"content":"作用 如何在Kubernetes环境中运行ELK Stack ","date":"2020-01-04","objectID":"/opensrouce/k8s_elk/:1:0","tags":["kubernetes","ELK"],"title":"ELK stack on kubernetes","uri":"/opensrouce/k8s_elk/"},{"categories":null,"content":"项目地址 https://github.com/russellgao/k8s_elk ","date":"2020-01-04","objectID":"/opensrouce/k8s_elk/:2:0","tags":["kubernetes","ELK"],"title":"ELK stack on kubernetes","uri":"/opensrouce/k8s_elk/"},{"categories":null,"content":"用法 manifests Can run in production environment experimental In the experimental stage 使用之前需要修改各个yaml文件的Storage，Service相关的参数，根据实际情况选择合适的介质，修改完之后执行kubectl -f manifests 即可。 详细信息参考 github ","date":"2020-01-04","objectID":"/opensrouce/k8s_elk/:3:0","tags":["kubernetes","ELK"],"title":"ELK stack on kubernetes","uri":"/opensrouce/k8s_elk/"},{"categories":null,"content":"支持的组件 es logstash kibana kafka zookeeper ","date":"2020-01-04","objectID":"/opensrouce/k8s_elk/:4:0","tags":["kubernetes","ELK"],"title":"ELK stack on kubernetes","uri":"/opensrouce/k8s_elk/"},{"categories":null,"content":"More https://mp.weixin.qq.com/s/93_Jf8P69Q0nkw1Ip7MsFQ ","date":"2020-01-04","objectID":"/opensrouce/k8s_elk/:5:0","tags":["kubernetes","ELK"],"title":"ELK stack on kubernetes","uri":"/opensrouce/k8s_elk/"}]